# INSTRUCCIONES: OpciÃ³n 2 - Correr Fase 3 con todos los datos

## Resumen
La Fase 3 actualmente **solo procesa 100 imÃ¡genes** de val_eval. Esto causa que el cache de MC-Dropout sea insuficiente para la Fase 5. La soluciÃ³n es correr la Fase 3 con **todas las 2,000 imÃ¡genes** de val_eval.

---

## ğŸ”§ Cambio Realizado

### Archivo modificado: `fase 3/main.ipynb`

**LÃ­nea modificada:**
```python
# ANTES (lÃ­nea ~1336):
for img_id in tqdm(image_ids[:100], desc="Procesando imÃ¡genes"):

# DESPUÃ‰S:
for img_id in tqdm(image_ids, desc="Procesando imÃ¡genes"):
```

**Cambio adicional:**
Se eliminÃ³ el mensaje de advertencia:
```python
# ELIMINADO:
print(f"âš ï¸  Procesando primeras 100 imÃ¡genes para prueba rÃ¡pida\n")
```

---

## ğŸ“‹ Pasos para Ejecutar

### Paso 1: Abrir Fase 3
```
1. Abrir el archivo: fase 3/main.ipynb
2. Verificar que tiene la modificaciÃ³n (sin [:100])
```

### Paso 2: Ejecutar todas las celdas
```
1. En VS Code: MenÃº "Run" > "Run All"
2. O usar Ctrl+Shift+Enter repetidamente
3. O en Jupyter: "Cell" > "Run All"
```

### Paso 3: Tiempo estimado
```
- Con 100 imÃ¡genes: ~15-20 minutos
- Con 2,000 imÃ¡genes: ~6-7 horas (estimado)
```

### Paso 4: Verificar resultados
Al finalizar, debe generar:
```
fase 3/outputs/mc_dropout/
â”œâ”€â”€ mc_stats_labeled.parquet     â† Debe tener ~2,000 imÃ¡genes (no solo 100)
â”œâ”€â”€ preds_mc_aggregated.json     â† Predicciones para todas las imÃ¡genes
â”œâ”€â”€ metrics.json                 â† MÃ©tricas de detecciÃ³n
â”œâ”€â”€ timing_data.parquet          â† Tiempos de inferencia
â””â”€â”€ ...
```

**VerificaciÃ³n del cache:**
```powershell
# En terminal PowerShell:
cd "fase 3/outputs/mc_dropout"
python -c "import pandas as pd; df = pd.read_parquet('mc_stats_labeled.parquet'); print(f'ImÃ¡genes en cache: {df.image_id.nunique()}')"
```

**Resultado esperado:**
```
ImÃ¡genes en cache: 2000  â† Â¡Debe ser 2000, no 100!
```

---

## ğŸš€ Paso 5: Correr Fase 5

Una vez que Fase 3 termine (y genere el cache completo), puedes correr Fase 5:

```
1. Abrir: fase 5/main.ipynb
2. Ejecutar todas las celdas ("Run All")
3. Tiempo estimado: ~30-45 minutos
```

### Verificar temperaturas diferentes
Al final de Fase 5, verificar:
```powershell
cat "outputs/comparison/temperatures.json"
```

**Resultado esperado (temperaturas DIFERENTES):**
```json
{
  "baseline": 1.53,
  "mc_dropout": 1.67,       â† Â¡Debe ser diferente!
  "decoder_variance": 1.42  â† Â¡Debe ser diferente!
}
```

**Si sale IGUAL (error):**
```json
{
  "baseline": 1.53,
  "mc_dropout": 1.53,       â† Â¡ERROR! igual que baseline
  "decoder_variance": 1.53  â† Â¡ERROR! igual que baseline
}
```

---

## ğŸ“Š Salidas esperadas de Fase 5

DespuÃ©s de correr Fase 5, deberÃ­as tener:

```
outputs/comparison/
â”œâ”€â”€ temperatures.json               â† Temperaturas (diferentes por mÃ©todo)
â”œâ”€â”€ calib_baseline.csv              â† CalibraciÃ³n baseline (1,500 imgs)
â”œâ”€â”€ calib_mc_dropout.csv            â† CalibraciÃ³n MC-Dropout (1,500 imgs)
â”œâ”€â”€ calib_decoder_variance.csv      â† CalibraciÃ³n decoder (1,500 imgs)
â”œâ”€â”€ eval_baseline.csv               â† EvaluaciÃ³n baseline (500 imgs)
â”œâ”€â”€ eval_mc_dropout.csv             â† EvaluaciÃ³n MC-Dropout (500 imgs)
â”œâ”€â”€ eval_decoder_variance.csv       â† EvaluaciÃ³n decoder (500 imgs)
â”œâ”€â”€ final_report.txt                â† Reporte final
â””â”€â”€ ...
```

---

## âš ï¸ Notas Importantes

### Si Fase 3 falla o se interrumpe:
1. **NO reiniciar desde cero**: El cÃ³digo guarda resultados parciales
2. **Checkpoint manual**: Si se interrumpe, puedes modificar el notebook para:
   ```python
   # Procesar desde la imagen N en adelante
   for img_id in tqdm(image_ids[N:], desc="Procesando imÃ¡genes"):
   ```

### Si no quieres esperar 6-7 horas:
**OpciÃ³n alternativa**: Usar un subset mÃ¡s grande (ej: 500 imÃ¡genes)
```python
# En fase 3/main.ipynb, lÃ­nea ~1336:
for img_id in tqdm(image_ids[:500], desc="Procesando imÃ¡genes"):
```

Esto te darÃ¡ mejor cobertura que 100 imÃ¡genes, pero terminarÃ¡ mÃ¡s rÃ¡pido que 2,000.

### Recursos computacionales:
- **GPU necesaria**: SÃ­ (CUDA debe estar disponible)
- **Memoria GPU**: ~6-8 GB recomendados
- **RAM**: ~16 GB recomendados
- **Almacenamiento**: ~2-3 GB para los outputs

---

## ğŸ¯ Resumen de la soluciÃ³n

| Estado | DescripciÃ³n |
|--------|-------------|
| âœ… **Fase 2** | Ya completa (baseline cache: 1,988 imÃ¡genes) |
| â³ **Fase 3** | **Debes correr** (generar cache para 2,000 imÃ¡genes) |
| âœ… **Fase 4** | Ya completa (temperatura scaling) |
| â³ **Fase 5** | **Correr despuÃ©s** de Fase 3 |

---

## ğŸ“ ValidaciÃ³n Final

DespuÃ©s de correr todo, puedes usar los scripts de diagnÃ³stico:

```powershell
# 1. Verificar cobertura de cache
python diagnose_cache.py

# 2. Verificar overlap entre splits
python check_overlap.py

# 3. Contar imÃ¡genes por split
python count_images.py

# 4. AnÃ¡lisis completo
python analyze_splits.py
```

---

## ğŸ“ ConclusiÃ³n

**Lo que debes hacer:**
1. âœ… Verificar que el notebook de Fase 3 tiene el cambio (sin `[:100]`)
2. ğŸš€ Correr Fase 3 completo (esperar ~6-7 horas)
3. âœ… Verificar que el cache tiene 2,000 imÃ¡genes
4. ğŸš€ Correr Fase 5
5. âœ… Verificar que las temperaturas son diferentes

**Si todo sale bien:**
- Temperaturas diferentes âœ…
- Cache completo âœ…
- Resultados de calibraciÃ³n correctos âœ…

---

Â¡Ã‰xito! ğŸ‰
