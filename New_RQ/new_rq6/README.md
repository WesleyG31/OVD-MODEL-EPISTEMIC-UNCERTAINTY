# RQ6 â€” Decoder Dynamics as Epistemic Uncertainty Signals

## ğŸ“‹ Resumen

Este notebook responde la **Research Question 6** del proyecto sobre incertidumbre epistÃ©mica en modelos de detecciÃ³n de objetos open-vocabulary (OVD).

**RQ6**: Â¿QuÃ© propiedades intrÃ­nsecas de la dinÃ¡mica del decoder transformer codifican incertidumbre epistÃ©mica en OVD, y cuÃ¡ndo la varianza inter-capa sirve de proxy confiable para la incertidumbre del modelo?

**HipÃ³tesis**: La incertidumbre se alinea mÃ¡s con los errores conforme aumenta la profundidad del decoder: las predicciones TP se estabilizan antes que las FP; la varianza en capas tardÃ­as separa mejor los errores y mejora el AUROC de detecciÃ³n de errores.

## ğŸ¯ Objetivos

1. **Capturar dinÃ¡micas del decoder**: Extraer embeddings de cada capa del decoder de GroundingDINO
2. **Calcular incertidumbre inter-capa**: Usar varianza entre capas como proxy de incertidumbre epistÃ©mica
3. **Analizar evoluciÃ³n por profundidad**: Verificar que la discriminaciÃ³n mejora en capas tardÃ­as
4. **Identificar condiciones de falla**: Encontrar escenarios donde la varianza es menos predictiva

## ğŸ“Š Deliverables

### Figuras (TPAMI-style)
- âœ… **Figure RQ6.1**: Varianza inter-capa de bounding-box por profundidad (TP vs FP)
- âœ… **Figure RQ6.2**: AUROC de detecciÃ³n de errores por capa del decoder

### Tablas (TPAMI-style)
- âœ… **Table RQ6.1**: DiagnÃ³sticos de efectividad de incertidumbre por capa
- âœ… **Table RQ6.2**: Condiciones de falla donde la varianza es menos predictiva

### Datos
- âœ… `decoder_dynamics.parquet`: Detecciones con varianzas por capa
- âœ… `layer_variance_stats.csv`: EstadÃ­sticas de varianza por capa
- âœ… `auroc_by_layer.csv`: AUROC por profundidad del decoder
- âœ… `summary_rq6.json`: Resumen completo de resultados

## ğŸš€ Quick Start

### EjecuciÃ³n RÃ¡pida (3 comandos)
```bash
# 1. Abrir notebook
jupyter notebook rq6.ipynb

# 2. Ejecutar celdas clave (marcar "âœ… EJECUTAR PARA RQ6")
#    - Celda 1: ConfiguraciÃ³n
#    - Celda 2: Cargar modelo
#    - Celda 5: Inferencia (15-20 min)

# 3. Verificar outputs
ls output/  # Debe mostrar 14 archivos
```

### Tiempo de EjecuciÃ³n
- **Primera vez**: ~20-25 minutos (con GPU)
- **Re-anÃ¡lisis**: ~3 minutos (si ya existe decoder_dynamics.parquet)

## ğŸ“ Estructura de Archivos

```
new_rq6/
â”œâ”€â”€ rq6.ipynb                    # ğŸ““ Notebook principal (30 celdas)
â”œâ”€â”€ output/                      # ğŸ“‚ Directorio de resultados
â”‚   â”œâ”€â”€ Fig_RQ6_1_*.png/pdf     # ğŸ–¼ï¸ Figura 1: Varianza TP vs FP
â”‚   â”œâ”€â”€ Fig_RQ6_2_*.png/pdf     # ğŸ–¼ï¸ Figura 2: AUROC por capa
â”‚   â”œâ”€â”€ Table_RQ6_1.csv/.tex    # ğŸ“‹ Tabla 1: Layer-wise diagnostics
â”‚   â”œâ”€â”€ Table_RQ6_2.csv/.tex    # ğŸ“‹ Tabla 2: Failure conditions
â”‚   â”œâ”€â”€ decoder_dynamics.parquet # ğŸ’¾ Datos crudos
â”‚   â”œâ”€â”€ layer_variance_stats.csv # ğŸ“Š EstadÃ­sticas por capa
â”‚   â”œâ”€â”€ auroc_by_layer.csv       # ğŸ“Š AUROC por capa
â”‚   â”œâ”€â”€ summary_rq6.json         # ğŸ“„ Resumen JSON
â”‚   â””â”€â”€ figure_captions.txt      # ğŸ“ Captions TPAMI
â”œâ”€â”€ README_RQ6.md                # ğŸ“– DocumentaciÃ³n completa
â”œâ”€â”€ QUICKSTART.md                # âš¡ GuÃ­a de inicio rÃ¡pido
â”œâ”€â”€ RESUMEN_EJECUTIVO.md         # ğŸ“‹ Resumen del notebook
â””â”€â”€ ARQUITECTURA_TECNICA.md      # ğŸ—ï¸ Detalles tÃ©cnicos
```

## ğŸ”¬ MetodologÃ­a

### 1. Captura de Embeddings del Decoder
- Se registran **hooks** en cada una de las 6 capas del decoder de GroundingDINO
- Durante inferencia, se capturan los embeddings de cada query en cada capa
- Formato: `[num_queries, batch, embed_dim]` â†’ `[900, 1, 256]`

### 2. CÃ¡lculo de Varianza Inter-Capa
Para cada detecciÃ³n:
```python
layer_scores = [score_layer_0, score_layer_1, ..., score_layer_5]
uncertainty = np.var(layer_scores)  # Incertidumbre epistÃ©mica
```

### 3. Matching con Ground Truth
- Cada predicciÃ³n se matchea con GT usando IoU
- TP (True Positive): IoU â‰¥ 0.5 y categorÃ­a correcta
- FP (False Positive): IoU < 0.5 o categorÃ­a incorrecta

### 4. AnÃ¡lisis Progresivo por Profundidad
Para cada capa â„“ âˆˆ {1, 2, 3, 4, 5, 6}:
- Calcular varianza acumulada usando capas 1..â„“
- Computar AUROC para detecciÃ³n de errores
- Separar estadÃ­sticas de TP vs FP

## ğŸ“ˆ Resultados Esperados

### HipÃ³tesis 1: TP se estabilizan antes que FP
**MÃ©trica**: Var(TP) < Var(FP) en capas tardÃ­as
- TP alcanzan consensus rÃ¡pido (baja varianza)
- FP mantienen alta varianza (incertidumbre)

### HipÃ³tesis 2: Capas tardÃ­as mejoran AUROC
**MÃ©trica**: AUROC(capa 6) > AUROC(capa 1)
- Primera capa: AUROC â‰ˆ 0.65-0.70
- Ãšltima capa: AUROC â‰ˆ 0.85-0.90
- Mejora: +0.15 a +0.25

### HipÃ³tesis 3: SeparaciÃ³n aumenta con profundidad
**MÃ©trica**: (Var(FP) - Var(TP)) aumenta con la capa
- Capas tempranas: SeparaciÃ³n baja
- Capas tardÃ­as: SeparaciÃ³n alta
- Indica concentraciÃ³n progresiva de seÃ±al epistÃ©mica

## ğŸ“‹ Prerequisitos

### Software
- Python 3.8+
- PyTorch 1.12+ con CUDA
- GroundingDINO instalado en `/opt/program/GroundingDINO/`
- LibrerÃ­as: pandas, numpy, matplotlib, seaborn, sklearn, pycocotools

### Datos
- Dataset BDD100K en `../../data/bdd100k_coco/`
- Split: `val_eval.json` (2,000 imÃ¡genes)
- Se procesan las primeras 500 por defecto

### Hardware
- **GPU**: NVIDIA con â‰¥8GB VRAM (recomendado)
- **CPU**: Funciona pero ~10x mÃ¡s lento
- **RAM**: â‰¥16GB
- **Disco**: ~500MB para outputs

## ğŸ”§ ConfiguraciÃ³n

### ParÃ¡metros Principales (Celda 1)
```python
CONFIG = {
    'seed': 42,                  # Reproducibilidad
    'device': 'cuda',            # cuda o cpu
    'sample_size': 500,          # ImÃ¡genes a procesar
    'iou_matching': 0.5,         # Threshold para TP/FP
    'conf_threshold': 0.25,      # Confianza mÃ­nima
    'num_layers': 6              # Capas del decoder
}
```

### Ajustes Comunes

#### EjecuciÃ³n rÃ¡pida (pruebas)
```python
'sample_size': 50  # 2 minutos en lugar de 15
```

#### EjecuciÃ³n completa (paper)
```python
'sample_size': 2000  # Todo val_eval
```

## ğŸ“š DocumentaciÃ³n Adicional

- **[QUICKSTART.md](QUICKSTART.md)**: GuÃ­a de inicio rÃ¡pido (5 minutos de lectura)
- **[README_RQ6.md](README_RQ6.md)**: DocumentaciÃ³n completa con troubleshooting
- **[RESUMEN_EJECUTIVO.md](RESUMEN_EJECUTIVO.md)**: Resumen del notebook (30 celdas)
- **[ARQUITECTURA_TECNICA.md](ARQUITECTURA_TECNICA.md)**: Detalles tÃ©cnicos y flujo de datos

## âœ… ValidaciÃ³n

### Checklist de Resultados
- [ ] Figure RQ6.1 muestra FP > TP en varianza
- [ ] Figure RQ6.2 muestra AUROC creciente
- [ ] Table RQ6.1 tiene valores coherentes
- [ ] Table RQ6.2 lista condiciones de falla
- [ ] summary_rq6.json confirma las 3 hipÃ³tesis

### ValidaciÃ³n AutomÃ¡tica
El notebook incluye validaciÃ³n automÃ¡tica de hipÃ³tesis:
```
âœ“ H1 (TP estabilizan antes que FP): CONFIRMADA
âœ“ H2 (Capas tardÃ­as mejor AUROC): CONFIRMADA
âœ“ H3 (SeparaciÃ³n aumenta con profundidad): CONFIRMADA
```

## ğŸ› Troubleshooting

### Problemas Comunes

#### "CUDA out of memory"
**SoluciÃ³n**: Reducir `sample_size` a 50 o 100

#### "Model not found"
**SoluciÃ³n**: Verificar instalaciÃ³n de GroundingDINO
```bash
ls /opt/program/GroundingDINO/weights/groundingdino_swint_ogc.pth
```

#### "Dataset not found"
**SoluciÃ³n**: Verificar path relativo al dataset
```bash
ls ../../data/bdd100k_coco/val_eval.json
```

#### EjecuciÃ³n muy lenta
**Causa**: Ejecutando en CPU en lugar de GPU
**SoluciÃ³n**: Verificar `torch.cuda.is_available() == True`

## ğŸ“Š MÃ©tricas y KPIs

### MÃ©tricas de Dataset
- ImÃ¡genes procesadas: 500 (configurable)
- Detecciones esperadas: ~8,000-10,000
- TP rate esperado: ~80-85%
- FP rate esperado: ~15-20%

### MÃ©tricas de Calidad
- AUROC primera capa: 0.65-0.70
- AUROC Ãºltima capa: 0.85-0.90
- Mejora en AUROC: +0.15 a +0.25
- SeparaciÃ³n Var(FP)-Var(TP): Positiva y creciente

## ğŸ“ Contexto del Proyecto

Este notebook es parte de un proyecto mÃ¡s amplio sobre incertidumbre epistÃ©mica en OVD:

- **Fase 2**: Baseline sin incertidumbre
- **Fase 3**: MC-Dropout para incertidumbre
- **Fase 4**: Temperature scaling para calibraciÃ³n
- **Fase 5**: ComparaciÃ³n de mÃ©todos
- **RQ6**: AnÃ¡lisis de dinÃ¡micas del decoder (este notebook)

## ğŸ¤ Contribuciones

### Estructura del CÃ³digo
- CÃ³digo bien documentado en espaÃ±ol
- Contenido de figuras en inglÃ©s (TPAMI-style)
- Funciones modulares y reutilizables
- Seeds fijados para reproducibilidad

### Extensiones Posibles
1. Analizar mÃ¡s capas (si el modelo tiene mÃ¡s de 6)
2. Probar otros transformers (DETR, etc.)
3. Agregar anÃ¡lisis por categorÃ­a
4. Estudiar varianza temporal (video)

## ğŸ“„ Licencia

Este cÃ³digo es parte del proyecto de investigaciÃ³n sobre incertidumbre epistÃ©mica en OVD. Uso acadÃ©mico y de investigaciÃ³n.

## ğŸ“ Soporte

### Recursos
- DocumentaciÃ³n: Ver archivos .md en este directorio
- Issues: Revisar troubleshooting en README_RQ6.md
- Logs: Revisar outputs del notebook

### Contacto
Para preguntas especÃ­ficas sobre RQ6, revisar primero:
1. QUICKSTART.md (inicio rÃ¡pido)
2. README_RQ6.md (troubleshooting)
3. ARQUITECTURA_TECNICA.md (detalles tÃ©cnicos)

---

## ğŸ‰ Â¡Listo para Ejecutar!

```bash
# Paso 1: Abrir notebook
jupyter notebook rq6.ipynb

# Paso 2: Ejecutar celdas marcadas "âœ… EJECUTAR PARA RQ6"
# (Celdas 1, 2, 5)

# Paso 3: Ver resultados
ls output/
```

**Tiempo total: ~20 minutos** â±ï¸

**Outputs esperados: 14 archivos** ğŸ“

**Figuras listas para paper: 2 (PNG + PDF)** ğŸ–¼ï¸

**Tablas listas para paper: 2 (CSV + LaTeX)** ğŸ“‹

---

*Generado para responder RQ6 del proyecto OVD Epistemic Uncertainty*  
*Ãšltima actualizaciÃ³n: 2026-02-04*
