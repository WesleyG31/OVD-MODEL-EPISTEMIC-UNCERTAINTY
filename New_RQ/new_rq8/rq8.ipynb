{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "512cccd8",
   "metadata": {},
   "source": [
    "# RQ8 â€” Joint Semanticâ€“Geometric Calibration for Reliability\n",
    "\n",
    "**Research Question**: How can semantic confidence and localization quality be jointly calibrated to yield meaningful scores for ranking/selection?\n",
    "\n",
    "**HipÃ³tesis**: Los scores semÃ¡nticos crudos estÃ¡n desalineados con la calidad geomÃ©trica (IoU); una calibraciÃ³n conjunta restaura la monotonicidad y mejora mÃ©tricas de ranking (e.g., Precision@K) incluso cuando el mAP cambia poco.\n",
    "\n",
    "**Expected Results**:\n",
    "- **Figure RQ8.1**: Confiabilidad de los scores de detecciÃ³n respecto a la calidad geomÃ©trica (mean IoU por bin de confianza). La calibraciÃ³n conjunta mejora sustancialmente la alineaciÃ³n monotÃ³nica entre score y precisiÃ³n de localizaciÃ³n.\n",
    "- **Figure RQ8.2**: Precision@K para ranking de detecciones bajo scores crudos y calibrados (escala log K). La calibraciÃ³n mejora la calidad del ranking, soportando selecciÃ³n confiable mÃ¡s allÃ¡ del mAP.\n",
    "- **Table RQ8.1**: CorrelaciÃ³n entre detection score e IoU antes y despuÃ©s de calibraciÃ³n conjunta\n",
    "- **Table RQ8.2**: Mejoras en ranking y selecciÃ³n inducidas por calibraciÃ³n conjunta con presupuesto fijo de propuestas\n",
    "\n",
    "**Nota**: Este notebook utiliza resultados REALES del modelo GroundingDINO evaluado en las fases anteriores. Los scores, IoUs y mÃ©tricas son autÃ©nticos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91051d91",
   "metadata": {},
   "source": [
    "## 1. ConfiguraciÃ³n e Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7568cfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ConfiguraciÃ³n cargada\n",
      "   Device: cuda\n",
      "   Output: /workspace/New_RQ/new_rq8/output\n",
      "   Data:   /workspace/New_RQ/new_rq8/../../data\n",
      "   Sample size: 500 imÃ¡genes\n",
      "âœ… ConfiguraciÃ³n guardada en output/config_rq8.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import yaml\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from pycocotools.coco import COCO\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ConfiguraciÃ³n de paths relativos (desde New_RQ/new_rq8/)\n",
    "BASE_DIR = Path('../..')  # Subir dos niveles hasta el root del proyecto\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "OUTPUT_DIR = Path('./output')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CONFIG = {\n",
    "    'seed': 42,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'categories': ['person', 'rider', 'car', 'truck', 'bus', 'train', 'motorcycle', 'bicycle', 'traffic light', 'traffic sign'],\n",
    "    'iou_matching': 0.5,\n",
    "    'conf_threshold': 0.25,\n",
    "    'sample_size': 500,  # NÃºmero de imÃ¡genes a procesar\n",
    "    'n_bins': 10,  # Para reliability diagrams\n",
    "    'top_k_values': [100, 200, 400]  # Presupuestos para Precision@K\n",
    "}\n",
    "\n",
    "# Semillas para reproducibilidad\n",
    "torch.manual_seed(CONFIG['seed'])\n",
    "np.random.seed(CONFIG['seed'])\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(CONFIG['seed'])\n",
    "\n",
    "# ConfiguraciÃ³n de visualizaciÃ³n\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(f\"âœ… ConfiguraciÃ³n cargada\")\n",
    "print(f\"   Device: {CONFIG['device']}\")\n",
    "print(f\"   Output: {OUTPUT_DIR.absolute()}\")\n",
    "print(f\"   Data:   {DATA_DIR.absolute()}\")\n",
    "print(f\"   Sample size: {CONFIG['sample_size']} imÃ¡genes\")\n",
    "\n",
    "# Guardar configuraciÃ³n\n",
    "with open(OUTPUT_DIR / 'config_rq8.yaml', 'w') as f:\n",
    "    yaml.dump(CONFIG, f)\n",
    "print(f\"âœ… ConfiguraciÃ³n guardada en {OUTPUT_DIR / 'config_rq8.yaml'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd9c327",
   "metadata": {},
   "source": [
    "## 2. Cargar Modelo GroundingDINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd7a96fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "   CARGANDO MODELO GROUNDINGDINO PARA CALIBRACIÃ“N CONJUNTA\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "ğŸ“ GroundingDINO instalado en: /opt/conda/lib/python3.10/site-packages/groundingdino-0.1.0-py3.10-linux-x86_64.egg/groundingdino\n",
      "âœ… Config encontrado: /opt/program/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\n",
      "âœ… Pesos encontrados: /opt/program/GroundingDINO/weights/groundingdino_swint_ogc.pth\n",
      "\n",
      "ğŸ”„ Cargando modelo desde:\n",
      "   Config:  /opt/program/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\n",
      "   Weights: /opt/program/GroundingDINO/weights/groundingdino_swint_ogc.pth\n",
      "final text_encoder_type: bert-base-uncased\n",
      "\n",
      "âœ… Modelo cargado en cuda\n",
      "âœ… Prompt: person. rider. car. truck. bus. train. motorcycle. bicycle. traffic light. traffic sign.\n",
      "âœ… Arquitectura: GroundingDINO SwinT-OGC\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# âœ… EJECUTAR PARA RQ8 - Cargar modelo GroundingDINO\n",
    "\n",
    "from groundingdino.util.inference import load_model, load_image, predict\n",
    "from groundingdino.util import box_ops\n",
    "import groundingdino\n",
    "import os\n",
    "\n",
    "print(\"â•\" * 70)\n",
    "print(\"   CARGANDO MODELO GROUNDINGDINO PARA CALIBRACIÃ“N CONJUNTA\")\n",
    "print(\"â•\" * 70)\n",
    "\n",
    "# Detectar ubicaciÃ³n de GroundingDINO\n",
    "gdino_path = os.path.dirname(groundingdino.__file__)\n",
    "print(f\"\\nğŸ“ GroundingDINO instalado en: {gdino_path}\")\n",
    "\n",
    "# Buscar archivos de configuraciÃ³n y pesos en ubicaciones comunes\n",
    "possible_configs = [\n",
    "    '/opt/program/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py',\n",
    "    os.path.join(gdino_path, 'config', 'GroundingDINO_SwinT_OGC.py'),\n",
    "    str(BASE_DIR / 'installing_dino' / 'GroundingDINO' / 'groundingdino' / 'config' / 'GroundingDINO_SwinT_OGC.py'),\n",
    "    'C:/opt/program/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py',  # Windows absoluta\n",
    "]\n",
    "\n",
    "possible_weights = [\n",
    "    '/opt/program/GroundingDINO/weights/groundingdino_swint_ogc.pth',\n",
    "    os.path.join(os.path.dirname(gdino_path), 'weights', 'groundingdino_swint_ogc.pth'),\n",
    "    str(BASE_DIR / 'installing_dino' / 'GroundingDINO' / 'weights' / 'groundingdino_swint_ogc.pth'),\n",
    "    str(OUTPUT_DIR / 'weights' / 'groundingdino_swint_ogc.pth'),\n",
    "    './weights/groundingdino_swint_ogc.pth',\n",
    "    'C:/opt/program/GroundingDINO/weights/groundingdino_swint_ogc.pth',  # Windows absoluta\n",
    "]\n",
    "\n",
    "# Encontrar archivos existentes\n",
    "model_config = None\n",
    "for config_path in possible_configs:\n",
    "    if os.path.exists(config_path):\n",
    "        model_config = config_path\n",
    "        print(f\"âœ… Config encontrado: {config_path}\")\n",
    "        break\n",
    "\n",
    "model_weights = None\n",
    "for weights_path in possible_weights:\n",
    "    if os.path.exists(weights_path):\n",
    "        model_weights = weights_path\n",
    "        print(f\"âœ… Pesos encontrados: {weights_path}\")\n",
    "        break\n",
    "\n",
    "# Verificar que se encontraron los archivos\n",
    "if model_config is None or model_weights is None:\n",
    "    print(\"\\nâŒ ERROR: No se encontraron los archivos del modelo\")\n",
    "    print(\"\\nğŸ” Buscando en:\")\n",
    "    print(\"\\nConfigs buscados:\")\n",
    "    for p in possible_configs:\n",
    "        print(f\"  {'âœ…' if os.path.exists(p) else 'âŒ'} {p}\")\n",
    "    print(\"\\nPesos buscados:\")\n",
    "    for p in possible_weights:\n",
    "        print(f\"  {'âœ…' if os.path.exists(p) else 'âŒ'} {p}\")\n",
    "    \n",
    "    print(\"\\nğŸ’¡ SOLUCIONES:\")\n",
    "    print(\"\\n1. DESCARGAR PESOS DEL MODELO:\")\n",
    "    print(\"   - URL: https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth\")\n",
    "    print(f\"   - Guardar en: {OUTPUT_DIR / 'weights' / 'groundingdino_swint_ogc.pth'}\")\n",
    "    print(f\"\\n2. CREAR DIRECTORIO Y DESCARGAR:\")\n",
    "    (OUTPUT_DIR / 'weights').mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"   - mkdir -p {OUTPUT_DIR / 'weights'}\")\n",
    "    print(f\"   - Descargar desde el link anterior a la carpeta weights/\")\n",
    "    \n",
    "    print(\"\\n3. ALTERNATIVA: Usar un notebook que ya tenga acceso al modelo\")\n",
    "    print(\"   - Este notebook requiere los pesos del modelo para ejecutar inferencias\")\n",
    "    print(\"   - Si ya ejecutaste Fase 2/3/4/5, los pesos deberÃ­an estar disponibles\")\n",
    "    \n",
    "    raise FileNotFoundError(\"Archivos del modelo no encontrados. Ver instrucciones arriba.\")\n",
    "\n",
    "print(f\"\\nğŸ”„ Cargando modelo desde:\")\n",
    "print(f\"   Config:  {model_config}\")\n",
    "print(f\"   Weights: {model_weights}\")\n",
    "\n",
    "model = load_model(model_config, model_weights)\n",
    "model.to(CONFIG['device'])\n",
    "model.eval()\n",
    "\n",
    "TEXT_PROMPT = '. '.join(CONFIG['categories']) + '.'\n",
    "\n",
    "print(f\"\\nâœ… Modelo cargado en {CONFIG['device']}\")\n",
    "print(f\"âœ… Prompt: {TEXT_PROMPT}\")\n",
    "print(f\"âœ… Arquitectura: GroundingDINO SwinT-OGC\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90064293",
   "metadata": {},
   "source": [
    "## 3. Funciones Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb0287fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Funciones auxiliares definidas\n"
     ]
    }
   ],
   "source": [
    "def normalize_label(label):\n",
    "    \"\"\"Normaliza etiquetas del modelo a categorÃ­as del dataset\"\"\"\n",
    "    synonyms = {\n",
    "        'bike': 'bicycle', \n",
    "        'motorbike': 'motorcycle', \n",
    "        'pedestrian': 'person',\n",
    "        'stop sign': 'traffic sign', \n",
    "        'red light': 'traffic light'\n",
    "    }\n",
    "    label_lower = label.lower().strip()\n",
    "    if label_lower in synonyms:\n",
    "        return synonyms[label_lower]\n",
    "    for cat in CONFIG['categories']:\n",
    "        if cat in label_lower:\n",
    "            return cat\n",
    "    return label_lower\n",
    "\n",
    "def compute_iou(box1, box2):\n",
    "    \"\"\"Calcula IoU entre dos bounding boxes en formato [x1, y1, x2, y2]\"\"\"\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "    \n",
    "    inter = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union = area1 + area2 - inter\n",
    "    \n",
    "    return inter / union if union > 0 else 0.0\n",
    "\n",
    "def match_predictions_to_gt(predictions, gt_annotations, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Matchea predicciones con ground truth usando IoU\n",
    "    Retorna: lista de (pred, gt, is_correct, iou)\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "    used_gt = set()\n",
    "    \n",
    "    # Ordenar predicciones por score descendente\n",
    "    predictions_sorted = sorted(predictions, key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    for pred in predictions_sorted:\n",
    "        best_iou = 0\n",
    "        best_gt = None\n",
    "        best_gt_idx = None\n",
    "        \n",
    "        for gt_idx, gt in enumerate(gt_annotations):\n",
    "            if gt_idx in used_gt:\n",
    "                continue\n",
    "            \n",
    "            # Verificar que sean de la misma categorÃ­a\n",
    "            if pred['category_id'] != gt['category_id']:\n",
    "                continue\n",
    "            \n",
    "            # Calcular IoU\n",
    "            iou = compute_iou(pred['bbox'], gt['bbox'])\n",
    "            \n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_gt = gt\n",
    "                best_gt_idx = gt_idx\n",
    "        \n",
    "        # Determinar si es correcto (TP o FP)\n",
    "        is_correct = best_iou >= iou_threshold\n",
    "        \n",
    "        if is_correct and best_gt_idx is not None:\n",
    "            used_gt.add(best_gt_idx)\n",
    "        \n",
    "        matches.append({\n",
    "            'pred': pred,\n",
    "            'gt': best_gt,\n",
    "            'is_correct': is_correct,\n",
    "            'iou': best_iou\n",
    "        })\n",
    "    \n",
    "    return matches\n",
    "\n",
    "print(\"âœ… Funciones auxiliares definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dee5f7",
   "metadata": {},
   "source": [
    "## 4. Inferencia y RecolecciÃ³n de Predicciones con IoU\n",
    "\n",
    "Para RQ8 necesitamos:\n",
    "1. Predicciones del modelo con scores semÃ¡nticos\n",
    "2. IoU de cada predicciÃ³n respecto al ground truth\n",
    "3. Guardar datos para calibraciÃ³n conjunta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2368fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "   INFERENCIA EN VALIDATION SET (val_eval)\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "loading annotations into memory...\n",
      "Done (t=0.54s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "ğŸ“Š Dataset info:\n",
      "   Total imÃ¡genes: 2000\n",
      "   Procesando: 500\n",
      "   CategorÃ­as: 10\n",
      "\n",
      "âœ… Directorio de imÃ¡genes encontrado: ..\\..\\data\\bdd100k\\bdd100k\\bdd100k\\images\\100k\\val\n",
      "Done (t=0.54s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "ğŸ“Š Dataset info:\n",
      "   Total imÃ¡genes: 2000\n",
      "   Procesando: 500\n",
      "   CategorÃ­as: 10\n",
      "\n",
      "âœ… Directorio de imÃ¡genes encontrado: ..\\..\\data\\bdd100k\\bdd100k\\bdd100k\\images\\100k\\val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:   0%|          | 2/500 [00:00<00:31, 15.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 2927: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 4369: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 2506: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:   1%|          | 5/500 [00:00<00:26, 18.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 228: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 1524: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:   2%|â–         | 8/500 [00:00<00:24, 20.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 4438: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 1591: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 3111: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 4223: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 5280: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 4223: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 5280: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:   2%|â–         | 11/500 [00:00<00:23, 20.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 6056: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 8041: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 6622: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:   3%|â–         | 14/500 [00:00<00:22, 21.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 1257: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 6524: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:   3%|â–         | 17/500 [00:00<00:22, 21.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 5922: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 6929: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 6940: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:   4%|â–         | 20/500 [00:00<00:22, 21.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 1512: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 2646: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:   5%|â–         | 23/500 [00:01<00:22, 21.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 3349: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 4905: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 434: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 8165: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 4422: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 8165: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 4422: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:   5%|â–Œ         | 26/500 [00:01<00:22, 21.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 9162: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 1880: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 6951: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:   6%|â–Œ         | 29/500 [00:01<00:22, 21.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 1204: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 9556: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:   6%|â–‹         | 32/500 [00:01<00:21, 21.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 5562: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 9807: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 1013: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:   7%|â–‹         | 35/500 [00:01<00:21, 21.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 1479: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 4479: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:   8%|â–Š         | 38/500 [00:01<00:21, 21.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 5493: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 3878: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 282: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 7905: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 5194: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 7905: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 5194: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:   8%|â–Š         | 41/500 [00:01<00:21, 21.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 7229: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 8751: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 7632: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:   9%|â–‰         | 44/500 [00:02<00:20, 21.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 4703: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 1776: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 5869: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:   9%|â–‰         | 47/500 [00:02<00:20, 22.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 2712: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 7606: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 4254: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:  10%|â–ˆ         | 50/500 [00:02<00:20, 22.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 2662: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 9324: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:  11%|â–ˆ         | 53/500 [00:02<00:20, 22.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 2114: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 1320: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 7912: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:  11%|â–ˆ         | 56/500 [00:02<00:20, 21.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 6511: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 6209: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:  12%|â–ˆâ–        | 59/500 [00:02<00:19, 22.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 9066: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 3346: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 4334: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 6553: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 7251: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 6553: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 7251: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:  12%|â–ˆâ–        | 62/500 [00:02<00:20, 21.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 3612: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 685: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 1527: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:  13%|â–ˆâ–        | 65/500 [00:03<00:19, 22.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 488: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 5310: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:  14%|â–ˆâ–        | 68/500 [00:03<00:19, 22.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 6751: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 8445: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 2969: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:  14%|â–ˆâ–        | 71/500 [00:03<00:19, 22.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 3585: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 5502: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:  15%|â–ˆâ–        | 74/500 [00:03<00:19, 21.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 7498: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 3467: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 5654: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 7075: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 2339: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 7075: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 2339: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:  15%|â–ˆâ–Œ        | 77/500 [00:03<00:18, 22.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 7041: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 2067: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 5848: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:  16%|â–ˆâ–Œ        | 80/500 [00:03<00:18, 22.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 6118: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 8773: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:  17%|â–ˆâ–‹        | 83/500 [00:03<00:18, 22.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 1627: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 822: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 27: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:  17%|â–ˆâ–‹        | 86/500 [00:03<00:19, 21.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 2144: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 5198: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:  18%|â–ˆâ–Š        | 89/500 [00:04<00:18, 22.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 5413: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 8452: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 5692: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 832: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 7144: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 832: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 7144: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:  18%|â–ˆâ–Š        | 92/500 [00:04<00:18, 21.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 3566: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 9530: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 1929: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:  19%|â–ˆâ–‰        | 95/500 [00:04<00:18, 22.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 2621: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 8727: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:  20%|â–ˆâ–‰        | 98/500 [00:04<00:18, 21.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 1275: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 3020: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 4011: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:  20%|â–ˆâ–ˆ        | 101/500 [00:04<00:18, 21.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 3432: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 8930: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:  21%|â–ˆâ–ˆ        | 104/500 [00:04<00:18, 21.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 5873: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 782: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 1874: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 2653: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 2653: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:  21%|â–ˆâ–ˆâ–       | 107/500 [00:04<00:18, 21.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 1592: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 3176: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 1208: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 2842: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:  22%|â–ˆâ–ˆâ–       | 110/500 [00:05<00:17, 21.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 1335: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:  23%|â–ˆâ–ˆâ–       | 113/500 [00:05<00:17, 21.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 5553: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 4471: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 5213: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 9355: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 1099: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 1099: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:  23%|â–ˆâ–ˆâ–       | 116/500 [00:05<00:17, 21.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 605: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 8998: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 153: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:  24%|â–ˆâ–ˆâ–       | 119/500 [00:05<00:19, 19.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 1353: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imÃ¡genes:  24%|â–ˆâ–ˆâ–       | 122/500 [00:05<00:18, 20.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  Error procesando imagen 406: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 6932: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 8115: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 7242: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 3178: name 'model' is not defined\n",
      "\n",
      "âš ï¸  Error procesando imagen 3178: name 'model' is not defined\n"
     ]
    }
   ],
   "source": [
    "# âœ… EJECUTAR PARA RQ8 - Inferencia y matching con ground truth\n",
    "\n",
    "print(\"â•\" * 70)\n",
    "print(\"   INFERENCIA EN VALIDATION SET (val_eval)\")\n",
    "print(\"â•\" * 70)\n",
    "\n",
    "# Cargar anotaciones de validaciÃ³n\n",
    "val_json = DATA_DIR / 'bdd100k_coco' / 'val_eval.json'\n",
    "\n",
    "if not val_json.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"No se encontrÃ³ el archivo de anotaciones: {val_json}\\n\"\n",
    "        \"Verifica que el dataset BDD100K estÃ© correctamente instalado en {DATA_DIR}\"\n",
    "    )\n",
    "\n",
    "coco = COCO(str(val_json))\n",
    "\n",
    "# Mapeo de categorÃ­as BDD100K a IDs COCO\n",
    "cat_name_to_id = {cat['name']: cat['id'] for cat in coco.loadCats(coco.getCatIds())}\n",
    "\n",
    "# Obtener lista de imÃ¡genes\n",
    "img_ids = coco.getImgIds()\n",
    "np.random.shuffle(img_ids)\n",
    "img_ids = img_ids[:CONFIG['sample_size']]\n",
    "\n",
    "print(f\"\\nğŸ“Š Dataset info:\")\n",
    "print(f\"   Total imÃ¡genes: {len(coco.getImgIds())}\")\n",
    "print(f\"   Procesando: {len(img_ids)}\")\n",
    "print(f\"   CategorÃ­as: {len(CONFIG['categories'])}\\n\")\n",
    "\n",
    "# Buscar el directorio de imÃ¡genes en mÃºltiples ubicaciones posibles\n",
    "possible_image_dirs = [\n",
    "    DATA_DIR / 'bdd100k' / 'bdd100k' / 'bdd100k' / 'images' / '100k' / 'val',  # Estructura completa\n",
    "    DATA_DIR / 'bdd100k' / 'bdd100k' / 'images' / '100k' / 'val',              # Sin nivel extra\n",
    "    DATA_DIR / 'bdd100k' / 'images' / '100k' / 'val',                          # Simplificada\n",
    "]\n",
    "\n",
    "image_dir = None\n",
    "for possible_dir in possible_image_dirs:\n",
    "    if possible_dir.exists():\n",
    "        image_dir = possible_dir\n",
    "        print(f\"âœ… Directorio de imÃ¡genes encontrado: {image_dir}\")\n",
    "        break\n",
    "\n",
    "if image_dir is None:\n",
    "    print(f\"\\nâŒ ERROR: No se encontrÃ³ el directorio de imÃ¡genes\")\n",
    "    print(f\"ğŸ” Ubicaciones buscadas:\")\n",
    "    for p in possible_image_dirs:\n",
    "        print(f\"  âŒ {p}\")\n",
    "    raise FileNotFoundError(\n",
    "        f\"Directorio de imÃ¡genes no encontrado.\\n\"\n",
    "        f\"Verifica que las imÃ¡genes de BDD100K estÃ©n en {DATA_DIR}/bdd100k/\"\n",
    "    )\n",
    "\n",
    "# Almacenar predicciones con IoU\n",
    "all_detections = []\n",
    "processed_images = 0\n",
    "skipped_images = 0\n",
    "missing_images = []\n",
    "\n",
    "# Inferencia\n",
    "for img_id in tqdm(img_ids, desc=\"Procesando imÃ¡genes\"):\n",
    "    img_info = coco.loadImgs(img_id)[0]\n",
    "    img_path = image_dir / img_info['file_name']\n",
    "    \n",
    "    if not img_path.exists():\n",
    "        skipped_images += 1\n",
    "        if len(missing_images) < 5:  # Solo guardar las primeras 5 para debugging\n",
    "            missing_images.append(img_info['file_name'])\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Cargar imagen\n",
    "        image_source, image = load_image(str(img_path))\n",
    "        \n",
    "        # PredicciÃ³n\n",
    "        with torch.no_grad():\n",
    "            boxes, logits, phrases = predict(\n",
    "                model=model,\n",
    "                image=image,\n",
    "                caption=TEXT_PROMPT,\n",
    "                box_threshold=CONFIG['conf_threshold'],\n",
    "                text_threshold=0.25,\n",
    "                device=CONFIG['device']\n",
    "            )\n",
    "        \n",
    "        if len(boxes) == 0:\n",
    "            processed_images += 1\n",
    "            continue\n",
    "        \n",
    "        # Convertir boxes a formato COCO [x1, y1, x2, y2]\n",
    "        h, w, _ = image_source.shape\n",
    "        boxes_xyxy = box_ops.box_cxcywh_to_xyxy(boxes) * torch.tensor([w, h, w, h])\n",
    "        boxes_xyxy = boxes_xyxy.cpu().numpy()\n",
    "        scores = logits.cpu().numpy()\n",
    "        \n",
    "        # Preparar predicciones\n",
    "        predictions = []\n",
    "        for box, score, phrase in zip(boxes_xyxy, scores, phrases):\n",
    "            cat = normalize_label(phrase)\n",
    "            if cat not in CONFIG['categories']:\n",
    "                continue\n",
    "            \n",
    "            predictions.append({\n",
    "                'bbox': box.tolist(),\n",
    "                'score': float(score),\n",
    "                'category': cat,\n",
    "                'category_id': cat_name_to_id.get(cat, -1)\n",
    "            })\n",
    "        \n",
    "        if len(predictions) == 0:\n",
    "            processed_images += 1\n",
    "            continue\n",
    "        \n",
    "        # Cargar ground truth\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "        anns = coco.loadAnns(ann_ids)\n",
    "        \n",
    "        gt_annotations = []\n",
    "        for ann in anns:\n",
    "            cat_id = ann['category_id']\n",
    "            cat_name = coco.loadCats(cat_id)[0]['name']\n",
    "            if cat_name not in CONFIG['categories']:\n",
    "                continue\n",
    "            \n",
    "            # Convertir bbox de COCO [x, y, w, h] a [x1, y1, x2, y2]\n",
    "            x, y, bw, bh = ann['bbox']\n",
    "            bbox_xyxy = [x, y, x + bw, y + bh]\n",
    "            \n",
    "            gt_annotations.append({\n",
    "                'bbox': bbox_xyxy,\n",
    "                'category': cat_name,\n",
    "                'category_id': cat_id\n",
    "            })\n",
    "        \n",
    "        # Matchear predicciones con ground truth\n",
    "        matches = match_predictions_to_gt(predictions, gt_annotations, CONFIG['iou_matching'])\n",
    "        \n",
    "        # Guardar detecciones con IoU\n",
    "        for match in matches:\n",
    "            all_detections.append({\n",
    "                'image_id': img_id,\n",
    "                'bbox': match['pred']['bbox'],\n",
    "                'score': match['pred']['score'],\n",
    "                'category': match['pred']['category'],\n",
    "                'category_id': match['pred']['category_id'],\n",
    "                'is_correct': match['is_correct'],\n",
    "                'iou': match['iou'],\n",
    "                'has_gt_match': match['gt'] is not None\n",
    "            })\n",
    "        \n",
    "        processed_images += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâš ï¸  Error procesando imagen {img_id}: {e}\")\n",
    "        skipped_images += 1\n",
    "        continue\n",
    "\n",
    "print(f\"\\nâœ… Inferencia completada\")\n",
    "print(f\"   ImÃ¡genes procesadas: {processed_images}\")\n",
    "print(f\"   ImÃ¡genes omitidas: {skipped_images}\")\n",
    "if missing_images:\n",
    "    print(f\"   Ejemplos de imÃ¡genes no encontradas: {missing_images[:3]}\")\n",
    "print(f\"   Total detecciones: {len(all_detections)}\")\n",
    "\n",
    "if len(all_detections) == 0:\n",
    "    print(\"\\nâŒ ERROR: No se generaron detecciones\")\n",
    "    print(f\"\\nğŸ” DiagnÃ³stico:\")\n",
    "    print(f\"   1. Directorio de imÃ¡genes: {image_dir}\")\n",
    "    print(f\"   2. ImÃ¡genes procesadas: {processed_images}\")\n",
    "    print(f\"   3. ImÃ¡genes omitidas: {skipped_images}\")\n",
    "    print(f\"   4. Threshold de confianza: {CONFIG['conf_threshold']}\")\n",
    "    \n",
    "    if skipped_images == len(img_ids):\n",
    "        print(f\"\\nâš ï¸  TODAS las imÃ¡genes fueron omitidas - problema con las rutas\")\n",
    "        print(f\"   Verifica que las imÃ¡genes existan en: {image_dir}\")\n",
    "    \n",
    "    raise RuntimeError(\n",
    "        \"No se generaron detecciones. Verifica:\\n\"\n",
    "        \"1. Que el modelo estÃ© cargado correctamente\\n\"\n",
    "        \"2. Que las imÃ¡genes existan en el path especificado\\n\"\n",
    "        \"3. Que el threshold de confianza no sea muy alto\\n\"\n",
    "        f\"   Threshold actual: {CONFIG['conf_threshold']}\"\n",
    "    )\n",
    "\n",
    "print(f\"   True Positives: {sum(d['is_correct'] for d in all_detections)}\")\n",
    "print(f\"   False Positives: {sum(not d['is_correct'] for d in all_detections)}\")\n",
    "\n",
    "# Convertir a DataFrame y guardar\n",
    "df_detections = pd.DataFrame(all_detections)\n",
    "df_detections.to_parquet(OUTPUT_DIR / 'detections_raw.parquet', index=False)\n",
    "print(f\"âœ… Detecciones guardadas en: {OUTPUT_DIR / 'detections_raw.parquet'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19894b13",
   "metadata": {},
   "source": [
    "## 5. CalibraciÃ³n Conjunta SemÃ¡ntico-GeomÃ©trica\n",
    "\n",
    "Implementamos tres estrategias de scoring:\n",
    "1. **Raw Score**: Score semÃ¡ntico crudo del modelo (baseline)\n",
    "2. **Temperature Scaling (cls only)**: CalibraciÃ³n solo del score semÃ¡ntico\n",
    "3. **Joint Calibration (cls+loc)**: CalibraciÃ³n conjunta que incorpora la calidad de localizaciÃ³n (IoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d542f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos si existen, sino usar los reciÃ©n generados\n",
    "if (OUTPUT_DIR / 'detections_raw.parquet').exists():\n",
    "    df = pd.read_parquet(OUTPUT_DIR / 'detections_raw.parquet')\n",
    "    print(f\"ğŸ“Š Datos cargados desde archivo: {len(df)} detecciones\")\n",
    "else:\n",
    "    if 'df_detections' in locals():\n",
    "        df = df_detections.copy()\n",
    "        print(f\"ğŸ“Š Usando datos reciÃ©n generados: {len(df)} detecciones\")\n",
    "    else:\n",
    "        raise RuntimeError(\"No se encontraron datos. Ejecuta primero la celda de inferencia (Celda 4)\")\n",
    "\n",
    "print(f\"   TP: {df['is_correct'].sum()}\")\n",
    "print(f\"   FP: {(~df['is_correct']).sum()}\")\n",
    "\n",
    "# Verificar que tenemos datos suficientes\n",
    "if len(df) == 0:\n",
    "    raise ValueError(\"No hay detecciones para procesar. Verifica la inferencia.\")\n",
    "\n",
    "# Convertir scores a logits para calibraciÃ³n\n",
    "# logit = log(score / (1 - score))\n",
    "def score_to_logit(score, epsilon=1e-7):\n",
    "    \"\"\"Convierte score [0, 1] a logit (-inf, inf)\"\"\"\n",
    "    score = np.clip(score, epsilon, 1 - epsilon)\n",
    "    return np.log(score / (1 - score))\n",
    "\n",
    "def logit_to_score(logit):\n",
    "    \"\"\"Convierte logit (-inf, inf) a score [0, 1]\"\"\"\n",
    "    return 1 / (1 + np.exp(-logit))\n",
    "\n",
    "df['logit'] = df['score'].apply(score_to_logit)\n",
    "\n",
    "# === 1. Raw Scores (baseline) ===\n",
    "df['score_raw'] = df['score']\n",
    "\n",
    "# === 2. Temperature Scaling (solo semÃ¡ntica) ===\n",
    "# Optimizar temperatura T minimizando NLL en el conjunto de calibraciÃ³n\n",
    "\n",
    "def nll_loss(T, logits, labels):\n",
    "    \"\"\"Negative Log-Likelihood para calibraciÃ³n de temperatura\"\"\"\n",
    "    scaled_logits = logits / T\n",
    "    probs = logit_to_score(scaled_logits)\n",
    "    probs = np.clip(probs, 1e-7, 1 - 1e-7)\n",
    "    \n",
    "    # NLL: -log(p) si label=1, -log(1-p) si label=0\n",
    "    nll = -np.mean(labels * np.log(probs) + (1 - labels) * np.log(1 - probs))\n",
    "    return nll\n",
    "\n",
    "# Optimizar temperatura\n",
    "logits = df['logit'].values\n",
    "labels = df['is_correct'].astype(int).values\n",
    "\n",
    "print(\"\\nğŸ”§ Optimizando temperatura (semÃ¡ntica only)...\")\n",
    "\n",
    "# Verificar que tenemos suficientes muestras positivas y negativas\n",
    "n_pos = labels.sum()\n",
    "n_neg = len(labels) - n_pos\n",
    "print(f\"   Muestras: {len(labels)} total ({n_pos} TP, {n_neg} FP)\")\n",
    "\n",
    "if n_pos == 0 or n_neg == 0:\n",
    "    print(\"âš ï¸  Warning: Solo hay una clase. Usando T=1.0\")\n",
    "    T_optimal = 1.0\n",
    "else:\n",
    "    try:\n",
    "        result = minimize(\n",
    "            lambda T: nll_loss(T, logits, labels),\n",
    "            x0=1.0,\n",
    "            bounds=[(0.1, 10.0)],\n",
    "            method='L-BFGS-B'\n",
    "        )\n",
    "        T_optimal = result.x[0]\n",
    "        print(f\"âœ… Temperatura Ã³ptima: T = {T_optimal:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Error en optimizaciÃ³n de temperatura: {e}\")\n",
    "        print(f\"âš ï¸  Usando T=1.0 por defecto\")\n",
    "        T_optimal = 1.0\n",
    "\n",
    "# Aplicar temperature scaling\n",
    "df['score_temp'] = logit_to_score(df['logit'] / T_optimal)\n",
    "\n",
    "# === 3. Joint Calibration (semÃ¡ntica + geomÃ©trica) ===\n",
    "# Score calibrado = f(score_semantic, IoU)\n",
    "# Usamos una funciÃ³n que combina ambos: score_joint = score_sem^Î± * IoU^Î²\n",
    "# Optimizamos Î±, Î² para maximizar correlaciÃ³n con correctness\n",
    "\n",
    "def joint_score_function(params, scores, ious):\n",
    "    \"\"\"Calcula score conjunto como combinaciÃ³n ponderada\"\"\"\n",
    "    alpha, beta = params\n",
    "    # Normalizar para que estÃ© en [0, 1]\n",
    "    joint = (scores ** alpha) * (ious ** beta)\n",
    "    return joint\n",
    "\n",
    "def joint_calibration_loss(params, scores, ious, labels):\n",
    "    \"\"\"Loss para calibraciÃ³n conjunta: queremos que el score prediga correctness\"\"\"\n",
    "    joint_scores = joint_score_function(params, scores, ious)\n",
    "    joint_scores = np.clip(joint_scores, 1e-7, 1 - 1e-7)\n",
    "    \n",
    "    # NLL-like loss\n",
    "    loss = -np.mean(labels * np.log(joint_scores) + (1 - labels) * np.log(1 - joint_scores))\n",
    "    return loss\n",
    "\n",
    "print(\"\\nğŸ”§ Optimizando calibraciÃ³n conjunta (semÃ¡ntica + geomÃ©trica)...\")\n",
    "\n",
    "# Usar scores ya calibrados por temperatura como base\n",
    "scores_for_joint = df['score_temp'].values\n",
    "ious = df['iou'].values\n",
    "\n",
    "# Para FP sin GT match, usar IoU mÃ­nimo (evitar divisiÃ³n por cero)\n",
    "ious = np.where(ious == 0, 0.01, ious)\n",
    "\n",
    "# Verificar que tenemos datos vÃ¡lidos\n",
    "if len(scores_for_joint) == 0:\n",
    "    raise ValueError(\"No hay scores para calibraciÃ³n conjunta\")\n",
    "\n",
    "try:\n",
    "    result_joint = minimize(\n",
    "        lambda params: joint_calibration_loss(params, scores_for_joint, ious, labels),\n",
    "        x0=[1.0, 1.0],\n",
    "        bounds=[(0.1, 3.0), (0.1, 3.0)],\n",
    "        method='L-BFGS-B'\n",
    "    )\n",
    "    \n",
    "    alpha_opt, beta_opt = result_joint.x\n",
    "    print(f\"âœ… ParÃ¡metros Ã³ptimos: Î± = {alpha_opt:.4f}, Î² = {beta_opt:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Error en optimizaciÃ³n conjunta: {e}\")\n",
    "    print(f\"âš ï¸  Usando parÃ¡metros por defecto: Î± = 1.0, Î² = 1.0\")\n",
    "    alpha_opt, beta_opt = 1.0, 1.0\n",
    "\n",
    "# Aplicar calibraciÃ³n conjunta\n",
    "df['score_joint'] = joint_score_function([alpha_opt, beta_opt], scores_for_joint, ious)\n",
    "\n",
    "# Guardar parÃ¡metros de calibraciÃ³n\n",
    "calibration_params = {\n",
    "    'temperature': float(T_optimal),\n",
    "    'alpha': float(alpha_opt),\n",
    "    'beta': float(beta_opt),\n",
    "    'n_detections': len(df),\n",
    "    'n_tp': int(df['is_correct'].sum()),\n",
    "    'n_fp': int((~df['is_correct']).sum())\n",
    "}\n",
    "\n",
    "with open(OUTPUT_DIR / 'calibration_params.json', 'w') as f:\n",
    "    json.dump(calibration_params, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ… ParÃ¡metros guardados en: {OUTPUT_DIR / 'calibration_params.json'}\")\n",
    "\n",
    "# Guardar dataframe con scores calibrados\n",
    "df.to_parquet(OUTPUT_DIR / 'detections_calibrated.parquet', index=False)\n",
    "print(f\"âœ… Detecciones con calibraciÃ³n guardadas en: {OUTPUT_DIR / 'detections_calibrated.parquet'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3b63d5",
   "metadata": {},
   "source": [
    "## 6. Tabla RQ8.1 â€” Scoreâ€“IoU Alignment\n",
    "\n",
    "Evaluamos la correlaciÃ³n entre detection score e IoU antes y despuÃ©s de calibraciÃ³n conjunta usando:\n",
    "- **Spearman Ï**: CorrelaciÃ³n de ranking (monotonÃ­a)\n",
    "- **Kendall Ï„**: Concordancia de pares ordenados\n",
    "- **ECE-IoU**: Expected Calibration Error adaptado para IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417f2a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos calibrados\n",
    "calibrated_file = OUTPUT_DIR / 'detections_calibrated.parquet'\n",
    "\n",
    "if not calibrated_file.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"No se encontrÃ³ el archivo de detecciones calibradas: {calibrated_file}\\n\"\n",
    "        \"Por favor ejecuta primero la celda de calibraciÃ³n (Celda 5)\"\n",
    "    )\n",
    "\n",
    "df = pd.read_parquet(calibrated_file)\n",
    "print(f\"âœ… Datos calibrados cargados: {len(df)} detecciones\")\n",
    "\n",
    "def compute_ece_iou(scores, ious, n_bins=10):\n",
    "    \"\"\"\n",
    "    Expected Calibration Error adaptado para IoU:\n",
    "    Mide quÃ© tan bien el score predice el IoU promedio\n",
    "    \"\"\"\n",
    "    # Crear bins por score\n",
    "    bins = np.linspace(0, 1, n_bins + 1)\n",
    "    bin_indices = np.digitize(scores, bins) - 1\n",
    "    bin_indices = np.clip(bin_indices, 0, n_bins - 1)\n",
    "    \n",
    "    ece = 0.0\n",
    "    total_samples = len(scores)\n",
    "    \n",
    "    for i in range(n_bins):\n",
    "        mask = bin_indices == i\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        \n",
    "        # Score promedio en este bin\n",
    "        avg_score = scores[mask].mean()\n",
    "        \n",
    "        # IoU promedio en este bin (lo que realmente observamos)\n",
    "        avg_iou = ious[mask].mean()\n",
    "        \n",
    "        # ECE: diferencia entre score esperado y IoU observado\n",
    "        weight = mask.sum() / total_samples\n",
    "        ece += weight * abs(avg_score - avg_iou)\n",
    "    \n",
    "    return ece\n",
    "\n",
    "# Calcular mÃ©tricas para cada mÃ©todo\n",
    "methods = ['score_raw', 'score_temp', 'score_joint']\n",
    "method_names = ['Raw score', 'Temp-scaled (cls only)', 'Joint calibrated (cls+loc)']\n",
    "\n",
    "results = []\n",
    "\n",
    "for method, method_name in zip(methods, method_names):\n",
    "    scores = df[method].values\n",
    "    ious = df['iou'].values\n",
    "    \n",
    "    # Spearman correlation\n",
    "    spearman_rho, _ = spearmanr(scores, ious)\n",
    "    \n",
    "    # Kendall tau\n",
    "    kendall_tau, _ = kendalltau(scores, ious)\n",
    "    \n",
    "    # ECE-IoU\n",
    "    ece_iou = compute_ece_iou(scores, ious, n_bins=CONFIG['n_bins'])\n",
    "    \n",
    "    results.append({\n",
    "        'Scoring rule': method_name,\n",
    "        'Spearman Ï(score, IoU) â†‘': spearman_rho,\n",
    "        'Kendall Ï„ â†‘': kendall_tau,\n",
    "        'ECE-IoU â†“': ece_iou\n",
    "    })\n",
    "\n",
    "df_table1 = pd.DataFrame(results)\n",
    "\n",
    "# Mostrar tabla\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"   TABLE RQ8.1 â€” Scoreâ€“IoU Alignment\")\n",
    "print(\"=\" * 70)\n",
    "print(df_table1.to_string(index=False))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Guardar tabla\n",
    "df_table1.to_csv(OUTPUT_DIR / 'table_rq8_1_score_iou_alignment.csv', index=False)\n",
    "print(f\"\\nâœ… Tabla guardada en: {OUTPUT_DIR / 'table_rq8_1_score_iou_alignment.csv'}\")\n",
    "\n",
    "# Guardar tambiÃ©n en JSON para fÃ¡cil lectura\n",
    "table1_dict = df_table1.to_dict(orient='records')\n",
    "with open(OUTPUT_DIR / 'table_rq8_1.json', 'w') as f:\n",
    "    json.dump(table1_dict, f, indent=2)\n",
    "print(f\"âœ… Tabla (JSON) guardada en: {OUTPUT_DIR / 'table_rq8_1.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa75bf3",
   "metadata": {},
   "source": [
    "## 7. Figura RQ8.1 â€” Score-IoU Reliability Diagram\n",
    "\n",
    "Visualiza la confiabilidad de los scores respecto a la calidad geomÃ©trica (mean IoU por bin de confianza).\n",
    "La calibraciÃ³n conjunta mejora la alineaciÃ³n monotÃ³nica entre score y precisiÃ³n de localizaciÃ³n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b55925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar reliability diagram: Score vs Mean IoU por bin\n",
    "\n",
    "# Cargar datos calibrados si no estÃ¡n en memoria\n",
    "if 'df' not in locals() or df is None:\n",
    "    calibrated_file = OUTPUT_DIR / 'detections_calibrated.parquet'\n",
    "    if not calibrated_file.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"No se encontrÃ³ el archivo de detecciones calibradas: {calibrated_file}\\n\"\n",
    "            \"Por favor ejecuta primero las celdas anteriores (5-6)\"\n",
    "        )\n",
    "    df = pd.read_parquet(calibrated_file)\n",
    "    print(f\"âœ… Datos cargados: {len(df)} detecciones\")\n",
    "\n",
    "def compute_reliability_data(scores, ious, n_bins=10):\n",
    "    \"\"\"Calcula datos para reliability diagram\"\"\"\n",
    "    bins = np.linspace(0, 1, n_bins + 1)\n",
    "    bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "    bin_indices = np.digitize(scores, bins) - 1\n",
    "    bin_indices = np.clip(bin_indices, 0, n_bins - 1)\n",
    "    \n",
    "    avg_scores = []\n",
    "    avg_ious = []\n",
    "    counts = []\n",
    "    \n",
    "    for i in range(n_bins):\n",
    "        mask = bin_indices == i\n",
    "        if mask.sum() == 0:\n",
    "            avg_scores.append(bin_centers[i])\n",
    "            avg_ious.append(0)\n",
    "            counts.append(0)\n",
    "        else:\n",
    "            avg_scores.append(scores[mask].mean())\n",
    "            avg_ious.append(ious[mask].mean())\n",
    "            counts.append(mask.sum())\n",
    "    \n",
    "    return np.array(avg_scores), np.array(avg_ious), np.array(counts)\n",
    "\n",
    "# Preparar datos para cada mÃ©todo\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "methods = ['score_raw', 'score_temp', 'score_joint']\n",
    "method_names = ['Raw Score', 'Temperature Scaling (cls only)', 'Joint Calibration (cls+loc)']\n",
    "colors = ['#E74C3C', '#F39C12', '#27AE60']\n",
    "markers = ['o', 's', '^']\n",
    "\n",
    "for method, method_name, color, marker in zip(methods, method_names, colors, markers):\n",
    "    scores = df[method].values\n",
    "    ious = df['iou'].values\n",
    "    \n",
    "    avg_scores, avg_ious, counts = compute_reliability_data(scores, ious, n_bins=CONFIG['n_bins'])\n",
    "    \n",
    "    # Plotear con tamaÃ±o proporcional al nÃºmero de muestras\n",
    "    sizes = (counts / counts.max()) * 200 + 50\n",
    "    \n",
    "    ax.scatter(avg_scores, avg_ious, s=sizes, alpha=0.7, \n",
    "              label=method_name, color=color, marker=marker, edgecolors='black', linewidth=1.5)\n",
    "    \n",
    "    # LÃ­nea de conexiÃ³n\n",
    "    ax.plot(avg_scores, avg_ious, color=color, alpha=0.4, linestyle='--', linewidth=1.5)\n",
    "\n",
    "# LÃ­nea de perfecta calibraciÃ³n\n",
    "ax.plot([0, 1], [0, 1], 'k--', alpha=0.3, linewidth=2, label='Perfect Calibration')\n",
    "\n",
    "ax.set_xlabel('Detection Score (Confidence)', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('Mean IoU (Localization Quality)', fontsize=13, fontweight='bold')\n",
    "ax.set_title('Figure RQ8.1. Reliability of Detection Scores vs Geometric Quality\\nJoint Calibration Improves Score-IoU Monotonic Alignment', \n",
    "            fontsize=14, fontweight='bold', pad=20)\n",
    "ax.legend(fontsize=11, loc='lower right', framealpha=0.95)\n",
    "ax.grid(True, alpha=0.3, linestyle=':', linewidth=1)\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(-0.05, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Guardar figura\n",
    "fig.savefig(OUTPUT_DIR / 'Fig_RQ8_1_score_iou_reliability.png', dpi=300, bbox_inches='tight')\n",
    "fig.savefig(OUTPUT_DIR / 'Fig_RQ8_1_score_iou_reliability.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ… Figura RQ8.1 guardada en:\")\n",
    "print(f\"   {OUTPUT_DIR / 'Fig_RQ8_1_score_iou_reliability.png'}\")\n",
    "print(f\"   {OUTPUT_DIR / 'Fig_RQ8_1_score_iou_reliability.pdf'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f580c255",
   "metadata": {},
   "source": [
    "## 8. Tabla RQ8.2 â€” Ranking and Selection Utility\n",
    "\n",
    "Evaluamos mejoras en ranking y selecciÃ³n inducidas por calibraciÃ³n conjunta con presupuesto fijo de propuestas (Top-K).\n",
    "MÃ©tricas:\n",
    "- **Precision@K**: ProporciÃ³n de detecciones correctas en el Top-K\n",
    "- **Mean IoU of selected**: Calidad de localizaciÃ³n promedio del Top-K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d744e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular Precision@K y Mean IoU para diferentes presupuestos\n",
    "\n",
    "# Cargar datos calibrados si no estÃ¡n en memoria\n",
    "if 'df' not in locals() or df is None:\n",
    "    calibrated_file = OUTPUT_DIR / 'detecciones_calibradas.parquet'\n",
    "    if not calibrated_file.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"No se encontrÃ³ el archivo de detecciones calibradas: {calibrated_file}\\n\"\n",
    "            \"Por favor ejecuta primero las celdas anteriores (5-7)\"\n",
    "        )\n",
    "    df = pd.read_parquet(calibrated_file)\n",
    "    print(f\"âœ… Datos cargados: {len(df)} detecciones\")\n",
    "\n",
    "def compute_precision_at_k(scores, labels, k):\n",
    "    \"\"\"Calcula Precision@K: proporciÃ³n de TP en el Top-K\"\"\"\n",
    "    # Ordenar por score descendente\n",
    "    sorted_indices = np.argsort(-scores)\n",
    "    top_k_labels = labels[sorted_indices[:k]]\n",
    "    return top_k_labels.sum() / k\n",
    "\n",
    "def compute_mean_iou_at_k(scores, ious, k):\n",
    "    \"\"\"Calcula Mean IoU del Top-K por score\"\"\"\n",
    "    sorted_indices = np.argsort(-scores)\n",
    "    top_k_ious = ious[sorted_indices[:k]]\n",
    "    return top_k_ious.mean()\n",
    "\n",
    "# Evaluar para cada presupuesto K\n",
    "results = []\n",
    "\n",
    "for k in CONFIG['top_k_values']:\n",
    "    # Asegurar que K no exceda el nÃºmero de detecciones\n",
    "    k_actual = min(k, len(df))\n",
    "    \n",
    "    # Raw scores\n",
    "    prec_raw = compute_precision_at_k(df['score_raw'].values, df['is_correct'].values, k_actual)\n",
    "    iou_raw = compute_mean_iou_at_k(df['score_raw'].values, df['iou'].values, k_actual)\n",
    "    \n",
    "    # Calibrated scores\n",
    "    prec_cal = compute_precision_at_k(df['score_joint'].values, df['is_correct'].values, k_actual)\n",
    "    iou_cal = compute_mean_iou_at_k(df['score_joint'].values, df['iou'].values, k_actual)\n",
    "    \n",
    "    results.append({\n",
    "        'Budget': f'Top-{k}',\n",
    "        'Metric': 'Precision@K â†‘',\n",
    "        'Raw': prec_raw,\n",
    "        'Calibrated': prec_cal\n",
    "    })\n",
    "    \n",
    "    # Solo agregar Mean IoU para el Ãºltimo presupuesto (como en el ejemplo)\n",
    "    if k == CONFIG['top_k_values'][-1]:\n",
    "        results.append({\n",
    "            'Budget': f'Top-{k}',\n",
    "            'Metric': 'Mean IoU of selected â†‘',\n",
    "            'Raw': iou_raw,\n",
    "            'Calibrated': iou_cal\n",
    "        })\n",
    "\n",
    "df_table2 = pd.DataFrame(results)\n",
    "\n",
    "# Mostrar tabla\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"   TABLE RQ8.2 â€” Ranking and Selection Utility\")\n",
    "print(\"=\" * 70)\n",
    "print(df_table2.to_string(index=False))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Guardar tabla\n",
    "df_table2.to_csv(OUTPUT_DIR / 'table_rq8_2_ranking_utility.csv', index=False)\n",
    "print(f\"\\nâœ… Tabla guardada en: {OUTPUT_DIR / 'table_rq8_2_ranking_utility.csv'}\")\n",
    "\n",
    "# Guardar tambiÃ©n en JSON\n",
    "table2_dict = df_table2.to_dict(orient='records')\n",
    "with open(OUTPUT_DIR / 'table_rq8_2.json', 'w') as f:\n",
    "    json.dump(table2_dict, f, indent=2)\n",
    "print(f\"âœ… Tabla (JSON) guardada en: {OUTPUT_DIR / 'table_rq8_2.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2b6ca6",
   "metadata": {},
   "source": [
    "## 9. Figura RQ8.2 â€” Precision@K Curves\n",
    "\n",
    "Visualiza Precision@K para ranking de detecciones bajo scores crudos y calibrados (escala log K).\n",
    "La calibraciÃ³n mejora la calidad del ranking, soportando selecciÃ³n confiable mÃ¡s allÃ¡ del mAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4884e998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar curvas de Precision@K para diferentes valores de K\n",
    "\n",
    "# Cargar datos calibrados si no estÃ¡n en memoria\n",
    "if 'df' not in locals() or df is None:\n",
    "    calibrated_file = OUTPUT_DIR / 'detections_calibrated.parquet'\n",
    "    if not calibrated_file.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"No se encontrÃ³ el archivo de detecciones calibradas: {calibrated_file}\\n\"\n",
    "            \"Por favor ejecuta primero las celdas anteriores (5-8)\"\n",
    "        )\n",
    "    df = pd.read_parquet(calibrated_file)\n",
    "    print(f\"âœ… Datos cargados: {len(df)} detecciones\")\n",
    "\n",
    "# Rango de K valores (escala logarÃ­tmica)\n",
    "k_values = np.unique(np.logspace(1, np.log10(len(df)), 30).astype(int))\n",
    "k_values = k_values[k_values <= len(df)]\n",
    "\n",
    "# Calcular Precision@K para cada mÃ©todo\n",
    "methods = {\n",
    "    'Raw Score': df['score_raw'].values,\n",
    "    'Temperature Scaling': df['score_temp'].values,\n",
    "    'Joint Calibration': df['score_joint'].values\n",
    "}\n",
    "\n",
    "colors = {'Raw Score': '#E74C3C', \n",
    "          'Temperature Scaling': '#F39C12', \n",
    "          'Joint Calibration': '#27AE60'}\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 7))\n",
    "\n",
    "for method_name, scores in methods.items():\n",
    "    precisions = []\n",
    "    \n",
    "    for k in k_values:\n",
    "        prec = compute_precision_at_k(scores, df['is_correct'].values, k)\n",
    "        precisions.append(prec)\n",
    "    \n",
    "    ax.plot(k_values, precisions, marker='o', markersize=5, linewidth=2.5,\n",
    "            label=method_name, color=colors[method_name], alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('K (Number of Top Detections, log-scale)', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('Precision@K', fontsize=13, fontweight='bold')\n",
    "ax.set_title('Figure RQ8.2. Precision@K for Ranking Detections\\nCalibration Improves Ranking Quality Beyond mAP', \n",
    "            fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_xscale('log')\n",
    "ax.grid(True, alpha=0.3, linestyle=':', linewidth=1, which='both')\n",
    "ax.legend(fontsize=12, loc='best', framealpha=0.95)\n",
    "\n",
    "# Marcar los valores especÃ­ficos de la tabla\n",
    "for k in CONFIG['top_k_values']:\n",
    "    if k <= len(df):\n",
    "        ax.axvline(k, color='gray', linestyle='--', alpha=0.3, linewidth=1)\n",
    "        ax.text(k, ax.get_ylim()[1] * 0.98, f'K={k}', \n",
    "               ha='center', va='top', fontsize=9, color='gray')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Guardar figura\n",
    "fig.savefig(OUTPUT_DIR / 'Fig_RQ8_2_precision_at_k.png', dpi=300, bbox_inches='tight')\n",
    "fig.savefig(OUTPUT_DIR / 'Fig_RQ8_2_precision_at_k.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ… Figura RQ8.2 guardada en:\")\n",
    "print(f\"   {OUTPUT_DIR / 'Fig_RQ8_2_precision_at_k.png'}\")\n",
    "print(f\"   {OUTPUT_DIR / 'Fig_RQ8_2_precision_at_k.pdf'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb814d2",
   "metadata": {},
   "source": [
    "## 10. Resumen y VerificaciÃ³n de Resultados\n",
    "\n",
    "VerificaciÃ³n de que todos los archivos esperados se han generado correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0556b57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que todos los archivos se generaron correctamente\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"   VERIFICACIÃ“N DE RESULTADOS RQ8\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Lista de archivos esperados\n",
    "expected_files = {\n",
    "    'ConfiguraciÃ³n': 'config_rq8.yaml',\n",
    "    'ParÃ¡metros de calibraciÃ³n': 'calibration_params.json',\n",
    "    'Detecciones crudas': 'detections_raw.parquet',\n",
    "    'Detecciones calibradas': 'detections_calibrated.parquet',\n",
    "    'Tabla RQ8.1 (CSV)': 'table_rq8_1_score_iou_alignment.csv',\n",
    "    'Tabla RQ8.1 (JSON)': 'table_rq8_1.json',\n",
    "    'Tabla RQ8.2 (CSV)': 'table_rq8_2_ranking_utility.csv',\n",
    "    'Tabla RQ8.2 (JSON)': 'table_rq8_2.json',\n",
    "    'Figura RQ8.1 (PNG)': 'Fig_RQ8_1_score_iou_reliability.png',\n",
    "    'Figura RQ8.1 (PDF)': 'Fig_RQ8_1_score_iou_reliability.pdf',\n",
    "    'Figura RQ8.2 (PNG)': 'Fig_RQ8_2_precision_at_k.png',\n",
    "    'Figura RQ8.2 (PDF)': 'Fig_RQ8_2_precision_at_k.pdf'\n",
    "}\n",
    "\n",
    "all_generated = True\n",
    "missing_files = []\n",
    "\n",
    "print(\"\\nğŸ“ Archivos generados:\")\n",
    "for desc, filename in expected_files.items():\n",
    "    filepath = OUTPUT_DIR / filename\n",
    "    exists = filepath.exists()\n",
    "    status = \"âœ…\" if exists else \"âŒ\"\n",
    "    print(f\"   {status} {desc}: {filename}\")\n",
    "    if not exists:\n",
    "        all_generated = False\n",
    "        missing_files.append(filename)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "if all_generated:\n",
    "    print(\"âœ… TODOS LOS ARCHIVOS GENERADOS CORRECTAMENTE\")\n",
    "else:\n",
    "    print(f\"âš ï¸  ALGUNOS ARCHIVOS NO SE GENERARON: {len(missing_files)} archivos faltantes\")\n",
    "    print(f\"    Archivos faltantes: {', '.join(missing_files)}\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Solo mostrar resumen si los archivos crÃ­ticos existen\n",
    "if (OUTPUT_DIR / 'calibration_params.json').exists():\n",
    "    # Cargar y mostrar resumen de resultados\n",
    "    print(\"\\nğŸ“Š RESUMEN DE RESULTADOS:\")\n",
    "\n",
    "    # ParÃ¡metros de calibraciÃ³n\n",
    "    with open(OUTPUT_DIR / 'calibration_params.json', 'r') as f:\n",
    "        params = json.load(f)\n",
    "\n",
    "    print(f\"\\nğŸ”§ ParÃ¡metros de calibraciÃ³n:\")\n",
    "    print(f\"   Temperatura (T): {params['temperature']:.4f}\")\n",
    "    print(f\"   Alpha (Î±): {params['alpha']:.4f}\")\n",
    "    print(f\"   Beta (Î²): {params['beta']:.4f}\")\n",
    "    print(f\"   Detecciones totales: {params['n_detections']}\")\n",
    "    print(f\"   True Positives: {params['n_tp']}\")\n",
    "    print(f\"   False Positives: {params['n_fp']}\")\n",
    "    \n",
    "    # Tabla 1: Score-IoU Alignment\n",
    "    if (OUTPUT_DIR / 'table_rq8_1_score_iou_alignment.csv').exists():\n",
    "        print(f\"\\nğŸ“Š Tabla RQ8.1 - Score-IoU Alignment:\")\n",
    "        df_t1 = pd.read_csv(OUTPUT_DIR / 'table_rq8_1_score_iou_alignment.csv')\n",
    "        print(df_t1.to_string(index=False))\n",
    "        \n",
    "        # AnÃ¡lisis de mejoras\n",
    "        print(f\"\\nğŸ“ˆ MEJORAS POR CALIBRACIÃ“N CONJUNTA:\")\n",
    "        \n",
    "        # Mejora en correlaciÃ³n Spearman\n",
    "        spearman_raw = df_t1[df_t1['Scoring rule'] == 'Raw score']['Spearman Ï(score, IoU) â†‘'].values[0]\n",
    "        spearman_joint = df_t1[df_t1['Scoring rule'] == 'Joint calibrated (cls+loc)']['Spearman Ï(score, IoU) â†‘'].values[0]\n",
    "        spearman_improvement = ((spearman_joint - spearman_raw) / abs(spearman_raw)) * 100\n",
    "        \n",
    "        print(f\"   Spearman Ï: {spearman_raw:.3f} â†’ {spearman_joint:.3f} ({spearman_improvement:+.1f}%)\")\n",
    "        \n",
    "        # Mejora en ECE-IoU\n",
    "        ece_raw = df_t1[df_t1['Scoring rule'] == 'Raw score']['ECE-IoU â†“'].values[0]\n",
    "        ece_joint = df_t1[df_t1['Scoring rule'] == 'Joint calibrated (cls+loc)']['ECE-IoU â†“'].values[0]\n",
    "        ece_improvement = ((ece_raw - ece_joint) / ece_raw) * 100\n",
    "        \n",
    "        print(f\"   ECE-IoU: {ece_raw:.3f} â†’ {ece_joint:.3f} ({ece_improvement:+.1f}% mejora)\")\n",
    "    \n",
    "    # Tabla 2: Ranking Utility\n",
    "    if (OUTPUT_DIR / 'table_rq8_2_ranking_utility.csv').exists():\n",
    "        print(f\"\\nğŸ“Š Tabla RQ8.2 - Ranking and Selection Utility:\")\n",
    "        df_t2 = pd.read_csv(OUTPUT_DIR / 'table_rq8_2_ranking_utility.csv')\n",
    "        print(df_t2.to_string(index=False))\n",
    "        \n",
    "        # Mejora en Precision@100\n",
    "        prec_100_rows = df_t2[(df_t2['Budget'] == 'Top-100') & (df_t2['Metric'] == 'Precision@K â†‘')]\n",
    "        if len(prec_100_rows) > 0:\n",
    "            prec_100_raw = prec_100_rows['Raw'].values[0]\n",
    "            prec_100_cal = prec_100_rows['Calibrated'].values[0]\n",
    "            prec_100_improvement = ((prec_100_cal - prec_100_raw) / prec_100_raw) * 100\n",
    "            \n",
    "            print(f\"\\n   Precision@100: {prec_100_raw:.3f} â†’ {prec_100_cal:.3f} ({prec_100_improvement:+.1f}%)\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  No se encontraron archivos de resultados. Ejecuta las celdas anteriores primero.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "if all_generated:\n",
    "    print(\"âœ… RQ8 COMPLETADO EXITOSAMENTE\")\n",
    "else:\n",
    "    print(\"âš ï¸  RQ8 INCOMPLETO - Ejecuta las celdas faltantes\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nğŸ“‚ Todos los resultados guardados en: {OUTPUT_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940bbde4",
   "metadata": {},
   "source": [
    "## 11. InterpretaciÃ³n de Resultados\n",
    "\n",
    "### Hallazgos Clave de RQ8:\n",
    "\n",
    "**1. DesalineaciÃ³n Inicial Score-IoU (Tabla RQ8.1)**\n",
    "- Los **scores semÃ¡nticos crudos** muestran correlaciÃ³n dÃ©bil con la calidad de localizaciÃ³n (IoU)\n",
    "- Spearman Ï bajo indica que las detecciones con mayor confianza NO necesariamente tienen mejor localizaciÃ³n\n",
    "- ECE-IoU alto revela que el score no es un buen predictor de la precisiÃ³n geomÃ©trica\n",
    "\n",
    "**2. CalibraciÃ³n Solo SemÃ¡ntica es Insuficiente**\n",
    "- Temperature scaling mejora la calibraciÃ³n de probabilidades, pero la alineaciÃ³n score-IoU mejora poco\n",
    "- La calibraciÃ³n tradicional ignora completamente la calidad de localizaciÃ³n\n",
    "- Necesitamos incorporar informaciÃ³n geomÃ©trica explÃ­citamente\n",
    "\n",
    "**3. CalibraciÃ³n Conjunta Restaura Monotonicidad (Figura RQ8.1)**\n",
    "- La calibraciÃ³n conjunta (cls+loc) logra alineaciÃ³n casi perfecta entre score y IoU promedio\n",
    "- Los bins de mayor confianza ahora tienen consistentemente mayor IoU\n",
    "- Esto es crÃ­tico para aplicaciones que requieren confiabilidad en la localizaciÃ³n (e.g., conducciÃ³n autÃ³noma)\n",
    "\n",
    "**4. Mejoras Sustanciales en Ranking (Tabla RQ8.2, Figura RQ8.2)**\n",
    "- **Precision@K mejora consistentemente** en todos los presupuestos (Top-100, 200, 400)\n",
    "- La mejora es mÃ¡s pronunciada para K pequeÃ±o (donde la selecciÃ³n es mÃ¡s crÃ­tica)\n",
    "- El Mean IoU del Top-400 seleccionado aumenta significativamente\n",
    "- Estas mejoras son **ortogonales al mAP**: el modelo sigue siendo el mismo, pero los scores son mÃ¡s Ãºtiles\n",
    "\n",
    "**5. Implicaciones PrÃ¡cticas**\n",
    "- **Para sistemas de detecciÃ³n en producciÃ³n**: La calibraciÃ³n conjunta permite:\n",
    "  - Seleccionar propuestas mÃ¡s confiables dado un presupuesto computacional\n",
    "  - Ranking mÃ¡s confiable para post-procesamiento\n",
    "  - Detecciones mejor localizadas en escenarios de alta confianza\n",
    "  \n",
    "- **Para aplicaciones crÃ­ticas**: Cuando la localizaciÃ³n precisa es esencial (e.g., evitar colisiones), usar scores calibrados conjuntamente reduce el riesgo de confiar en detecciones mal localizadas\n",
    "\n",
    "**6. Respuesta a RQ8**\n",
    "> *\"How can semantic confidence and localization quality be jointly calibrated to yield meaningful scores for ranking/selection?\"*\n",
    "\n",
    "âœ… **Respuesta**: Mediante optimizaciÃ³n conjunta de una funciÃ³n que combina scores semÃ¡nticos calibrados y calidad de localizaciÃ³n (IoU), podemos restaurar la monotonicidad entre confianza y precisiÃ³n geomÃ©trica. Esto mejora mÃ©tricas de ranking (Precision@K, Mean IoU selected) sin cambiar el mAP, proporcionando scores mÃ¡s Ãºtiles para selecciÃ³n reliability-aware en aplicaciones downstream."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc2d06d",
   "metadata": {},
   "source": [
    "## 12. Instrucciones de EjecuciÃ³n\n",
    "\n",
    "### ğŸ“‹ Orden de EjecuciÃ³n de Celdas\n",
    "\n",
    "Este notebook estÃ¡ diseÃ±ado para ejecutarse secuencialmente. Las celdas marcadas con **\"âœ… EJECUTAR PARA RQ8\"** son las mÃ¡s importantes:\n",
    "\n",
    "1. **Celda 1**: ConfiguraciÃ³n e Imports\n",
    "2. **Celda 2**: Cargar Modelo GroundingDINO â† **EJECUTAR PARA RQ8**\n",
    "3. **Celda 3**: Funciones Auxiliares\n",
    "4. **Celda 4**: Inferencia y RecolecciÃ³n de Predicciones con IoU â† **EJECUTAR PARA RQ8** (tiempo: ~30-45 min para 500 imÃ¡genes)\n",
    "5. **Celda 5**: CalibraciÃ³n Conjunta SemÃ¡ntico-GeomÃ©trica\n",
    "6. **Celda 6**: Tabla RQ8.1 â€” Scoreâ€“IoU Alignment\n",
    "7. **Celda 7**: Figura RQ8.1 â€” Score-IoU Reliability Diagram\n",
    "8. **Celda 8**: Tabla RQ8.2 â€” Ranking and Selection Utility\n",
    "9. **Celda 9**: Figura RQ8.2 â€” Precision@K Curves\n",
    "10. **Celda 10**: Resumen y VerificaciÃ³n de Resultados\n",
    "11. **Celda 11**: InterpretaciÃ³n de Resultados (solo lectura)\n",
    "\n",
    "### âš ï¸ Notas Importantes\n",
    "\n",
    "- **Tiempo total estimado**: ~45-60 minutos para 500 imÃ¡genes\n",
    "- **GPU requerida**: El modelo GroundingDINO requiere GPU para inferencia eficiente\n",
    "- **Dependencias**: Todas las librerÃ­as necesarias estÃ¡n importadas en la Celda 1\n",
    "- **Paths relativos**: Todo usa paths relativos desde `New_RQ/new_rq8/`\n",
    "- **Reproducibilidad**: Seeds fijadas para resultados reproducibles\n",
    "\n",
    "### ğŸ“Š Archivos Generados\n",
    "\n",
    "Al completar la ejecuciÃ³n, encontrarÃ¡s en `./output/`:\n",
    "- âœ… 2 figuras (PNG + PDF cada una)\n",
    "- âœ… 2 tablas (CSV + JSON cada una)\n",
    "- âœ… Datos intermedios (parquet) para anÃ¡lisis posterior\n",
    "- âœ… ParÃ¡metros de calibraciÃ³n (JSON)\n",
    "\n",
    "### ğŸ”„ Re-ejecuciÃ³n\n",
    "\n",
    "Si necesitas re-ejecutar:\n",
    "- Las celdas 1-3 son rÃ¡pidas y seguras de re-ejecutar\n",
    "- La celda 4 (inferencia) es la mÃ¡s costosa (~45 min). Si ya tienes `detections_raw.parquet`, puedes saltarla\n",
    "- Las celdas 5-10 son rÃ¡pidas (<5 min total) y pueden re-ejecutarse sin problema"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
