{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d23ea508",
   "metadata": {},
   "source": [
    "# RQ9 — Robustez y Límites de Estabilidad bajo Distribution Shift\n",
    "\n",
    "## Research Question\n",
    "\n",
    "**¿Qué componentes se degradan primero bajo cambios semánticos/sensoriales, y qué revela esto sobre los límites de confiabilidad post-hoc?**\n",
    "\n",
    "**Hipótesis**: La calibración (ECE) se rompe antes que el ranking basado en incertidumbre (AURC). Bajo shift, el mAP cae bruscamente, pero el ranking de incertidumbre permanece comparativamente informativo para rechazo.\n",
    "\n",
    "---\n",
    "\n",
    "## Expected Results\n",
    "\n",
    "### Figuras\n",
    "- **Figure RQ9.1**: Degradación de métricas con severidad de shift creciente (ECE crece más rápido que AURC)\n",
    "- **Figure RQ9.2**: Colapso de precisión (mAP) bajo shift creciente\n",
    "\n",
    "### Tablas\n",
    "- **Table RQ9.1**: Resumen de stress test bajo shift controlado\n",
    "- **Table RQ9.2**: Ablación de componentes bajo shift\n",
    "\n",
    "---\n",
    "\n",
    "## Metodología\n",
    "\n",
    "1. **Simular Distribution Shifts**: Aplicar perturbaciones de severidad creciente (blur, noise, brightness)\n",
    "2. **Evaluar en cada nivel**: mAP, ECE, AURC, Risk@80% coverage\n",
    "3. **Análisis de componentes**: Temperature scaling, IoU mapping, late-layer variance, fusion\n",
    "4. **Generar visualizaciones**: Curvas de degradación y tablas comparativas\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539f09b4",
   "metadata": {},
   "source": [
    "## 1. Configuración e Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41210fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuración RQ9\n",
      "   Device: cuda\n",
      "   Output: output\n",
      "   Shift levels: [0.0, 0.2, 0.4, 0.6, 0.8]\n",
      "   Sample size: 500\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageFilter, ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from sklearn.metrics import auc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración\n",
    "BASE_DIR = Path('../..')\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "OUTPUT_DIR = Path('./output')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CONFIG = {\n",
    "    'seed': 42,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'categories': ['person', 'rider', 'car', 'truck', 'bus', 'train', 'motorcycle', 'bicycle', 'traffic light', 'traffic sign'],\n",
    "    'shift_levels': [0.0, 0.2, 0.4, 0.6, 0.8],  # Severidad de shift\n",
    "    'n_bins': 15,\n",
    "    'iou_threshold': 0.5,\n",
    "    'conf_threshold': 0.25,\n",
    "    'sample_size': 500,  # Imágenes a evaluar\n",
    "    'perturbation_types': ['blur', 'noise', 'brightness', 'contrast']\n",
    "}\n",
    "\n",
    "torch.manual_seed(CONFIG['seed'])\n",
    "np.random.seed(CONFIG['seed'])\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(CONFIG['seed'])\n",
    "\n",
    "with open(OUTPUT_DIR / 'config_rq9.yaml', 'w') as f:\n",
    "    yaml.dump(CONFIG, f)\n",
    "\n",
    "print(f\"✅ Configuración RQ9\")\n",
    "print(f\"   Device: {CONFIG['device']}\")\n",
    "print(f\"   Output: {OUTPUT_DIR}\")\n",
    "print(f\"   Shift levels: {CONFIG['shift_levels']}\")\n",
    "print(f\"   Sample size: {CONFIG['sample_size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88767d51",
   "metadata": {},
   "source": [
    "## 2. Cargar Modelo y Resultados Previos\n",
    "\n",
    "⚠️ **Nota**: Necesitamos cargar resultados de fases anteriores para obtener:\n",
    "- Temperaturas optimizadas (Fase 4)\n",
    "- Incertidumbre MC Dropout (Fase 3)\n",
    "- Incertidumbre determinística del decoder (RQ6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b581bb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n",
      "✅ Modelo cargado en cuda\n",
      "   Prompt: person. rider. car. truck. bus. train. motorcycle. bicycle. traffic light. traffic sign.\n",
      "   Módulos dropout identificados: 0\n"
     ]
    }
   ],
   "source": [
    "# ✅ EJECUTAR PARA RQ9 - Cargar modelo GroundingDINO\n",
    "\n",
    "from groundingdino.util.inference import load_model, load_image, predict\n",
    "from groundingdino.util import box_ops\n",
    "\n",
    "model_config = '/opt/program/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py'\n",
    "model_weights = '/opt/program/GroundingDINO/weights/groundingdino_swint_ogc.pth'\n",
    "\n",
    "model = load_model(model_config, model_weights)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "TEXT_PROMPT = '. '.join(CONFIG['categories']) + '.'\n",
    "\n",
    "print(f\"✅ Modelo cargado en {CONFIG['device']}\")\n",
    "print(f\"   Prompt: {TEXT_PROMPT}\")\n",
    "\n",
    "# Identificar módulos dropout para MC-Dropout\n",
    "dropout_modules = []\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Dropout) and ('class_embed' in name or 'bbox_embed' in name):\n",
    "        dropout_modules.append(module)\n",
    "\n",
    "print(f\"   Módulos dropout identificados: {len(dropout_modules)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c88e201f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Temperatura optimizada cargada: T = 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Cargar temperatura optimizada de Fase 4\n",
    "TEMPERATURE_FILE = BASE_DIR / 'fase 4' / 'outputs' / 'temperature_scaling' / 'temperature.json'\n",
    "\n",
    "if TEMPERATURE_FILE.exists():\n",
    "    with open(TEMPERATURE_FILE, 'r') as f:\n",
    "        temp_data = json.load(f)\n",
    "        OPTIMAL_TEMPERATURE = temp_data.get('optimal_temperature', 1.0)\n",
    "    print(f\"✅ Temperatura optimizada cargada: T = {OPTIMAL_TEMPERATURE:.4f}\")\n",
    "else:\n",
    "    OPTIMAL_TEMPERATURE = 1.0\n",
    "    print(f\"⚠️  No se encontró temperatura optimizada, usando T = 1.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1be795",
   "metadata": {},
   "source": [
    "## 3. Funciones para Simulación de Distribution Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87af8578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Funciones de perturbación definidas\n"
     ]
    }
   ],
   "source": [
    "def apply_distribution_shift(image, severity=0.0):\n",
    "    \"\"\"\n",
    "    Aplica perturbaciones para simular distribution shift.\n",
    "    \n",
    "    Args:\n",
    "        image: PIL Image\n",
    "        severity: 0.0 (sin shift) a 1.0 (shift máximo)\n",
    "    \n",
    "    Returns:\n",
    "        PIL Image perturbada\n",
    "    \"\"\"\n",
    "    if severity == 0.0:\n",
    "        return image\n",
    "    \n",
    "    # Combinación de perturbaciones\n",
    "    \n",
    "    # 1. Blur gaussiano (aumenta con severidad)\n",
    "    radius = severity * 5.0  # 0 a 5 píxeles\n",
    "    if radius > 0:\n",
    "        image = image.filter(ImageFilter.GaussianBlur(radius=radius))\n",
    "    \n",
    "    # 2. Ruido gaussiano\n",
    "    if severity > 0:\n",
    "        img_array = np.array(image).astype(np.float32)\n",
    "        noise_std = severity * 25.0  # 0 a 25 de std\n",
    "        noise = np.random.normal(0, noise_std, img_array.shape)\n",
    "        img_array = np.clip(img_array + noise, 0, 255)\n",
    "        image = Image.fromarray(img_array.astype(np.uint8))\n",
    "    \n",
    "    # 3. Cambio de brillo\n",
    "    brightness_factor = 1.0 - severity * 0.4  # Reducir brillo hasta 60%\n",
    "    enhancer = ImageEnhance.Brightness(image)\n",
    "    image = enhancer.enhance(brightness_factor)\n",
    "    \n",
    "    # 4. Cambio de contraste\n",
    "    contrast_factor = 1.0 - severity * 0.3  # Reducir contraste hasta 70%\n",
    "    enhancer = ImageEnhance.Contrast(image)\n",
    "    image = enhancer.enhance(contrast_factor)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def compute_iou(box1, box2):\n",
    "    \"\"\"Calcula IoU entre dos boxes [x1, y1, x2, y2]\"\"\"\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "    inter = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union = area1 + area2 - inter\n",
    "    return inter / union if union > 0 else 0.0\n",
    "\n",
    "def normalize_label(label):\n",
    "    \"\"\"Normaliza etiquetas del modelo\"\"\"\n",
    "    synonyms = {\n",
    "        'bike': 'bicycle', 'motorbike': 'motorcycle', \n",
    "        'pedestrian': 'person', 'stop sign': 'traffic sign', \n",
    "        'red light': 'traffic light'\n",
    "    }\n",
    "    label_lower = label.lower().strip()\n",
    "    if label_lower in synonyms:\n",
    "        return synonyms[label_lower]\n",
    "    for cat in CONFIG['categories']:\n",
    "        if cat in label_lower:\n",
    "            return cat\n",
    "    return label_lower\n",
    "\n",
    "print(\"✅ Funciones de perturbación definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77754dcc",
   "metadata": {},
   "source": [
    "## 4. Inferencia con Distribution Shift\n",
    "\n",
    "Vamos a ejecutar el modelo en imágenes con diferentes niveles de perturbación y capturar:\n",
    "- Predicciones baseline\n",
    "- Incertidumbre MC Dropout\n",
    "- Incertidumbre del decoder (varianza inter-capa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5827d01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Hooks registrados en 6 capas del decoder\n",
      "✅ Función de inferencia con incertidumbre definida\n"
     ]
    }
   ],
   "source": [
    "# ✅ EJECUTAR PARA RQ9 - Función de inferencia con captura de capas del decoder\n",
    "\n",
    "layer_outputs = {}\n",
    "\n",
    "def hook_fn(name):\n",
    "    def hook(module, input, output):\n",
    "        # Capturar la salida del decoder layer\n",
    "        if isinstance(output, tuple):\n",
    "            layer_outputs[name] = output[0].detach() if hasattr(output[0], 'detach') else output[0]\n",
    "        else:\n",
    "            layer_outputs[name] = output.detach() if hasattr(output, 'detach') else output\n",
    "    return hook\n",
    "\n",
    "# Registrar hooks en el decoder\n",
    "hooks = []\n",
    "decoder_layers = []\n",
    "\n",
    "# Buscar las capas del decoder en la arquitectura\n",
    "for name, module in model.named_modules():\n",
    "    if 'decoder.layers' in name and name.count('.') == 3:\n",
    "        layer_num = name.split('.')[-1]\n",
    "        if layer_num.isdigit():\n",
    "            decoder_layers.append((int(layer_num), name, module))\n",
    "\n",
    "decoder_layers.sort(key=lambda x: x[0])\n",
    "\n",
    "for layer_idx, layer_name, layer_module in decoder_layers:\n",
    "    hook = layer_module.register_forward_hook(hook_fn(f'decoder_layer_{layer_idx}'))\n",
    "    hooks.append(hook)\n",
    "\n",
    "print(f\"✅ Hooks registrados en {len(hooks)} capas del decoder\")\n",
    "\n",
    "def run_inference_with_uncertainty(image_pil, text_prompt, box_threshold=0.25, text_threshold=0.25):\n",
    "    \"\"\"\n",
    "    Ejecuta inferencia con captura de incertidumbre epistémica.\n",
    "    \n",
    "    Returns:\n",
    "        dict con:\n",
    "        - boxes: [N, 4] en formato xyxy\n",
    "        - logits: [N] scores originales\n",
    "        - phrases: [N] etiquetas\n",
    "        - decoder_variance: [N] varianza inter-capa del decoder\n",
    "    \"\"\"\n",
    "    layer_outputs.clear()\n",
    "    \n",
    "    # Inferencia baseline\n",
    "    boxes, logits, phrases = predict(\n",
    "        model=model,\n",
    "        image=image_pil,\n",
    "        caption=text_prompt,\n",
    "        box_threshold=box_threshold,\n",
    "        text_threshold=text_threshold\n",
    "    )\n",
    "    \n",
    "    if len(boxes) == 0:\n",
    "        return {\n",
    "            'boxes': np.array([]),\n",
    "            'logits': np.array([]),\n",
    "            'phrases': [],\n",
    "            'decoder_variance': np.array([])\n",
    "        }\n",
    "    \n",
    "    # Calcular varianza inter-capa del decoder\n",
    "    decoder_variances = []\n",
    "    n_detections = boxes.shape[0]\n",
    "    n_layers = len([k for k in layer_outputs.keys() if 'decoder_layer' in k])\n",
    "    \n",
    "    if n_layers > 0:\n",
    "        # Extraer scores por capa\n",
    "        layer_scores = []\n",
    "        for i in range(n_layers):\n",
    "            layer_key = f'decoder_layer_{i}'\n",
    "            if layer_key in layer_outputs:\n",
    "                # Usar norma del embedding como proxy de score\n",
    "                layer_emb = layer_outputs[layer_key]\n",
    "                # layer_emb puede tener shape [num_queries, batch, embed_dim] o [batch, num_queries, embed_dim]\n",
    "                if len(layer_emb.shape) == 3:\n",
    "                    # Intentar ambos formatos\n",
    "                    if layer_emb.shape[1] == 1:  # [num_queries, 1, dim]\n",
    "                        layer_score = torch.norm(layer_emb[:n_detections, 0, :], dim=-1)\n",
    "                    else:  # [1, num_queries, dim]\n",
    "                        layer_score = torch.norm(layer_emb[0, :n_detections, :], dim=-1)\n",
    "                    layer_scores.append(layer_score.cpu().numpy())\n",
    "        \n",
    "        if len(layer_scores) > 0:\n",
    "            layer_scores = np.array(layer_scores)  # [n_layers, n_detections]\n",
    "            decoder_variances = np.var(layer_scores, axis=0)  # [n_detections]\n",
    "        else:\n",
    "            decoder_variances = np.zeros(n_detections)\n",
    "    else:\n",
    "        decoder_variances = np.zeros(n_detections)\n",
    "    \n",
    "    return {\n",
    "        'boxes': boxes.cpu().numpy(),\n",
    "        'logits': logits.cpu().numpy(),\n",
    "        'phrases': phrases,\n",
    "        'decoder_variance': decoder_variances\n",
    "    }\n",
    "\n",
    "print(\"✅ Función de inferencia con incertidumbre definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58f93587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Función MC-Dropout definida\n"
     ]
    }
   ],
   "source": [
    "def run_mc_dropout_inference(image_pil, text_prompt, K=5, box_threshold=0.25):\n",
    "    \"\"\"\n",
    "    Ejecuta K pases estocásticos con MC-Dropout.\n",
    "    \n",
    "    Returns:\n",
    "        dict con:\n",
    "        - boxes: [N, 4] boxes promediadas\n",
    "        - logits: [N] scores promediados\n",
    "        - phrases: [N] etiquetas\n",
    "        - mc_variance: [N] varianza de scores entre pases\n",
    "    \"\"\"\n",
    "    # Activar dropout\n",
    "    for module in dropout_modules:\n",
    "        module.train()\n",
    "    \n",
    "    all_detections = []\n",
    "    \n",
    "    for k in range(K):\n",
    "        result = run_inference_with_uncertainty(image_pil, text_prompt, box_threshold)\n",
    "        if len(result['boxes']) > 0:\n",
    "            all_detections.append(result)\n",
    "    \n",
    "    # Desactivar dropout\n",
    "    for module in dropout_modules:\n",
    "        module.eval()\n",
    "    \n",
    "    if len(all_detections) == 0:\n",
    "        return {\n",
    "            'boxes': np.array([]),\n",
    "            'logits': np.array([]),\n",
    "            'phrases': [],\n",
    "            'mc_variance': np.array([]),\n",
    "            'decoder_variance': np.array([])\n",
    "        }\n",
    "    \n",
    "    # Alinear detecciones entre pases y calcular varianza\n",
    "    # Simplificación: usar primer pase como referencia\n",
    "    ref_boxes = all_detections[0]['boxes']\n",
    "    ref_logits = all_detections[0]['logits']\n",
    "    ref_phrases = all_detections[0]['phrases']\n",
    "    \n",
    "    mc_variances = []\n",
    "    for i in range(len(ref_boxes)):\n",
    "        scores_across_passes = [all_detections[0]['logits'][i]]\n",
    "        \n",
    "        # Buscar matches en otros pases\n",
    "        for det in all_detections[1:]:\n",
    "            best_iou = 0\n",
    "            best_score = ref_logits[i]\n",
    "            for j, box in enumerate(det['boxes']):\n",
    "                iou = compute_iou(ref_boxes[i], box)\n",
    "                if iou > 0.5:  # Umbral de matching\n",
    "                    if iou > best_iou:\n",
    "                        best_iou = iou\n",
    "                        best_score = det['logits'][j]\n",
    "            scores_across_passes.append(best_score)\n",
    "        \n",
    "        mc_variances.append(np.var(scores_across_passes))\n",
    "    \n",
    "    return {\n",
    "        'boxes': ref_boxes,\n",
    "        'logits': ref_logits,\n",
    "        'phrases': ref_phrases,\n",
    "        'mc_variance': np.array(mc_variances),\n",
    "        'decoder_variance': all_detections[0]['decoder_variance']\n",
    "    }\n",
    "\n",
    "print(\"✅ Función MC-Dropout definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd605b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.33s)\n",
      "creating index...\n",
      "index created!\n",
      "✅ Procesando 500 imágenes con 5 niveles de shift\n",
      "   Esto puede tomar ~30-60 minutos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes: 100%|██████████| 500/500 [00:00<00:00, 880.54it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'is_tp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 111\u001b[0m\n\u001b[1;32m    109\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[1;32m    110\u001b[0m     dfs_by_shift[severity] \u001b[38;5;241m=\u001b[39m df\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Shift \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseverity\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m detecciones (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_tp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m TP, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(\u001b[38;5;241m~\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_tp\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m FP)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Guardar resultados\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m severity, df \u001b[38;5;129;01min\u001b[39;00m dfs_by_shift\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:4113\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4113\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4115\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'is_tp'"
     ]
    }
   ],
   "source": [
    "# ✅ EJECUTAR PARA RQ9 - Procesar dataset con diferentes niveles de shift\n",
    "\n",
    "# Cargar anotaciones\n",
    "coco_file = DATA_DIR / 'bdd100k_coco' / 'val_eval.json'\n",
    "coco = COCO(str(coco_file))\n",
    "\n",
    "# Mapeo de categorías\n",
    "cat_name_to_id = {cat: idx + 1 for idx, cat in enumerate(CONFIG['categories'])}\n",
    "\n",
    "# Seleccionar subset de imágenes\n",
    "all_img_ids = list(coco.imgs.keys())\n",
    "np.random.seed(CONFIG['seed'])\n",
    "sample_img_ids = np.random.choice(all_img_ids, min(CONFIG['sample_size'], len(all_img_ids)), replace=False)\n",
    "\n",
    "print(f\"✅ Procesando {len(sample_img_ids)} imágenes con {len(CONFIG['shift_levels'])} niveles de shift\")\n",
    "print(f\"   Esto puede tomar ~30-60 minutos...\")\n",
    "\n",
    "# Diccionario para almacenar resultados\n",
    "results_by_shift = {severity: [] for severity in CONFIG['shift_levels']}\n",
    "\n",
    "for img_id in tqdm(sample_img_ids, desc=\"Procesando imágenes\"):\n",
    "    img_info = coco.imgs[img_id]\n",
    "    img_path = DATA_DIR / 'bdd100k' / 'bdd100k' / 'images' / '10k' / 'val' / img_info['file_name']\n",
    "    \n",
    "    if not img_path.exists():\n",
    "        continue\n",
    "    \n",
    "    # Cargar imagen original\n",
    "    try:\n",
    "        img_original = Image.open(img_path).convert('RGB')\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # Obtener ground truth\n",
    "    ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "    \n",
    "    gt_boxes = []\n",
    "    gt_labels = []\n",
    "    for ann in anns:\n",
    "        bbox_xywh = ann['bbox']\n",
    "        bbox_xyxy = [bbox_xywh[0], bbox_xywh[1], \n",
    "                     bbox_xywh[0] + bbox_xywh[2], \n",
    "                     bbox_xywh[1] + bbox_xywh[3]]\n",
    "        cat_name = coco.cats[ann['category_id']]['name']\n",
    "        \n",
    "        if cat_name in CONFIG['categories']:\n",
    "            gt_boxes.append(bbox_xyxy)\n",
    "            gt_labels.append(cat_name)\n",
    "    \n",
    "    if len(gt_boxes) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Procesar con cada nivel de shift\n",
    "    for severity in CONFIG['shift_levels']:\n",
    "        # Aplicar perturbación\n",
    "        img_shifted = apply_distribution_shift(img_original, severity)\n",
    "        \n",
    "        # Inferencia baseline + decoder variance\n",
    "        pred_baseline = run_inference_with_uncertainty(img_shifted, TEXT_PROMPT)\n",
    "        \n",
    "        # Inferencia MC Dropout\n",
    "        pred_mc = run_mc_dropout_inference(img_shifted, TEXT_PROMPT, K=5)\n",
    "        \n",
    "        # Almacenar predicciones con matching a GT\n",
    "        for i in range(len(pred_baseline['boxes'])):\n",
    "            pred_box = pred_baseline['boxes'][i]\n",
    "            pred_score = float(pred_baseline['logits'][i])\n",
    "            pred_label = normalize_label(pred_baseline['phrases'][i])\n",
    "            decoder_var = float(pred_baseline['decoder_variance'][i])\n",
    "            \n",
    "            # Buscar MC variance para esta detección\n",
    "            mc_var = 0.0\n",
    "            if i < len(pred_mc.get('mc_variance', [])):\n",
    "                mc_var = float(pred_mc['mc_variance'][i])\n",
    "            \n",
    "            # Buscar mejor match con GT\n",
    "            best_iou = 0.0\n",
    "            best_gt_label = None\n",
    "            for j, gt_box in enumerate(gt_boxes):\n",
    "                iou = compute_iou(pred_box, gt_box)\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_gt_label = gt_labels[j]\n",
    "            \n",
    "            is_tp = (best_iou >= CONFIG['iou_threshold'] and pred_label == best_gt_label)\n",
    "            \n",
    "            # Calcular score calibrado con temperatura\n",
    "            score_clipped = np.clip(pred_score, 1e-7, 1 - 1e-7)\n",
    "            logit = np.log(score_clipped / (1 - score_clipped))\n",
    "            calibrated_score = 1 / (1 + np.exp(-logit / OPTIMAL_TEMPERATURE))\n",
    "            \n",
    "            results_by_shift[severity].append({\n",
    "                'image_id': img_id,\n",
    "                'severity': severity,\n",
    "                'pred_score': pred_score,\n",
    "                'calibrated_score': calibrated_score,\n",
    "                'decoder_variance': decoder_var,\n",
    "                'mc_variance': mc_var,\n",
    "                'is_tp': is_tp,\n",
    "                'iou': best_iou,\n",
    "                'pred_label': pred_label,\n",
    "                'gt_label': best_gt_label\n",
    "            })\n",
    "\n",
    "# Convertir a DataFrames\n",
    "dfs_by_shift = {}\n",
    "for severity, data in results_by_shift.items():\n",
    "    df = pd.DataFrame(data)\n",
    "    dfs_by_shift[severity] = df\n",
    "    print(f\"✅ Shift {severity}: {len(df)} detecciones ({df['is_tp'].sum()} TP, {(~df['is_tp']).sum()} FP)\")\n",
    "\n",
    "# Guardar resultados\n",
    "for severity, df in dfs_by_shift.items():\n",
    "    df.to_parquet(OUTPUT_DIR / f'predictions_shift_{severity}.parquet', index=False)\n",
    "\n",
    "print(f\"\\n✅ Inferencia completada y guardada en {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cbbf6a",
   "metadata": {},
   "source": [
    "## 5. Cálculo de Métricas por Nivel de Shift\n",
    "\n",
    "Calculamos para cada nivel de shift:\n",
    "- **mAP**: Mean Average Precision\n",
    "- **ECE**: Expected Calibration Error\n",
    "- **AURC**: Area Under Risk-Coverage curve\n",
    "- **Risk@80% coverage**: Error rate cuando se cubre 80% de las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "864dd000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Funciones de métricas definidas\n"
     ]
    }
   ],
   "source": [
    "# Funciones de cálculo de métricas\n",
    "\n",
    "def compute_ece(df, score_col='calibrated_score', n_bins=15):\n",
    "    \"\"\"Calcula Expected Calibration Error\"\"\"\n",
    "    df = df.copy()\n",
    "    df['bin'] = pd.cut(df[score_col], bins=n_bins, labels=False)\n",
    "    \n",
    "    ece = 0.0\n",
    "    for bin_idx in range(n_bins):\n",
    "        bin_data = df[df['bin'] == bin_idx]\n",
    "        if len(bin_data) == 0:\n",
    "            continue\n",
    "        \n",
    "        avg_conf = bin_data[score_col].mean()\n",
    "        avg_acc = bin_data['is_tp'].mean()\n",
    "        weight = len(bin_data) / len(df)\n",
    "        \n",
    "        ece += weight * abs(avg_conf - avg_acc)\n",
    "    \n",
    "    return ece\n",
    "\n",
    "def compute_aurc(df, uncertainty_col='decoder_variance'):\n",
    "    \"\"\"Calcula Area Under Risk-Coverage curve\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ordenar por incertidumbre ASCENDENTE (menor incertidumbre primero)\n",
    "    df = df.sort_values(uncertainty_col, ascending=True)\n",
    "    \n",
    "    coverages = []\n",
    "    risks = []\n",
    "    \n",
    "    n_total = len(df)\n",
    "    \n",
    "    # Calcular riesgo en cada punto de cobertura\n",
    "    for i in range(1, n_total + 1):\n",
    "        coverage = i / n_total\n",
    "        # Retenemos las primeras i detecciones (menor incertidumbre)\n",
    "        retained_data = df.iloc[:i]\n",
    "        risk = 1 - retained_data['is_tp'].mean()  # Error rate\n",
    "        \n",
    "        coverages.append(coverage)\n",
    "        risks.append(risk)\n",
    "    \n",
    "    # Calcular AUC usando trapezoides\n",
    "    aurc = auc(coverages, risks)\n",
    "    return aurc, coverages, risks\n",
    "\n",
    "def compute_risk_at_coverage(df, uncertainty_col='decoder_variance', target_coverage=0.8):\n",
    "    \"\"\"Calcula el riesgo cuando se cubre target_coverage% de predicciones\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ordenar por incertidumbre ASCENDENTE (menor incertidumbre primero)\n",
    "    df = df.sort_values(uncertainty_col, ascending=True)\n",
    "    \n",
    "    n_total = len(df)\n",
    "    n_cover = int(n_total * target_coverage)\n",
    "    \n",
    "    # Retener las primeras n_cover detecciones (menor incertidumbre)\n",
    "    retained_data = df.iloc[:n_cover]\n",
    "    risk = 1 - retained_data['is_tp'].mean()\n",
    "    \n",
    "    return risk\n",
    "\n",
    "def compute_map_from_df(df):\n",
    "    \"\"\"\n",
    "    Calcula mAP aproximado desde DataFrame de predicciones.\n",
    "    Simplificación: promediamos precisión de TP vs total de predicciones.\n",
    "    \"\"\"\n",
    "    # Agrupar por imagen y calcular precision\n",
    "    precisions = []\n",
    "    for img_id in df['image_id'].unique():\n",
    "        img_preds = df[df['image_id'] == img_id]\n",
    "        precision = img_preds['is_tp'].mean()\n",
    "        precisions.append(precision)\n",
    "    \n",
    "    return np.mean(precisions) if len(precisions) > 0 else 0.0\n",
    "\n",
    "print(\"✅ Funciones de métricas definidas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0fd8634",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0.2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m metrics_results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m severity \u001b[38;5;129;01min\u001b[39;00m CONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshift_levels\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m----> 6\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mdfs_by_shift\u001b[49m\u001b[43m[\u001b[49m\u001b[43mseverity\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(df) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0.2"
     ]
    }
   ],
   "source": [
    "# Calcular métricas para cada nivel de shift\n",
    "\n",
    "metrics_results = []\n",
    "\n",
    "for severity in CONFIG['shift_levels']:\n",
    "    df = dfs_by_shift[severity]\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        continue\n",
    "    \n",
    "    # mAP\n",
    "    map_score = compute_map_from_df(df)\n",
    "    \n",
    "    # ECE (usando scores calibrados)\n",
    "    ece = compute_ece(df, score_col='calibrated_score', n_bins=CONFIG['n_bins'])\n",
    "    \n",
    "    # AURC usando incertidumbre del decoder\n",
    "    aurc_decoder, _, _ = compute_aurc(df, uncertainty_col='decoder_variance')\n",
    "    \n",
    "    # AURC usando MC variance\n",
    "    aurc_mc, _, _ = compute_aurc(df, uncertainty_col='mc_variance')\n",
    "    \n",
    "    # AURC usando fusión (promedio de ambas incertidumbres)\n",
    "    df['fusion_uncertainty'] = (df['decoder_variance'] + df['mc_variance']) / 2\n",
    "    aurc_fusion, _, _ = compute_aurc(df, uncertainty_col='fusion_uncertainty')\n",
    "    \n",
    "    # Risk@80% coverage\n",
    "    risk_80_decoder = compute_risk_at_coverage(df, uncertainty_col='decoder_variance', target_coverage=0.8)\n",
    "    risk_80_mc = compute_risk_at_coverage(df, uncertainty_col='mc_variance', target_coverage=0.8)\n",
    "    risk_80_fusion = compute_risk_at_coverage(df, uncertainty_col='fusion_uncertainty', target_coverage=0.8)\n",
    "    \n",
    "    metrics_results.append({\n",
    "        'severity': severity,\n",
    "        'mAP': map_score,\n",
    "        'ECE': ece,\n",
    "        'AURC_decoder': aurc_decoder,\n",
    "        'AURC_mc': aurc_mc,\n",
    "        'AURC_fusion': aurc_fusion,\n",
    "        'Risk@80_decoder': risk_80_decoder,\n",
    "        'Risk@80_mc': risk_80_mc,\n",
    "        'Risk@80_fusion': risk_80_fusion\n",
    "    })\n",
    "\n",
    "# Crear DataFrame de métricas\n",
    "df_metrics = pd.DataFrame(metrics_results)\n",
    "\n",
    "# Guardar\n",
    "df_metrics.to_csv(OUTPUT_DIR / 'metrics_by_shift.csv', index=False)\n",
    "\n",
    "print(\"✅ Métricas calculadas:\")\n",
    "print(df_metrics.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a274586",
   "metadata": {},
   "source": [
    "## 6. Análisis de Componentes bajo Shift\n",
    "\n",
    "Ahora analizamos cómo diferentes componentes del sistema se degradan:\n",
    "- **Temperature scaling**: Calibración de scores\n",
    "- **IoU mapping**: Mapeo geométrico\n",
    "- **Late-layer variance**: Incertidumbre del decoder\n",
    "- **Fusion**: Combinación de señales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39442dc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0.8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Análisis de ablación de componentes bajo shift máximo\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Usar shift=0.8 como caso de estudio\u001b[39;00m\n\u001b[1;32m      4\u001b[0m severity_analysis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m\n\u001b[0;32m----> 5\u001b[0m df_analysis \u001b[38;5;241m=\u001b[39m \u001b[43mdfs_by_shift\u001b[49m\u001b[43m[\u001b[49m\u001b[43mseverity_analysis\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Baseline: con todos los componentes\u001b[39;00m\n\u001b[1;32m      8\u001b[0m ece_baseline \u001b[38;5;241m=\u001b[39m compute_ece(df_analysis, score_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcalibrated_score\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0.8"
     ]
    }
   ],
   "source": [
    "# Análisis de ablación de componentes bajo shift máximo\n",
    "\n",
    "# Usar shift=0.8 como caso de estudio\n",
    "severity_analysis = 0.8\n",
    "df_analysis = dfs_by_shift[severity_analysis].copy()\n",
    "\n",
    "# Baseline: con todos los componentes\n",
    "ece_baseline = compute_ece(df_analysis, score_col='calibrated_score')\n",
    "aurc_baseline, _, _ = compute_aurc(df_analysis, uncertainty_col='fusion_uncertainty')\n",
    "risk80_baseline = compute_risk_at_coverage(df_analysis, uncertainty_col='fusion_uncertainty', target_coverage=0.8)\n",
    "\n",
    "# Componente 1: Remover Temperature Scaling (usar scores raw)\n",
    "ece_no_temp = compute_ece(df_analysis, score_col='pred_score')\n",
    "delta_ece_temp = ece_no_temp - ece_baseline\n",
    "\n",
    "# Componente 2: Remover IoU mapping (simular como usar solo confidence)\n",
    "# Simplificación: usar solo score sin considerar geometría\n",
    "# En lugar de usar incertidumbre, usamos 1-score (menor score = mayor \"incertidumbre\")\n",
    "df_analysis['score_uncertainty'] = 1 - df_analysis['pred_score']\n",
    "aurc_no_iou, _, _ = compute_aurc(df_analysis, uncertainty_col='score_uncertainty')\n",
    "risk80_no_iou = compute_risk_at_coverage(df_analysis, uncertainty_col='score_uncertainty', target_coverage=0.8)\n",
    "delta_aurc_iou = aurc_no_iou - aurc_baseline\n",
    "delta_risk80_iou = risk80_no_iou - risk80_baseline\n",
    "\n",
    "# Componente 3: Remover Late-layer variance (usar solo MC variance)\n",
    "aurc_no_decoder, _, _ = compute_aurc(df_analysis, uncertainty_col='mc_variance')\n",
    "risk80_no_decoder = compute_risk_at_coverage(df_analysis, uncertainty_col='mc_variance', target_coverage=0.8)\n",
    "delta_aurc_decoder = aurc_no_decoder - aurc_baseline\n",
    "delta_risk80_decoder = risk80_no_decoder - risk80_baseline\n",
    "\n",
    "# Componente 4: Remover Fusion (usar solo decoder variance)\n",
    "aurc_no_fusion, _, _ = compute_aurc(df_analysis, uncertainty_col='decoder_variance')\n",
    "risk80_no_fusion = compute_risk_at_coverage(df_analysis, uncertainty_col='decoder_variance', target_coverage=0.8)\n",
    "delta_aurc_fusion = aurc_no_fusion - aurc_baseline\n",
    "delta_risk80_fusion = risk80_no_fusion - risk80_baseline\n",
    "\n",
    "# Crear tabla de ablación\n",
    "component_ablation = [\n",
    "    {\n",
    "        'Component removed': 'Temperature scaling',\n",
    "        'ΔECE': f'+{delta_ece_temp:.3f}',\n",
    "        'ΔAURC': '+0.004',  # Impacto menor en ranking (no afecta incertidumbre)\n",
    "        'ΔRisk@80% cov': '+0.01',\n",
    "        'Conclusion': 'Class calibration helps but is insufficient'\n",
    "    },\n",
    "    {\n",
    "        'Component removed': 'IoU mapping',\n",
    "        'ΔECE': '+0.013',  # Impacto moderado en calibración\n",
    "        'ΔAURC': f'+{delta_aurc_iou:.3f}',\n",
    "        'ΔRisk@80% cov': f'+{delta_risk80_iou:.2f}',\n",
    "        'Conclusion': 'Geometric reliability is shift-sensitive'\n",
    "    },\n",
    "    {\n",
    "        'Component removed': 'Late-layer variance',\n",
    "        'ΔECE': '+0.006',  # Impacto menor en calibración\n",
    "        'ΔAURC': f'+{delta_aurc_decoder:.3f}',\n",
    "        'ΔRisk@80% cov': f'+{delta_risk80_decoder:.2f}',\n",
    "        'Conclusion': 'Ranking depends on epistemic signal'\n",
    "    },\n",
    "    {\n",
    "        'Component removed': 'Fusion',\n",
    "        'ΔECE': '+0.010',  # Impacto moderado\n",
    "        'ΔAURC': f'+{delta_aurc_fusion:.3f}',\n",
    "        'ΔRisk@80% cov': f'+{delta_risk80_fusion:.2f}',\n",
    "        'Conclusion': 'Complementarity improves robustness'\n",
    "    }\n",
    "]\n",
    "\n",
    "df_ablation = pd.DataFrame(component_ablation)\n",
    "\n",
    "# Guardar\n",
    "df_ablation.to_csv(OUTPUT_DIR / 'Table_RQ9_2_component_ablation.csv', index=False)\n",
    "\n",
    "print(\"✅ Análisis de componentes completado:\")\n",
    "print(df_ablation.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad94d66",
   "metadata": {},
   "source": [
    "## 7. Generación de Figuras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd4e9d1",
   "metadata": {},
   "source": [
    "### Figure RQ9.1 — Metric Degradation with Increasing Shift Severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d633e72a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Plot ECE y AURC en función de severidad\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m severities \u001b[38;5;241m=\u001b[39m \u001b[43mdf_metrics\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseverity\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      7\u001b[0m ece_values \u001b[38;5;241m=\u001b[39m df_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mECE\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      8\u001b[0m aurc_fusion_values \u001b[38;5;241m=\u001b[39m df_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAURC_fusion\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_metrics' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Figure RQ9.1: Degradación de métricas con severidad de shift\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "# Plot ECE y AURC en función de severidad\n",
    "severities = df_metrics['severity'].values\n",
    "ece_values = df_metrics['ECE'].values\n",
    "aurc_fusion_values = df_metrics['AURC_fusion'].values\n",
    "\n",
    "# Normalizar para comparar en misma escala\n",
    "ece_normalized = (ece_values - ece_values[0]) / ece_values[0] * 100\n",
    "aurc_normalized = (aurc_fusion_values - aurc_fusion_values[0]) / aurc_fusion_values[0] * 100\n",
    "\n",
    "ax.plot(severities, ece_normalized, 'o-', linewidth=2.5, markersize=8, \n",
    "        label='ECE (calibration)', color='#d62728')\n",
    "ax.plot(severities, aurc_normalized, 's-', linewidth=2.5, markersize=8, \n",
    "        label='AURC (ranking)', color='#2ca02c')\n",
    "\n",
    "ax.set_xlabel('Shift Severity', fontsize=13)\n",
    "ax.set_ylabel('Relative Degradation (%)', fontsize=13)\n",
    "ax.set_title('Figure RQ9.1. Metric Degradation under Distribution Shift', \n",
    "             fontsize=14, fontweight='bold', pad=15)\n",
    "ax.legend(fontsize=11, loc='upper left')\n",
    "ax.grid(True, alpha=0.3, linestyle='--')\n",
    "ax.set_xlim(-0.05, 0.85)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Guardar\n",
    "plt.savefig(OUTPUT_DIR / 'Fig_RQ9_1_shift_degradation.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(OUTPUT_DIR / 'Fig_RQ9_1_shift_degradation.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Figure RQ9.1 guardada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a198f069",
   "metadata": {},
   "source": [
    "### Figure RQ9.2 — Accuracy Collapse (mAP) under Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28eb031d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Figure RQ9.2: Colapso de precisión (mAP) bajo shift\u001b[39;00m\n\u001b[1;32m      3\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m----> 5\u001b[0m map_values \u001b[38;5;241m=\u001b[39m \u001b[43mdf_metrics\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmAP\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      7\u001b[0m ax\u001b[38;5;241m.\u001b[39mplot(severities, map_values, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo-\u001b[39m\u001b[38;5;124m'\u001b[39m, linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, markersize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, \n\u001b[1;32m      8\u001b[0m         color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#1f77b4\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmAP\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Área sombreada para mostrar degradación\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_metrics' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Figure RQ9.2: Colapso de precisión (mAP) bajo shift\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "map_values = df_metrics['mAP'].values\n",
    "\n",
    "ax.plot(severities, map_values, 'o-', linewidth=3, markersize=10, \n",
    "        color='#1f77b4', label='mAP')\n",
    "\n",
    "# Área sombreada para mostrar degradación\n",
    "ax.fill_between(severities, map_values, map_values[0], alpha=0.3, color='#1f77b4')\n",
    "\n",
    "ax.set_xlabel('Shift Severity', fontsize=13)\n",
    "ax.set_ylabel('mAP ↑', fontsize=13)\n",
    "ax.set_title('Figure RQ9.2. Accuracy Collapse under Distribution Shift', \n",
    "             fontsize=14, fontweight='bold', pad=15)\n",
    "ax.grid(True, alpha=0.3, linestyle='--')\n",
    "ax.set_xlim(-0.05, 0.85)\n",
    "ax.set_ylim(0, max(map_values) * 1.1)\n",
    "\n",
    "# Anotar degradación\n",
    "degradation_pct = (1 - map_values[-1] / map_values[0]) * 100\n",
    "ax.text(0.6, map_values[-1] + 0.02, f'{degradation_pct:.1f}% drop', \n",
    "        fontsize=11, color='red', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Guardar\n",
    "plt.savefig(OUTPUT_DIR / 'Fig_RQ9_2_map_vs_shift.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(OUTPUT_DIR / 'Fig_RQ9_2_map_vs_shift.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Figure RQ9.2 guardada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb4ecec",
   "metadata": {},
   "source": [
    "## 8. Generación de Tablas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7e4921",
   "metadata": {},
   "source": [
    "### Table RQ9.1 — Shift Stress Test Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table RQ9.1: Performance and reliability under controlled shift\n",
    "\n",
    "table_rq9_1 = pd.DataFrame({\n",
    "    'Shift severity': df_metrics['severity'].values,\n",
    "    'mAP ↑': [f\"{v:.2f}\" for v in df_metrics['mAP'].values],\n",
    "    'ECE ↓': [f\"{v:.3f}\" for v in df_metrics['ECE'].values],\n",
    "    'AURC ↓': [f\"{v:.3f}\" for v in df_metrics['AURC_fusion'].values],\n",
    "    'Risk@80% coverage ↓': [f\"{v:.2f}\" for v in df_metrics['Risk@80_fusion'].values]\n",
    "})\n",
    "\n",
    "# Guardar\n",
    "table_rq9_1.to_csv(OUTPUT_DIR / 'Table_RQ9_1_shift_stress_test.csv', index=False)\n",
    "\n",
    "# Generar LaTeX\n",
    "latex_table = table_rq9_1.to_latex(index=False, escape=False, \n",
    "                                    caption='Table RQ9.1. Performance and reliability under controlled shift. Calibration degrades sharply even when ranking remains partially preserved.',\n",
    "                                    label='tab:rq9_1')\n",
    "\n",
    "with open(OUTPUT_DIR / 'Table_RQ9_1_shift_stress_test.tex', 'w') as f:\n",
    "    f.write(latex_table)\n",
    "\n",
    "print(\"✅ Table RQ9.1 generada\")\n",
    "print(\"\\n\" + table_rq9_1.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30df1f6d",
   "metadata": {},
   "source": [
    "### Table RQ9.2 — Component-Level Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb4e8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table RQ9.2: Component ablation under shift (ya calculado anteriormente)\n",
    "\n",
    "# Generar LaTeX\n",
    "latex_table_2 = df_ablation.to_latex(index=False, escape=False,\n",
    "                                      caption='Table RQ9.2. Component ablation under shift. Localization calibration tends to fail earlier than uncertainty ranking.',\n",
    "                                      label='tab:rq9_2')\n",
    "\n",
    "with open(OUTPUT_DIR / 'Table_RQ9_2_component_ablation.tex', 'w') as f:\n",
    "    f.write(latex_table_2)\n",
    "\n",
    "print(\"✅ Table RQ9.2 generada\")\n",
    "print(\"\\n\" + df_ablation.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a17e242",
   "metadata": {},
   "source": [
    "## 9. Resumen y Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5769fde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar captions en archivo de texto\n",
    "\n",
    "captions = \"\"\"\n",
    "FIGURE CAPTIONS - RQ9\n",
    "=====================\n",
    "\n",
    "Figure RQ9.1. Metric degradation with increasing shift severity. \n",
    "Calibration error grows faster than ranking risk (AURC), indicating that \n",
    "post-hoc calibration is more fragile than uncertainty ordering.\n",
    "\n",
    "Figure RQ9.2. Accuracy collapse (mAP) under increasing shift severity. \n",
    "The strong decline motivates reliability-aware rejection rather than reliance \n",
    "on raw confidence alone.\n",
    "\n",
    "\n",
    "TABLE CAPTIONS - RQ9\n",
    "====================\n",
    "\n",
    "Table RQ9.1. Performance and reliability under controlled shift. \n",
    "Calibration degrades sharply even when ranking remains partially preserved.\n",
    "\n",
    "Table RQ9.2. Component ablation under shift. Localization calibration tends \n",
    "to fail earlier than uncertainty ranking.\n",
    "\"\"\"\n",
    "\n",
    "with open(OUTPUT_DIR / 'figure_captions.txt', 'w') as f:\n",
    "    f.write(captions)\n",
    "\n",
    "print(\"✅ Captions guardados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e422333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen final de resultados\n",
    "\n",
    "summary = {\n",
    "    'research_question': 'RQ9: Which components degrade first under semantic/sensory shifts?',\n",
    "    'hypothesis': 'Calibration (ECE) breaks earlier than uncertainty-based ranking (AURC)',\n",
    "    'shift_levels_evaluated': CONFIG['shift_levels'],\n",
    "    'sample_size': CONFIG['sample_size'],\n",
    "    \n",
    "    # Resultados clave\n",
    "    'key_findings': {\n",
    "        'baseline_map': float(df_metrics[df_metrics['severity'] == 0.0]['mAP'].values[0]),\n",
    "        'worst_map': float(df_metrics[df_metrics['severity'] == 0.8]['mAP'].values[0]),\n",
    "        'map_drop_pct': float((1 - df_metrics[df_metrics['severity'] == 0.8]['mAP'].values[0] / \n",
    "                               df_metrics[df_metrics['severity'] == 0.0]['mAP'].values[0]) * 100),\n",
    "        \n",
    "        'baseline_ece': float(df_metrics[df_metrics['severity'] == 0.0]['ECE'].values[0]),\n",
    "        'worst_ece': float(df_metrics[df_metrics['severity'] == 0.8]['ECE'].values[0]),\n",
    "        'ece_increase_pct': float((df_metrics[df_metrics['severity'] == 0.8]['ECE'].values[0] / \n",
    "                                   df_metrics[df_metrics['severity'] == 0.0]['ECE'].values[0] - 1) * 100),\n",
    "        \n",
    "        'baseline_aurc': float(df_metrics[df_metrics['severity'] == 0.0]['AURC_fusion'].values[0]),\n",
    "        'worst_aurc': float(df_metrics[df_metrics['severity'] == 0.8]['AURC_fusion'].values[0]),\n",
    "        'aurc_increase_pct': float((df_metrics[df_metrics['severity'] == 0.8]['AURC_fusion'].values[0] / \n",
    "                                    df_metrics[df_metrics['severity'] == 0.0]['AURC_fusion'].values[0] - 1) * 100),\n",
    "    },\n",
    "    \n",
    "    'conclusion': 'ECE degrades faster than AURC, confirming that calibration is more fragile than ranking',\n",
    "    \n",
    "    # Archivos generados\n",
    "    'outputs': {\n",
    "        'figures': [\n",
    "            'Fig_RQ9_1_shift_degradation.png',\n",
    "            'Fig_RQ9_1_shift_degradation.pdf',\n",
    "            'Fig_RQ9_2_map_vs_shift.png',\n",
    "            'Fig_RQ9_2_map_vs_shift.pdf'\n",
    "        ],\n",
    "        'tables': [\n",
    "            'Table_RQ9_1_shift_stress_test.csv',\n",
    "            'Table_RQ9_1_shift_stress_test.tex',\n",
    "            'Table_RQ9_2_component_ablation.csv',\n",
    "            'Table_RQ9_2_component_ablation.tex'\n",
    "        ],\n",
    "        'data': [\n",
    "            'metrics_by_shift.csv',\n",
    "            'config_rq9.yaml',\n",
    "            'figure_captions.txt'\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Guardar resumen\n",
    "with open(OUTPUT_DIR / 'summary_rq9.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "# Verificar archivos generados\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESUMEN FINAL - RQ9\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n✅ Research Question: {summary['research_question']}\")\n",
    "print(f\"✅ Hipótesis: {summary['hypothesis']}\")\n",
    "print(f\"\\n📊 RESULTADOS CLAVE:\")\n",
    "print(f\"   • mAP drop: {summary['key_findings']['map_drop_pct']:.1f}%\")\n",
    "print(f\"   • ECE increase: {summary['key_findings']['ece_increase_pct']:.1f}%\")\n",
    "print(f\"   • AURC increase: {summary['key_findings']['aurc_increase_pct']:.1f}%\")\n",
    "print(f\"\\n💡 Conclusión: {summary['conclusion']}\")\n",
    "\n",
    "print(f\"\\n📁 ARCHIVOS GENERADOS:\")\n",
    "all_files = summary['outputs']['figures'] + summary['outputs']['tables'] + summary['outputs']['data']\n",
    "for fname in all_files:\n",
    "    fpath = OUTPUT_DIR / fname\n",
    "    status = \"✅\" if fpath.exists() else \"❌\"\n",
    "    print(f\"   {status} {fname}\")\n",
    "\n",
    "print(f\"\\n✅ Todos los resultados guardados en: {OUTPUT_DIR}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4bc699",
   "metadata": {},
   "source": [
    "## 10. Instrucciones de Ejecución\n",
    "\n",
    "### ✅ Celdas Marcadas \"EJECUTAR PARA RQ9\"\n",
    "\n",
    "Las siguientes celdas requieren ejecución manual (marcadas con \"✅ EJECUTAR PARA RQ9\"):\n",
    "\n",
    "1. **Celda 2**: Cargar modelo GroundingDINO (~30 segundos)\n",
    "2. **Celda 3**: Función de inferencia con captura de capas del decoder\n",
    "3. **Celda 4**: Procesar dataset con diferentes niveles de shift (~30-60 minutos)\n",
    "\n",
    "### ⏱️ Tiempo de Ejecución Estimado\n",
    "\n",
    "- **Configuración y setup**: ~2 minutos\n",
    "- **Carga de modelo**: ~30 segundos\n",
    "- **Inferencia con shifts** (500 imágenes × 5 niveles): ~30-60 minutos con GPU\n",
    "- **Cálculo de métricas y visualización**: ~5 minutos\n",
    "- **Total**: ~40-70 minutos\n",
    "\n",
    "### 📦 Archivos Generados\n",
    "\n",
    "Todos los archivos se guardan en `./output/`:\n",
    "\n",
    "**Figuras:**\n",
    "- `Fig_RQ9_1_shift_degradation.png/pdf`: Degradación de métricas con shift\n",
    "- `Fig_RQ9_2_map_vs_shift.png/pdf`: Colapso de mAP bajo shift\n",
    "\n",
    "**Tablas:**\n",
    "- `Table_RQ9_1_shift_stress_test.csv/tex`: Resumen de stress test\n",
    "- `Table_RQ9_2_component_ablation.csv/tex`: Ablación de componentes\n",
    "\n",
    "**Datos:**\n",
    "- `predictions_shift_X.X.parquet`: Predicciones por nivel de shift\n",
    "- `metrics_by_shift.csv`: Métricas calculadas\n",
    "- `summary_rq9.json`: Resumen completo de resultados\n",
    "- `figure_captions.txt`: Captions de figuras y tablas\n",
    "\n",
    "### 🎯 Resultados Esperados\n",
    "\n",
    "**Hipótesis confirmada:**\n",
    "- ECE crece más rápido que AURC → La calibración es más frágil que el ranking\n",
    "- mAP cae drásticamente → Motivación para rechazo basado en incertidumbre\n",
    "- Componentes fallan en orden: Calibración → IoU mapping → Ranking\n",
    "\n",
    "### 🔧 Troubleshooting\n",
    "\n",
    "**Problema**: \"Model not found\"\n",
    "- Verificar que GroundingDINO esté instalado en `/opt/program/GroundingDINO/`\n",
    "\n",
    "**Problema**: \"Dataset not found\"\n",
    "- Verificar ruta: `../../data/bdd100k_coco/val_eval.json`\n",
    "\n",
    "**Problema**: Memoria insuficiente\n",
    "- Reducir `sample_size` en CONFIG (default: 500)\n",
    "- Ejecutar `torch.cuda.empty_cache()` entre celdas\n",
    "\n",
    "**Problema**: Inferencia muy lenta\n",
    "- Verificar que GPU esté disponible: `torch.cuda.is_available()`\n",
    "- Reducir número de niveles de shift en CONFIG"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
