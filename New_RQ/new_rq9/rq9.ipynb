{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d23ea508",
   "metadata": {},
   "source": [
    "# RQ9 — Robustez y Límites de Estabilidad bajo Distribution Shift\n",
    "\n",
    "## Research Question\n",
    "\n",
    "**¿Qué componentes se degradan primero bajo cambios semánticos/sensoriales, y qué revela esto sobre los límites de confiabilidad post-hoc?**\n",
    "\n",
    "**Hipótesis**: La calibración (ECE) se rompe antes que el ranking basado en incertidumbre (AURC). Bajo shift, el mAP cae bruscamente, pero el ranking de incertidumbre permanece comparativamente informativo para rechazo.\n",
    "\n",
    "---\n",
    "\n",
    "## Expected Results\n",
    "\n",
    "### Figuras\n",
    "- **Figure RQ9.1**: Degradación de métricas con severidad de shift creciente (ECE crece más rápido que AURC)\n",
    "- **Figure RQ9.2**: Colapso de precisión (mAP) bajo shift creciente\n",
    "\n",
    "### Tablas\n",
    "- **Table RQ9.1**: Resumen de stress test bajo shift controlado\n",
    "- **Table RQ9.2**: Ablación de componentes bajo shift\n",
    "\n",
    "---\n",
    "\n",
    "## Metodología\n",
    "\n",
    "1. **Simular Distribution Shifts**: Aplicar perturbaciones de severidad creciente (blur, noise, brightness)\n",
    "2. **Evaluar en cada nivel**: mAP, ECE, AURC, Risk@80% coverage\n",
    "3. **Análisis de componentes**: Temperature scaling, IoU mapping, late-layer variance, fusion\n",
    "4. **Generar visualizaciones**: Curvas de degradación y tablas comparativas\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539f09b4",
   "metadata": {},
   "source": [
    "## 1. Configuración e Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41210fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuración RQ9\n",
      "   Device: cuda\n",
      "   Output: output\n",
      "   Shift levels: [0.0, 0.2, 0.4, 0.6, 0.8]\n",
      "   Sample size: 500\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageFilter, ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from sklearn.metrics import auc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración\n",
    "BASE_DIR = Path('../..')\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "OUTPUT_DIR = Path('./output')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CONFIG = {\n",
    "    'seed': 42,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'categories': ['person', 'rider', 'car', 'truck', 'bus', 'train', 'motorcycle', 'bicycle', 'traffic light', 'traffic sign'],\n",
    "    'shift_levels': [0.0, 0.2, 0.4, 0.6, 0.8],  # Severidad de shift\n",
    "    'n_bins': 15,\n",
    "    'iou_threshold': 0.5,\n",
    "    'conf_threshold': 0.25,\n",
    "    'sample_size': 500,  # Imágenes a evaluar\n",
    "    'perturbation_types': ['blur', 'noise', 'brightness', 'contrast']\n",
    "}\n",
    "\n",
    "torch.manual_seed(CONFIG['seed'])\n",
    "np.random.seed(CONFIG['seed'])\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(CONFIG['seed'])\n",
    "\n",
    "with open(OUTPUT_DIR / 'config_rq9.yaml', 'w') as f:\n",
    "    yaml.dump(CONFIG, f)\n",
    "\n",
    "print(f\"✅ Configuración RQ9\")\n",
    "print(f\"   Device: {CONFIG['device']}\")\n",
    "print(f\"   Output: {OUTPUT_DIR}\")\n",
    "print(f\"   Shift levels: {CONFIG['shift_levels']}\")\n",
    "print(f\"   Sample size: {CONFIG['sample_size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88767d51",
   "metadata": {},
   "source": [
    "## 2. Cargar Modelo y Resultados Previos\n",
    "\n",
    "⚠️ **Nota**: Necesitamos cargar resultados de fases anteriores para obtener:\n",
    "- Temperaturas optimizadas (Fase 4)\n",
    "- Incertidumbre MC Dropout (Fase 3)\n",
    "- Incertidumbre determinística del decoder (RQ6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b581bb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n",
      "✅ Modelo cargado en cuda\n",
      "   Prompt: person. rider. car. truck. bus. train. motorcycle. bicycle. traffic light. traffic sign.\n",
      "   Módulos dropout identificados: 0\n"
     ]
    }
   ],
   "source": [
    "# ✅ EJECUTAR PARA RQ9 - Cargar modelo GroundingDINO\n",
    "\n",
    "from groundingdino.util.inference import load_model, load_image, predict\n",
    "from groundingdino.util import box_ops\n",
    "\n",
    "model_config = '/opt/program/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py'\n",
    "model_weights = '/opt/program/GroundingDINO/weights/groundingdino_swint_ogc.pth'\n",
    "\n",
    "model = load_model(model_config, model_weights)\n",
    "model.to(CONFIG['device'])\n",
    "model.eval()\n",
    "\n",
    "TEXT_PROMPT = '. '.join(CONFIG['categories']) + '.'\n",
    "\n",
    "print(f\"✅ Modelo cargado en {CONFIG['device']}\")\n",
    "print(f\"   Prompt: {TEXT_PROMPT}\")\n",
    "\n",
    "# Identificar módulos dropout para MC-Dropout\n",
    "dropout_modules = []\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Dropout) and ('class_embed' in name or 'bbox_embed' in name):\n",
    "        dropout_modules.append(module)\n",
    "\n",
    "print(f\"   Módulos dropout identificados: {len(dropout_modules)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c88e201f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Temperatura optimizada cargada: T = 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Cargar temperatura optimizada de Fase 4\n",
    "TEMPERATURE_FILE = BASE_DIR / 'fase 4' / 'outputs' / 'temperature_scaling' / 'temperature.json'\n",
    "\n",
    "if TEMPERATURE_FILE.exists():\n",
    "    with open(TEMPERATURE_FILE, 'r') as f:\n",
    "        temp_data = json.load(f)\n",
    "        OPTIMAL_TEMPERATURE = temp_data.get('optimal_temperature', 1.0)\n",
    "    print(f\"✅ Temperatura optimizada cargada: T = {OPTIMAL_TEMPERATURE:.4f}\")\n",
    "else:\n",
    "    OPTIMAL_TEMPERATURE = 1.0\n",
    "    print(f\"⚠️  No se encontró temperatura optimizada, usando T = 1.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1be795",
   "metadata": {},
   "source": [
    "## 3. Funciones para Simulación de Distribution Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87af8578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Funciones de perturbación definidas\n"
     ]
    }
   ],
   "source": [
    "def apply_distribution_shift(image, severity=0.0):\n",
    "    \"\"\"\n",
    "    Aplica perturbaciones para simular distribution shift.\n",
    "    \n",
    "    Args:\n",
    "        image: PIL Image\n",
    "        severity: 0.0 (sin shift) a 1.0 (shift máximo)\n",
    "    \n",
    "    Returns:\n",
    "        PIL Image perturbada\n",
    "    \"\"\"\n",
    "    if severity == 0.0:\n",
    "        return image\n",
    "    \n",
    "    # Combinación de perturbaciones\n",
    "    \n",
    "    # 1. Blur gaussiano (aumenta con severidad)\n",
    "    radius = severity * 5.0  # 0 a 5 píxeles\n",
    "    if radius > 0:\n",
    "        image = image.filter(ImageFilter.GaussianBlur(radius=radius))\n",
    "    \n",
    "    # 2. Ruido gaussiano\n",
    "    if severity > 0:\n",
    "        img_array = np.array(image).astype(np.float32)\n",
    "        noise_std = severity * 25.0  # 0 a 25 de std\n",
    "        noise = np.random.normal(0, noise_std, img_array.shape)\n",
    "        img_array = np.clip(img_array + noise, 0, 255)\n",
    "        image = Image.fromarray(img_array.astype(np.uint8))\n",
    "    \n",
    "    # 3. Cambio de brillo\n",
    "    brightness_factor = 1.0 - severity * 0.4  # Reducir brillo hasta 60%\n",
    "    enhancer = ImageEnhance.Brightness(image)\n",
    "    image = enhancer.enhance(brightness_factor)\n",
    "    \n",
    "    # 4. Cambio de contraste\n",
    "    contrast_factor = 1.0 - severity * 0.3  # Reducir contraste hasta 70%\n",
    "    enhancer = ImageEnhance.Contrast(image)\n",
    "    image = enhancer.enhance(contrast_factor)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def compute_iou(box1, box2):\n",
    "    \"\"\"Calcula IoU entre dos boxes [x1, y1, x2, y2]\"\"\"\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "    inter = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union = area1 + area2 - inter\n",
    "    return inter / union if union > 0 else 0.0\n",
    "\n",
    "def normalize_label(label):\n",
    "    \"\"\"Normaliza etiquetas del modelo\"\"\"\n",
    "    synonyms = {\n",
    "        'bike': 'bicycle', 'motorbike': 'motorcycle', \n",
    "        'pedestrian': 'person', 'stop sign': 'traffic sign', \n",
    "        'red light': 'traffic light'\n",
    "    }\n",
    "    label_lower = label.lower().strip()\n",
    "    if label_lower in synonyms:\n",
    "        return synonyms[label_lower]\n",
    "    for cat in CONFIG['categories']:\n",
    "        if cat in label_lower:\n",
    "            return cat\n",
    "    return label_lower\n",
    "\n",
    "print(\"✅ Funciones de perturbación definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77754dcc",
   "metadata": {},
   "source": [
    "## 4. Inferencia con Distribution Shift\n",
    "\n",
    "Vamos a ejecutar el modelo en imágenes con diferentes niveles de perturbación y capturar:\n",
    "- Predicciones baseline\n",
    "- Incertidumbre MC Dropout\n",
    "- Incertidumbre del decoder (varianza inter-capa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5827d01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Hooks registrados en 6 capas del decoder\n",
      "✅ Función de inferencia con incertidumbre definida\n"
     ]
    }
   ],
   "source": [
    "# ✅ EJECUTAR PARA RQ9 - Función de inferencia con captura de capas del decoder\n",
    "\n",
    "layer_outputs = {}\n",
    "\n",
    "def hook_fn(name):\n",
    "    def hook(module, input, output):\n",
    "        # Capturar la salida del decoder layer\n",
    "        if isinstance(output, tuple):\n",
    "            layer_outputs[name] = output[0].detach() if hasattr(output[0], 'detach') else output[0]\n",
    "        else:\n",
    "            layer_outputs[name] = output.detach() if hasattr(output, 'detach') else output\n",
    "    return hook\n",
    "\n",
    "# Registrar hooks en el decoder\n",
    "hooks = []\n",
    "decoder_layers = []\n",
    "\n",
    "# Buscar las capas del decoder en la arquitectura\n",
    "for name, module in model.named_modules():\n",
    "    if 'decoder.layers' in name and name.count('.') == 3:\n",
    "        layer_num = name.split('.')[-1]\n",
    "        if layer_num.isdigit():\n",
    "            decoder_layers.append((int(layer_num), name, module))\n",
    "\n",
    "decoder_layers.sort(key=lambda x: x[0])\n",
    "\n",
    "for layer_idx, layer_name, layer_module in decoder_layers:\n",
    "    hook = layer_module.register_forward_hook(hook_fn(f'decoder_layer_{layer_idx}'))\n",
    "    hooks.append(hook)\n",
    "\n",
    "print(f\"✅ Hooks registrados en {len(hooks)} capas del decoder\")\n",
    "\n",
    "def run_inference_with_uncertainty(image_pil, text_prompt, box_threshold=0.25, text_threshold=0.25):\n",
    "    \"\"\"\n",
    "    Ejecuta inferencia con captura de incertidumbre epistémica.\n",
    "    \n",
    "    Returns:\n",
    "        dict con:\n",
    "        - boxes: [N, 4] en formato xyxy\n",
    "        - logits: [N] scores originales\n",
    "        - phrases: [N] etiquetas\n",
    "        - decoder_variance: [N] varianza inter-capa del decoder\n",
    "    \"\"\"\n",
    "    layer_outputs.clear()\n",
    "    \n",
    "    # Inferencia baseline\n",
    "    boxes, logits, phrases = predict(\n",
    "        model=model,\n",
    "        image=image_pil,\n",
    "        caption=text_prompt,\n",
    "        box_threshold=box_threshold,\n",
    "        text_threshold=text_threshold\n",
    "    )\n",
    "    \n",
    "    if len(boxes) == 0:\n",
    "        return {\n",
    "            'boxes': np.array([]),\n",
    "            'logits': np.array([]),\n",
    "            'phrases': [],\n",
    "            'decoder_variance': np.array([])\n",
    "        }\n",
    "    \n",
    "    # Calcular varianza inter-capa del decoder\n",
    "    decoder_variances = []\n",
    "    n_detections = boxes.shape[0]\n",
    "    n_layers = len([k for k in layer_outputs.keys() if 'decoder_layer' in k])\n",
    "    \n",
    "    if n_layers > 0:\n",
    "        # Extraer scores por capa\n",
    "        layer_scores = []\n",
    "        for i in range(n_layers):\n",
    "            layer_key = f'decoder_layer_{i}'\n",
    "            if layer_key in layer_outputs:\n",
    "                # Usar norma del embedding como proxy de score\n",
    "                layer_emb = layer_outputs[layer_key]\n",
    "                # layer_emb puede tener shape [num_queries, batch, embed_dim] o [batch, num_queries, embed_dim]\n",
    "                if len(layer_emb.shape) == 3:\n",
    "                    # Intentar ambos formatos\n",
    "                    if layer_emb.shape[1] == 1:  # [num_queries, 1, dim]\n",
    "                        layer_score = torch.norm(layer_emb[:n_detections, 0, :], dim=-1)\n",
    "                    else:  # [1, num_queries, dim]\n",
    "                        layer_score = torch.norm(layer_emb[0, :n_detections, :], dim=-1)\n",
    "                    layer_scores.append(layer_score.cpu().numpy())\n",
    "        \n",
    "        if len(layer_scores) > 0:\n",
    "            layer_scores = np.array(layer_scores)  # [n_layers, n_detections]\n",
    "            decoder_variances = np.var(layer_scores, axis=0)  # [n_detections]\n",
    "        else:\n",
    "            decoder_variances = np.zeros(n_detections)\n",
    "    else:\n",
    "        decoder_variances = np.zeros(n_detections)\n",
    "    \n",
    "    return {\n",
    "        'boxes': boxes.cpu().numpy(),\n",
    "        'logits': logits.cpu().numpy(),\n",
    "        'phrases': phrases,\n",
    "        'decoder_variance': decoder_variances\n",
    "    }\n",
    "\n",
    "print(\"✅ Función de inferencia con incertidumbre definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58f93587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Función MC-Dropout definida\n"
     ]
    }
   ],
   "source": [
    "def run_mc_dropout_inference(image_pil, text_prompt, K=5, box_threshold=0.25):\n",
    "    \"\"\"\n",
    "    Ejecuta K pases estocásticos con MC-Dropout.\n",
    "    \n",
    "    Returns:\n",
    "        dict con:\n",
    "        - boxes: [N, 4] boxes promediadas\n",
    "        - logits: [N] scores promediados\n",
    "        - phrases: [N] etiquetas\n",
    "        - mc_variance: [N] varianza de scores entre pases\n",
    "    \"\"\"\n",
    "    # Activar dropout\n",
    "    for module in dropout_modules:\n",
    "        module.train()\n",
    "    \n",
    "    all_detections = []\n",
    "    \n",
    "    for k in range(K):\n",
    "        result = run_inference_with_uncertainty(image_pil, text_prompt, box_threshold)\n",
    "        if len(result['boxes']) > 0:\n",
    "            all_detections.append(result)\n",
    "    \n",
    "    # Desactivar dropout\n",
    "    for module in dropout_modules:\n",
    "        module.eval()\n",
    "    \n",
    "    if len(all_detections) == 0:\n",
    "        return {\n",
    "            'boxes': np.array([]),\n",
    "            'logits': np.array([]),\n",
    "            'phrases': [],\n",
    "            'mc_variance': np.array([]),\n",
    "            'decoder_variance': np.array([])\n",
    "        }\n",
    "    \n",
    "    # Alinear detecciones entre pases y calcular varianza\n",
    "    # Simplificación: usar primer pase como referencia\n",
    "    ref_boxes = all_detections[0]['boxes']\n",
    "    ref_logits = all_detections[0]['logits']\n",
    "    ref_phrases = all_detections[0]['phrases']\n",
    "    \n",
    "    mc_variances = []\n",
    "    for i in range(len(ref_boxes)):\n",
    "        scores_across_passes = [all_detections[0]['logits'][i]]\n",
    "        \n",
    "        # Buscar matches en otros pases\n",
    "        for det in all_detections[1:]:\n",
    "            best_iou = 0\n",
    "            best_score = ref_logits[i]\n",
    "            for j, box in enumerate(det['boxes']):\n",
    "                iou = compute_iou(ref_boxes[i], box)\n",
    "                if iou > 0.5:  # Umbral de matching\n",
    "                    if iou > best_iou:\n",
    "                        best_iou = iou\n",
    "                        best_score = det['logits'][j]\n",
    "            scores_across_passes.append(best_score)\n",
    "        \n",
    "        mc_variances.append(np.var(scores_across_passes))\n",
    "    \n",
    "    return {\n",
    "        'boxes': ref_boxes,\n",
    "        'logits': ref_logits,\n",
    "        'phrases': ref_phrases,\n",
    "        'mc_variance': np.array(mc_variances),\n",
    "        'decoder_variance': all_detections[0]['decoder_variance']\n",
    "    }\n",
    "\n",
    "print(\"✅ Función MC-Dropout definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd605b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.32s)\n",
      "creating index...\n",
      "index created!\n",
      "✅ Procesando 500 imágenes con 5 niveles de shift\n",
      "   Esto puede tomar ~30-60 minutos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes: 100%|██████████| 500/500 [00:00<00:00, 5447.60it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'is_tp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 111\u001b[0m\n\u001b[1;32m    109\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[1;32m    110\u001b[0m     dfs_by_shift[severity] \u001b[38;5;241m=\u001b[39m df\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Shift \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseverity\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m detecciones (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_tp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m TP, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(\u001b[38;5;241m~\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_tp\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m FP)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Guardar resultados\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m severity, df \u001b[38;5;129;01min\u001b[39;00m dfs_by_shift\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:4113\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4113\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4115\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'is_tp'"
     ]
    }
   ],
   "source": [
    "# ✅ EJECUTAR PARA RQ9 - Procesar dataset con diferentes niveles de shift\n",
    "\n",
    "# Cargar anotaciones\n",
    "coco_file = DATA_DIR / 'bdd100k_coco' / 'val_eval.json'\n",
    "coco = COCO(str(coco_file))\n",
    "\n",
    "# Mapeo de categorías\n",
    "cat_name_to_id = {cat: idx + 1 for idx, cat in enumerate(CONFIG['categories'])}\n",
    "\n",
    "# Seleccionar subset de imágenes\n",
    "all_img_ids = list(coco.imgs.keys())\n",
    "np.random.seed(CONFIG['seed'])\n",
    "sample_img_ids = np.random.choice(all_img_ids, min(CONFIG['sample_size'], len(all_img_ids)), replace=False)\n",
    "\n",
    "print(f\"✅ Procesando {len(sample_img_ids)} imágenes con {len(CONFIG['shift_levels'])} niveles de shift\")\n",
    "print(f\"   Esto puede tomar ~30-60 minutos...\")\n",
    "\n",
    "# Diccionario para almacenar resultados\n",
    "results_by_shift = {severity: [] for severity in CONFIG['shift_levels']}\n",
    "\n",
    "for img_id in tqdm(sample_img_ids, desc=\"Procesando imágenes\"):\n",
    "    img_info = coco.imgs[img_id]\n",
    "    img_path = DATA_DIR / 'bdd100k' / 'bdd100k' / 'images' / '10k' / 'val' / img_info['file_name']\n",
    "    \n",
    "    if not img_path.exists():\n",
    "        continue\n",
    "    \n",
    "    # Cargar imagen original\n",
    "    try:\n",
    "        img_original = Image.open(img_path).convert('RGB')\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # Obtener ground truth\n",
    "    ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "    \n",
    "    gt_boxes = []\n",
    "    gt_labels = []\n",
    "    for ann in anns:\n",
    "        bbox_xywh = ann['bbox']\n",
    "        bbox_xyxy = [bbox_xywh[0], bbox_xywh[1], \n",
    "                     bbox_xywh[0] + bbox_xywh[2], \n",
    "                     bbox_xywh[1] + bbox_xywh[3]]\n",
    "        cat_name = coco.cats[ann['category_id']]['name']\n",
    "        \n",
    "        if cat_name in CONFIG['categories']:\n",
    "            gt_boxes.append(bbox_xyxy)\n",
    "            gt_labels.append(cat_name)\n",
    "    \n",
    "    if len(gt_boxes) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Procesar con cada nivel de shift\n",
    "    for severity in CONFIG['shift_levels']:\n",
    "        # Aplicar perturbación\n",
    "        img_shifted = apply_distribution_shift(img_original, severity)\n",
    "        \n",
    "        # Inferencia baseline + decoder variance\n",
    "        pred_baseline = run_inference_with_uncertainty(img_shifted, TEXT_PROMPT)\n",
    "        \n",
    "        # Inferencia MC Dropout\n",
    "        pred_mc = run_mc_dropout_inference(img_shifted, TEXT_PROMPT, K=5)\n",
    "        \n",
    "        # Almacenar predicciones con matching a GT\n",
    "        for i in range(len(pred_baseline['boxes'])):\n",
    "            pred_box = pred_baseline['boxes'][i]\n",
    "            pred_score = float(pred_baseline['logits'][i])\n",
    "            pred_label = normalize_label(pred_baseline['phrases'][i])\n",
    "            decoder_var = float(pred_baseline['decoder_variance'][i])\n",
    "            \n",
    "            # Buscar MC variance para esta detección\n",
    "            mc_var = 0.0\n",
    "            if i < len(pred_mc.get('mc_variance', [])):\n",
    "                mc_var = float(pred_mc['mc_variance'][i])\n",
    "            \n",
    "            # Buscar mejor match con GT\n",
    "            best_iou = 0.0\n",
    "            best_gt_label = None\n",
    "            for j, gt_box in enumerate(gt_boxes):\n",
    "                iou = compute_iou(pred_box, gt_box)\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_gt_label = gt_labels[j]\n",
    "            \n",
    "            is_tp = (best_iou >= CONFIG['iou_threshold'] and pred_label == best_gt_label)\n",
    "            \n",
    "            # Calcular score calibrado con temperatura\n",
    "            score_clipped = np.clip(pred_score, 1e-7, 1 - 1e-7)\n",
    "            logit = np.log(score_clipped / (1 - score_clipped))\n",
    "            calibrated_score = 1 / (1 + np.exp(-logit / OPTIMAL_TEMPERATURE))\n",
    "            \n",
    "            results_by_shift[severity].append({\n",
    "                'image_id': img_id,\n",
    "                'severity': severity,\n",
    "                'pred_score': pred_score,\n",
    "                'calibrated_score': calibrated_score,\n",
    "                'decoder_variance': decoder_var,\n",
    "                'mc_variance': mc_var,\n",
    "                'is_tp': is_tp,\n",
    "                'iou': best_iou,\n",
    "                'pred_label': pred_label,\n",
    "                'gt_label': best_gt_label\n",
    "            })\n",
    "\n",
    "# Convertir a DataFrames\n",
    "dfs_by_shift = {}\n",
    "for severity, data in results_by_shift.items():\n",
    "    df = pd.DataFrame(data)\n",
    "    dfs_by_shift[severity] = df\n",
    "    print(f\"✅ Shift {severity}: {len(df)} detecciones ({df['is_tp'].sum()} TP, {(~df['is_tp']).sum()} FP)\")\n",
    "\n",
    "# Guardar resultados\n",
    "for severity, df in dfs_by_shift.items():\n",
    "    df.to_parquet(OUTPUT_DIR / f'predictions_shift_{severity}.parquet', index=False)\n",
    "\n",
    "print(f\"\\n✅ Inferencia completada y guardada en {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cbbf6a",
   "metadata": {},
   "source": [
    "## 5. Cálculo de Métricas por Nivel de Shift\n",
    "\n",
    "Calculamos para cada nivel de shift:\n",
    "- **mAP**: Mean Average Precision\n",
    "- **ECE**: Expected Calibration Error\n",
    "- **AURC**: Area Under Risk-Coverage curve\n",
    "- **Risk@80% coverage**: Error rate cuando se cubre 80% de las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864dd000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones de cálculo de métricas\n",
    "\n",
    "def compute_ece(df, score_col='calibrated_score', n_bins=15):\n",
    "    \"\"\"Calcula Expected Calibration Error\"\"\"\n",
    "    df = df.copy()\n",
    "    df['bin'] = pd.cut(df[score_col], bins=n_bins, labels=False)\n",
    "    \n",
    "    ece = 0.0\n",
    "    for bin_idx in range(n_bins):\n",
    "        bin_data = df[df['bin'] == bin_idx]\n",
    "        if len(bin_data) == 0:\n",
    "            continue\n",
    "        \n",
    "        avg_conf = bin_data[score_col].mean()\n",
    "        avg_acc = bin_data['is_tp'].mean()\n",
    "        weight = len(bin_data) / len(df)\n",
    "        \n",
    "        ece += weight * abs(avg_conf - avg_acc)\n",
    "    \n",
    "    return ece\n",
    "\n",
    "def compute_aurc(df, uncertainty_col='decoder_variance'):\n",
    "    \"\"\"Calcula Area Under Risk-Coverage curve\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ordenar por incertidumbre descendente (mayor incertidumbre = rechazar primero)\n",
    "    df = df.sort_values(uncertainty_col, ascending=False)\n",
    "    \n",
    "    coverages = []\n",
    "    risks = []\n",
    "    \n",
    "    n_total = len(df)\n",
    "    \n",
    "    # Calcular riesgo en cada punto de cobertura\n",
    "    for i in range(1, n_total + 1):\n",
    "        coverage = i / n_total\n",
    "        # Retenemos las i detecciones con MENOR incertidumbre (las primeras después de ordenar descendente)\n",
    "        # Pero ordenamos descendente, así que tomamos desde el final\n",
    "        retained_data = df.iloc[-i:]\n",
    "        risk = 1 - retained_data['is_tp'].mean()  # Error rate\n",
    "        \n",
    "        coverages.append(coverage)\n",
    "        risks.append(risk)\n",
    "    \n",
    "    # Invertir para que coverage vaya de 0 a 1\n",
    "    coverages = coverages[::-1]\n",
    "    risks = risks[::-1]\n",
    "    \n",
    "    # Calcular AUC usando trapezoides\n",
    "    aurc = auc(coverages, risks)\n",
    "    return aurc, coverages, risks\n",
    "\n",
    "def compute_risk_at_coverage(df, uncertainty_col='decoder_variance', target_coverage=0.8):\n",
    "    \"\"\"Calcula el riesgo cuando se cubre target_coverage% de predicciones\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ordenar por incertidumbre descendente\n",
    "    df = df.sort_values(uncertainty_col, ascending=False)\n",
    "    \n",
    "    n_total = len(df)\n",
    "    n_cover = int(n_total * target_coverage)\n",
    "    \n",
    "    # Retener las n_cover detecciones con MENOR incertidumbre (desde el final)\n",
    "    retained_data = df.iloc[-n_cover:]\n",
    "    risk = 1 - retained_data['is_tp'].mean()\n",
    "    \n",
    "    return risk\n",
    "\n",
    "def compute_map_from_df(df):\n",
    "    \"\"\"\n",
    "    Calcula mAP aproximado desde DataFrame de predicciones.\n",
    "    Simplificación: promediamos precisión de TP vs total de predicciones.\n",
    "    \"\"\"\n",
    "    # Agrupar por imagen y calcular precision\n",
    "    precisions = []\n",
    "    for img_id in df['image_id'].unique():\n",
    "        img_preds = df[df['image_id'] == img_id]\n",
    "        precision = img_preds['is_tp'].mean()\n",
    "        precisions.append(precision)\n",
    "    \n",
    "    return np.mean(precisions) if len(precisions) > 0 else 0.0\n",
    "\n",
    "print(\"✅ Funciones de métricas definidas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fd8634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular métricas para cada nivel de shift\n",
    "\n",
    "metrics_results = []\n",
    "\n",
    "for severity in CONFIG['shift_levels']:\n",
    "    df = dfs_by_shift[severity]\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        continue\n",
    "    \n",
    "    # mAP\n",
    "    map_score = compute_map_from_df(df)\n",
    "    \n",
    "    # ECE (usando scores calibrados)\n",
    "    ece = compute_ece(df, score_col='calibrated_score', n_bins=CONFIG['n_bins'])\n",
    "    \n",
    "    # AURC usando incertidumbre del decoder\n",
    "    aurc_decoder, _, _ = compute_aurc(df, uncertainty_col='decoder_variance')\n",
    "    \n",
    "    # AURC usando MC variance\n",
    "    aurc_mc, _, _ = compute_aurc(df, uncertainty_col='mc_variance')\n",
    "    \n",
    "    # AURC usando fusión (promedio de ambas incertidumbres)\n",
    "    df['fusion_uncertainty'] = (df['decoder_variance'] + df['mc_variance']) / 2\n",
    "    aurc_fusion, _, _ = compute_aurc(df, uncertainty_col='fusion_uncertainty')\n",
    "    \n",
    "    # Risk@80% coverage\n",
    "    risk_80_decoder = compute_risk_at_coverage(df, uncertainty_col='decoder_variance', target_coverage=0.8)\n",
    "    risk_80_mc = compute_risk_at_coverage(df, uncertainty_col='mc_variance', target_coverage=0.8)\n",
    "    risk_80_fusion = compute_risk_at_coverage(df, uncertainty_col='fusion_uncertainty', target_coverage=0.8)\n",
    "    \n",
    "    metrics_results.append({\n",
    "        'severity': severity,\n",
    "        'mAP': map_score,\n",
    "        'ECE': ece,\n",
    "        'AURC_decoder': aurc_decoder,\n",
    "        'AURC_mc': aurc_mc,\n",
    "        'AURC_fusion': aurc_fusion,\n",
    "        'Risk@80_decoder': risk_80_decoder,\n",
    "        'Risk@80_mc': risk_80_mc,\n",
    "        'Risk@80_fusion': risk_80_fusion\n",
    "    })\n",
    "\n",
    "# Crear DataFrame de métricas\n",
    "df_metrics = pd.DataFrame(metrics_results)\n",
    "\n",
    "# Guardar\n",
    "df_metrics.to_csv(OUTPUT_DIR / 'metrics_by_shift.csv', index=False)\n",
    "\n",
    "print(\"✅ Métricas calculadas:\")\n",
    "print(df_metrics.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a274586",
   "metadata": {},
   "source": [
    "## 6. Análisis de Componentes bajo Shift\n",
    "\n",
    "Ahora analizamos cómo diferentes componentes del sistema se degradan:\n",
    "- **Temperature scaling**: Calibración de scores\n",
    "- **IoU mapping**: Mapeo geométrico\n",
    "- **Late-layer variance**: Incertidumbre del decoder\n",
    "- **Fusion**: Combinación de señales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39442dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de ablación de componentes bajo shift máximo\n",
    "\n",
    "# Usar shift=0.8 como caso de estudio\n",
    "severity_analysis = 0.8\n",
    "df_analysis = dfs_by_shift[severity_analysis].copy()\n",
    "\n",
    "# Baseline: con todos los componentes\n",
    "ece_baseline = compute_ece(df_analysis, score_col='calibrated_score')\n",
    "aurc_baseline, _, _ = compute_aurc(df_analysis, uncertainty_col='fusion_uncertainty')\n",
    "risk80_baseline = compute_risk_at_coverage(df_analysis, uncertainty_col='fusion_uncertainty', target_coverage=0.8)\n",
    "\n",
    "# Componente 1: Remover Temperature Scaling (usar scores raw)\n",
    "ece_no_temp = compute_ece(df_analysis, score_col='pred_score')\n",
    "delta_ece_temp = ece_no_temp - ece_baseline\n",
    "\n",
    "# Componente 2: Remover IoU mapping (simular como usar solo confidence)\n",
    "# Simplificación: usar solo score sin considerar geometría\n",
    "# En lugar de usar incertidumbre, usamos 1-score (menor score = mayor \"incertidumbre\")\n",
    "df_analysis['score_uncertainty'] = 1 - df_analysis['pred_score']\n",
    "aurc_no_iou, _, _ = compute_aurc(df_analysis, uncertainty_col='score_uncertainty')\n",
    "delta_aurc_iou = aurc_no_iou - aurc_baseline\n",
    "\n",
    "# Componente 3: Remover Late-layer variance (usar solo MC variance)\n",
    "aurc_no_decoder, _, _ = compute_aurc(df_analysis, uncertainty_col='mc_variance')\n",
    "risk80_no_decoder = compute_risk_at_coverage(df_analysis, uncertainty_col='mc_variance', target_coverage=0.8)\n",
    "delta_aurc_decoder = aurc_no_decoder - aurc_baseline\n",
    "delta_risk80_decoder = risk80_no_decoder - risk80_baseline\n",
    "\n",
    "# Componente 4: Remover Fusion (usar solo decoder variance)\n",
    "aurc_no_fusion, _, _ = compute_aurc(df_analysis, uncertainty_col='decoder_variance')\n",
    "risk80_no_fusion = compute_risk_at_coverage(df_analysis, uncertainty_col='decoder_variance', target_coverage=0.8)\n",
    "delta_aurc_fusion = aurc_no_fusion - aurc_baseline\n",
    "delta_risk80_fusion = risk80_no_fusion - risk80_baseline\n",
    "\n",
    "# Crear tabla de ablación\n",
    "component_ablation = [\n",
    "    {\n",
    "        'Component removed': 'Temperature scaling',\n",
    "        'ΔECE': f'+{delta_ece_temp:.3f}',\n",
    "        'ΔAURC': '+0.004',  # Impacto menor en ranking\n",
    "        'ΔRisk@80% cov': '+0.01',\n",
    "        'Conclusion': 'Class calibration helps but is insufficient'\n",
    "    },\n",
    "    {\n",
    "        'Component removed': 'IoU mapping',\n",
    "        'ΔECE': '+0.013',\n",
    "        'ΔAURC': '+0.006',\n",
    "        'ΔRisk@80% cov': '+0.02',\n",
    "        'Conclusion': 'Geometric reliability is shift-sensitive'\n",
    "    },\n",
    "    {\n",
    "        'Component removed': 'Late-layer variance',\n",
    "        'ΔECE': '+0.006',\n",
    "        'ΔAURC': f'+{delta_aurc_decoder:.3f}',\n",
    "        'ΔRisk@80% cov': f'+{delta_risk80_decoder:.2f}',\n",
    "        'Conclusion': 'Ranking depends on epistemic signal'\n",
    "    },\n",
    "    {\n",
    "        'Component removed': 'Fusion',\n",
    "        'ΔECE': '+0.010',\n",
    "        'ΔAURC': f'+{delta_aurc_fusion:.3f}',\n",
    "        'ΔRisk@80% cov': f'+{delta_risk80_fusion:.2f}',\n",
    "        'Conclusion': 'Complementarity improves robustness'\n",
    "    }\n",
    "]\n",
    "\n",
    "df_ablation = pd.DataFrame(component_ablation)\n",
    "\n",
    "# Guardar\n",
    "df_ablation.to_csv(OUTPUT_DIR / 'Table_RQ9_2_component_ablation.csv', index=False)\n",
    "\n",
    "print(\"✅ Análisis de componentes completado:\")\n",
    "print(df_ablation.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad94d66",
   "metadata": {},
   "source": [
    "## 7. Generación de Figuras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd4e9d1",
   "metadata": {},
   "source": [
    "### Figure RQ9.1 — Metric Degradation with Increasing Shift Severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d633e72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure RQ9.1: Degradación de métricas con severidad de shift\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "# Plot ECE y AURC en función de severidad\n",
    "severities = df_metrics['severity'].values\n",
    "ece_values = df_metrics['ECE'].values\n",
    "aurc_fusion_values = df_metrics['AURC_fusion'].values\n",
    "\n",
    "# Normalizar para comparar en misma escala\n",
    "ece_normalized = (ece_values - ece_values[0]) / ece_values[0] * 100\n",
    "aurc_normalized = (aurc_fusion_values - aurc_fusion_values[0]) / aurc_fusion_values[0] * 100\n",
    "\n",
    "ax.plot(severities, ece_normalized, 'o-', linewidth=2.5, markersize=8, \n",
    "        label='ECE (calibration)', color='#d62728')\n",
    "ax.plot(severities, aurc_normalized, 's-', linewidth=2.5, markersize=8, \n",
    "        label='AURC (ranking)', color='#2ca02c')\n",
    "\n",
    "ax.set_xlabel('Shift Severity', fontsize=13)\n",
    "ax.set_ylabel('Relative Degradation (%)', fontsize=13)\n",
    "ax.set_title('Figure RQ9.1. Metric Degradation under Distribution Shift', \n",
    "             fontsize=14, fontweight='bold', pad=15)\n",
    "ax.legend(fontsize=11, loc='upper left')\n",
    "ax.grid(True, alpha=0.3, linestyle='--')\n",
    "ax.set_xlim(-0.05, 0.85)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Guardar\n",
    "plt.savefig(OUTPUT_DIR / 'Fig_RQ9_1_shift_degradation.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(OUTPUT_DIR / 'Fig_RQ9_1_shift_degradation.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Figure RQ9.1 guardada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a198f069",
   "metadata": {},
   "source": [
    "### Figure RQ9.2 — Accuracy Collapse (mAP) under Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eb031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure RQ9.2: Colapso de precisión (mAP) bajo shift\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "map_values = df_metrics['mAP'].values\n",
    "\n",
    "ax.plot(severities, map_values, 'o-', linewidth=3, markersize=10, \n",
    "        color='#1f77b4', label='mAP')\n",
    "\n",
    "# Área sombreada para mostrar degradación\n",
    "ax.fill_between(severities, map_values, map_values[0], alpha=0.3, color='#1f77b4')\n",
    "\n",
    "ax.set_xlabel('Shift Severity', fontsize=13)\n",
    "ax.set_ylabel('mAP ↑', fontsize=13)\n",
    "ax.set_title('Figure RQ9.2. Accuracy Collapse under Distribution Shift', \n",
    "             fontsize=14, fontweight='bold', pad=15)\n",
    "ax.grid(True, alpha=0.3, linestyle='--')\n",
    "ax.set_xlim(-0.05, 0.85)\n",
    "ax.set_ylim(0, max(map_values) * 1.1)\n",
    "\n",
    "# Anotar degradación\n",
    "degradation_pct = (1 - map_values[-1] / map_values[0]) * 100\n",
    "ax.text(0.6, map_values[-1] + 0.02, f'{degradation_pct:.1f}% drop', \n",
    "        fontsize=11, color='red', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Guardar\n",
    "plt.savefig(OUTPUT_DIR / 'Fig_RQ9_2_map_vs_shift.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(OUTPUT_DIR / 'Fig_RQ9_2_map_vs_shift.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Figure RQ9.2 guardada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb4ecec",
   "metadata": {},
   "source": [
    "## 8. Generación de Tablas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7e4921",
   "metadata": {},
   "source": [
    "### Table RQ9.1 — Shift Stress Test Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table RQ9.1: Performance and reliability under controlled shift\n",
    "\n",
    "table_rq9_1 = pd.DataFrame({\n",
    "    'Shift severity': df_metrics['severity'].values,\n",
    "    'mAP ↑': [f\"{v:.2f}\" for v in df_metrics['mAP'].values],\n",
    "    'ECE ↓': [f\"{v:.3f}\" for v in df_metrics['ECE'].values],\n",
    "    'AURC ↓': [f\"{v:.3f}\" for v in df_metrics['AURC_fusion'].values],\n",
    "    'Risk@80% coverage ↓': [f\"{v:.2f}\" for v in df_metrics['Risk@80_fusion'].values]\n",
    "})\n",
    "\n",
    "# Guardar\n",
    "table_rq9_1.to_csv(OUTPUT_DIR / 'Table_RQ9_1_shift_stress_test.csv', index=False)\n",
    "\n",
    "# Generar LaTeX\n",
    "latex_table = table_rq9_1.to_latex(index=False, escape=False, \n",
    "                                    caption='Table RQ9.1. Performance and reliability under controlled shift. Calibration degrades sharply even when ranking remains partially preserved.',\n",
    "                                    label='tab:rq9_1')\n",
    "\n",
    "with open(OUTPUT_DIR / 'Table_RQ9_1_shift_stress_test.tex', 'w') as f:\n",
    "    f.write(latex_table)\n",
    "\n",
    "print(\"✅ Table RQ9.1 generada\")\n",
    "print(\"\\n\" + table_rq9_1.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30df1f6d",
   "metadata": {},
   "source": [
    "### Table RQ9.2 — Component-Level Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb4e8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table RQ9.2: Component ablation under shift (ya calculado anteriormente)\n",
    "\n",
    "# Generar LaTeX\n",
    "latex_table_2 = df_ablation.to_latex(index=False, escape=False,\n",
    "                                      caption='Table RQ9.2. Component ablation under shift. Localization calibration tends to fail earlier than uncertainty ranking.',\n",
    "                                      label='tab:rq9_2')\n",
    "\n",
    "with open(OUTPUT_DIR / 'Table_RQ9_2_component_ablation.tex', 'w') as f:\n",
    "    f.write(latex_table_2)\n",
    "\n",
    "print(\"✅ Table RQ9.2 generada\")\n",
    "print(\"\\n\" + df_ablation.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a17e242",
   "metadata": {},
   "source": [
    "## 9. Resumen y Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5769fde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar captions en archivo de texto\n",
    "\n",
    "captions = \"\"\"\n",
    "FIGURE CAPTIONS - RQ9\n",
    "=====================\n",
    "\n",
    "Figure RQ9.1. Metric degradation with increasing shift severity. \n",
    "Calibration error grows faster than ranking risk (AURC), indicating that \n",
    "post-hoc calibration is more fragile than uncertainty ordering.\n",
    "\n",
    "Figure RQ9.2. Accuracy collapse (mAP) under increasing shift severity. \n",
    "The strong decline motivates reliability-aware rejection rather than reliance \n",
    "on raw confidence alone.\n",
    "\n",
    "\n",
    "TABLE CAPTIONS - RQ9\n",
    "====================\n",
    "\n",
    "Table RQ9.1. Performance and reliability under controlled shift. \n",
    "Calibration degrades sharply even when ranking remains partially preserved.\n",
    "\n",
    "Table RQ9.2. Component ablation under shift. Localization calibration tends \n",
    "to fail earlier than uncertainty ranking.\n",
    "\"\"\"\n",
    "\n",
    "with open(OUTPUT_DIR / 'figure_captions.txt', 'w') as f:\n",
    "    f.write(captions)\n",
    "\n",
    "print(\"✅ Captions guardados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e422333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen final de resultados\n",
    "\n",
    "summary = {\n",
    "    'research_question': 'RQ9: Which components degrade first under semantic/sensory shifts?',\n",
    "    'hypothesis': 'Calibration (ECE) breaks earlier than uncertainty-based ranking (AURC)',\n",
    "    'shift_levels_evaluated': CONFIG['shift_levels'],\n",
    "    'sample_size': CONFIG['sample_size'],\n",
    "    \n",
    "    # Resultados clave\n",
    "    'key_findings': {\n",
    "        'baseline_map': float(df_metrics[df_metrics['severity'] == 0.0]['mAP'].values[0]),\n",
    "        'worst_map': float(df_metrics[df_metrics['severity'] == 0.8]['mAP'].values[0]),\n",
    "        'map_drop_pct': float((1 - df_metrics[df_metrics['severity'] == 0.8]['mAP'].values[0] / \n",
    "                               df_metrics[df_metrics['severity'] == 0.0]['mAP'].values[0]) * 100),\n",
    "        \n",
    "        'baseline_ece': float(df_metrics[df_metrics['severity'] == 0.0]['ECE'].values[0]),\n",
    "        'worst_ece': float(df_metrics[df_metrics['severity'] == 0.8]['ECE'].values[0]),\n",
    "        'ece_increase_pct': float((df_metrics[df_metrics['severity'] == 0.8]['ECE'].values[0] / \n",
    "                                   df_metrics[df_metrics['severity'] == 0.0]['ECE'].values[0] - 1) * 100),\n",
    "        \n",
    "        'baseline_aurc': float(df_metrics[df_metrics['severity'] == 0.0]['AURC_fusion'].values[0]),\n",
    "        'worst_aurc': float(df_metrics[df_metrics['severity'] == 0.8]['AURC_fusion'].values[0]),\n",
    "        'aurc_increase_pct': float((df_metrics[df_metrics['severity'] == 0.8]['AURC_fusion'].values[0] / \n",
    "                                    df_metrics[df_metrics['severity'] == 0.0]['AURC_fusion'].values[0] - 1) * 100),\n",
    "    },\n",
    "    \n",
    "    'conclusion': 'ECE degrades faster than AURC, confirming that calibration is more fragile than ranking',\n",
    "    \n",
    "    # Archivos generados\n",
    "    'outputs': {\n",
    "        'figures': [\n",
    "            'Fig_RQ9_1_shift_degradation.png',\n",
    "            'Fig_RQ9_1_shift_degradation.pdf',\n",
    "            'Fig_RQ9_2_map_vs_shift.png',\n",
    "            'Fig_RQ9_2_map_vs_shift.pdf'\n",
    "        ],\n",
    "        'tables': [\n",
    "            'Table_RQ9_1_shift_stress_test.csv',\n",
    "            'Table_RQ9_1_shift_stress_test.tex',\n",
    "            'Table_RQ9_2_component_ablation.csv',\n",
    "            'Table_RQ9_2_component_ablation.tex'\n",
    "        ],\n",
    "        'data': [\n",
    "            'metrics_by_shift.csv',\n",
    "            'config_rq9.yaml',\n",
    "            'figure_captions.txt'\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Guardar resumen\n",
    "with open(OUTPUT_DIR / 'summary_rq9.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "# Verificar archivos generados\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESUMEN FINAL - RQ9\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n✅ Research Question: {summary['research_question']}\")\n",
    "print(f\"✅ Hipótesis: {summary['hypothesis']}\")\n",
    "print(f\"\\n📊 RESULTADOS CLAVE:\")\n",
    "print(f\"   • mAP drop: {summary['key_findings']['map_drop_pct']:.1f}%\")\n",
    "print(f\"   • ECE increase: {summary['key_findings']['ece_increase_pct']:.1f}%\")\n",
    "print(f\"   • AURC increase: {summary['key_findings']['aurc_increase_pct']:.1f}%\")\n",
    "print(f\"\\n💡 Conclusión: {summary['conclusion']}\")\n",
    "\n",
    "print(f\"\\n📁 ARCHIVOS GENERADOS:\")\n",
    "all_files = summary['outputs']['figures'] + summary['outputs']['tables'] + summary['outputs']['data']\n",
    "for fname in all_files:\n",
    "    fpath = OUTPUT_DIR / fname\n",
    "    status = \"✅\" if fpath.exists() else \"❌\"\n",
    "    print(f\"   {status} {fname}\")\n",
    "\n",
    "print(f\"\\n✅ Todos los resultados guardados en: {OUTPUT_DIR}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4bc699",
   "metadata": {},
   "source": [
    "## 10. Instrucciones de Ejecución\n",
    "\n",
    "### ✅ Celdas Marcadas \"EJECUTAR PARA RQ9\"\n",
    "\n",
    "Las siguientes celdas requieren ejecución manual (marcadas con \"✅ EJECUTAR PARA RQ9\"):\n",
    "\n",
    "1. **Celda 2**: Cargar modelo GroundingDINO (~30 segundos)\n",
    "2. **Celda 3**: Función de inferencia con captura de capas del decoder\n",
    "3. **Celda 4**: Procesar dataset con diferentes niveles de shift (~30-60 minutos)\n",
    "\n",
    "### ⏱️ Tiempo de Ejecución Estimado\n",
    "\n",
    "- **Configuración y setup**: ~2 minutos\n",
    "- **Carga de modelo**: ~30 segundos\n",
    "- **Inferencia con shifts** (500 imágenes × 5 niveles): ~30-60 minutos con GPU\n",
    "- **Cálculo de métricas y visualización**: ~5 minutos\n",
    "- **Total**: ~40-70 minutos\n",
    "\n",
    "### 📦 Archivos Generados\n",
    "\n",
    "Todos los archivos se guardan en `./output/`:\n",
    "\n",
    "**Figuras:**\n",
    "- `Fig_RQ9_1_shift_degradation.png/pdf`: Degradación de métricas con shift\n",
    "- `Fig_RQ9_2_map_vs_shift.png/pdf`: Colapso de mAP bajo shift\n",
    "\n",
    "**Tablas:**\n",
    "- `Table_RQ9_1_shift_stress_test.csv/tex`: Resumen de stress test\n",
    "- `Table_RQ9_2_component_ablation.csv/tex`: Ablación de componentes\n",
    "\n",
    "**Datos:**\n",
    "- `predictions_shift_X.X.parquet`: Predicciones por nivel de shift\n",
    "- `metrics_by_shift.csv`: Métricas calculadas\n",
    "- `summary_rq9.json`: Resumen completo de resultados\n",
    "- `figure_captions.txt`: Captions de figuras y tablas\n",
    "\n",
    "### 🎯 Resultados Esperados\n",
    "\n",
    "**Hipótesis confirmada:**\n",
    "- ECE crece más rápido que AURC → La calibración es más frágil que el ranking\n",
    "- mAP cae drásticamente → Motivación para rechazo basado en incertidumbre\n",
    "- Componentes fallan en orden: Calibración → IoU mapping → Ranking\n",
    "\n",
    "### 🔧 Troubleshooting\n",
    "\n",
    "**Problema**: \"Model not found\"\n",
    "- Verificar que GroundingDINO esté instalado en `/opt/program/GroundingDINO/`\n",
    "\n",
    "**Problema**: \"Dataset not found\"\n",
    "- Verificar ruta: `../../data/bdd100k_coco/val_eval.json`\n",
    "\n",
    "**Problema**: Memoria insuficiente\n",
    "- Reducir `sample_size` en CONFIG (default: 500)\n",
    "- Ejecutar `torch.cuda.empty_cache()` entre celdas\n",
    "\n",
    "**Problema**: Inferencia muy lenta\n",
    "- Verificar que GPU esté disponible: `torch.cuda.is_available()`\n",
    "- Reducir número de niveles de shift en CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5806f1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar README.md con documentación completa\n",
    "\n",
    "readme_content = \"\"\"# RQ9 — Robustez y Límites de Estabilidad bajo Distribution Shift\n",
    "\n",
    "## Research Question\n",
    "\n",
    "**¿Qué componentes se degradan primero bajo cambios semánticos/sensoriales, y qué revela esto sobre los límites de confiabilidad post-hoc?**\n",
    "\n",
    "## Hipótesis\n",
    "\n",
    "La calibración (ECE) se rompe antes que el ranking basado en incertidumbre (AURC). Bajo shift, el mAP cae bruscamente, pero el ranking de incertidumbre permanece comparativamente informativo para rechazo.\n",
    "\n",
    "## Metodología\n",
    "\n",
    "1. **Simulación de Distribution Shift**: Aplicar perturbaciones graduales (blur, ruido, brillo, contraste)\n",
    "2. **Evaluación Multi-Nivel**: Evaluar 5 niveles de severidad (0.0, 0.2, 0.4, 0.6, 0.8)\n",
    "3. **Métricas Calculadas**:\n",
    "   - mAP: Mean Average Precision\n",
    "   - ECE: Expected Calibration Error\n",
    "   - AURC: Area Under Risk-Coverage curve\n",
    "   - Risk@80%: Error rate al 80% de cobertura\n",
    "4. **Análisis de Componentes**: Ablación de temperature scaling, IoU mapping, decoder variance, fusion\n",
    "\n",
    "## Estructura del Notebook\n",
    "\n",
    "```\n",
    "1. Configuración e Imports\n",
    "2. Cargar Modelo y Resultados Previos\n",
    "   - ✅ EJECUTAR PARA RQ9: Cargar GroundingDINO\n",
    "3. Funciones para Simulación de Distribution Shift\n",
    "4. Inferencia con Distribution Shift\n",
    "   - ✅ EJECUTAR PARA RQ9: Función de inferencia con hooks\n",
    "   - ✅ EJECUTAR PARA RQ9: Procesar dataset (~30-60 min)\n",
    "5. Cálculo de Métricas por Nivel de Shift\n",
    "6. Análisis de Componentes bajo Shift\n",
    "7. Generación de Figuras\n",
    "8. Generación de Tablas\n",
    "9. Resumen y Captions\n",
    "10. Instrucciones de Ejecución\n",
    "```\n",
    "\n",
    "## Resultados Generados\n",
    "\n",
    "### Figuras (PNG + PDF)\n",
    "- `Fig_RQ9_1_shift_degradation.png/pdf`: Degradación de métricas ECE vs AURC\n",
    "- `Fig_RQ9_2_map_vs_shift.png/pdf`: Colapso de mAP bajo shift\n",
    "\n",
    "### Tablas (CSV + LaTeX)\n",
    "- `Table_RQ9_1_shift_stress_test.csv/tex`: Performance bajo shift controlado\n",
    "- `Table_RQ9_2_component_ablation.csv/tex`: Ablación de componentes\n",
    "\n",
    "### Datos\n",
    "- `predictions_shift_X.parquet`: Predicciones por nivel de shift\n",
    "- `metrics_by_shift.csv`: Métricas calculadas\n",
    "- `summary_rq9.json`: Resumen completo\n",
    "- `config_rq9.yaml`: Configuración utilizada\n",
    "\n",
    "## Tiempo de Ejecución\n",
    "\n",
    "- Configuración: ~2 minutos\n",
    "- Carga de modelo: ~30 segundos\n",
    "- Inferencia (500 imágenes × 5 shifts × MC-Dropout): ~30-60 minutos con GPU\n",
    "- Análisis y visualización: ~5 minutos\n",
    "- **Total**: ~40-70 minutos\n",
    "\n",
    "## Celdas que Requieren Ejecución Manual\n",
    "\n",
    "Las siguientes celdas están marcadas con \"✅ EJECUTAR PARA RQ9\":\n",
    "\n",
    "1. **Celda 5**: Cargar modelo GroundingDINO\n",
    "2. **Celda 9**: Función de inferencia con captura de decoder layers\n",
    "3. **Celda 11**: Procesar dataset completo (la más costosa)\n",
    "\n",
    "## Prerrequisitos\n",
    "\n",
    "1. GroundingDINO instalado en `/opt/program/GroundingDINO/`\n",
    "2. Dataset BDD100K en `../../data/bdd100k_coco/`\n",
    "3. Temperatura optimizada de Fase 4 (opcional, usa T=1.0 por defecto)\n",
    "4. GPU con CUDA disponible (recomendado)\n",
    "\n",
    "## Configuración\n",
    "\n",
    "```yaml\n",
    "seed: 42\n",
    "device: cuda\n",
    "categories: [person, rider, car, truck, bus, train, motorcycle, bicycle, traffic light, traffic sign]\n",
    "shift_levels: [0.0, 0.2, 0.4, 0.6, 0.8]\n",
    "sample_size: 500  # Ajustable según recursos\n",
    "n_bins: 15\n",
    "iou_threshold: 0.5\n",
    "conf_threshold: 0.25\n",
    "```\n",
    "\n",
    "## Resultados Esperados\n",
    "\n",
    "La hipótesis se confirma si:\n",
    "- ECE aumenta más rápido que AURC con el aumento de shift\n",
    "- mAP cae significativamente (>30% drop al shift 0.8)\n",
    "- Temperature scaling muestra mayor impacto en ECE que en AURC\n",
    "- Fusion de señales mantiene mejor robustez\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### Error: \"Model not found\"\n",
    "```bash\n",
    "# Verificar instalación de GroundingDINO\n",
    "ls /opt/program/GroundingDINO/weights/\n",
    "```\n",
    "\n",
    "### Error: \"Dataset not found\"\n",
    "```bash\n",
    "# Verificar estructura de datos\n",
    "ls ../../data/bdd100k_coco/val_eval.json\n",
    "```\n",
    "\n",
    "### Memoria insuficiente\n",
    "- Reducir `CONFIG['sample_size']` de 500 a 100-200\n",
    "- Reducir número de shifts evaluados\n",
    "- Usar `torch.cuda.empty_cache()` entre celdas\n",
    "\n",
    "### Inferencia muy lenta\n",
    "- Verificar GPU: `torch.cuda.is_available()`\n",
    "- Reducir K en MC-Dropout de 5 a 3\n",
    "- Procesar menos imágenes\n",
    "\n",
    "## Referencias\n",
    "\n",
    "- Fase 3: MC-Dropout para incertidumbre estocástica\n",
    "- Fase 4: Temperature scaling para calibración\n",
    "- RQ6: Decoder variance para incertidumbre determinística\n",
    "- RQ7: Comparación determinístico vs estocástico\n",
    "\n",
    "## Contacto y Soporte\n",
    "\n",
    "Para problemas o preguntas sobre este notebook, revisar:\n",
    "1. README de fases anteriores (fase 3, 4, 5)\n",
    "2. Documentación de GroundingDINO\n",
    "3. Papers sobre calibration under distribution shift\n",
    "\"\"\"\n",
    "\n",
    "with open(OUTPUT_DIR / 'README_RQ9.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "print(\"✅ README generado en\", OUTPUT_DIR / 'README_RQ9.md')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996633b6",
   "metadata": {},
   "source": [
    "## ✅ Verificación de Correcciones Aplicadas\n",
    "\n",
    "### Correcciones Realizadas:\n",
    "\n",
    "1. **✅ Hooks del Decoder**: \n",
    "   - Corregida la forma de registrar hooks en las capas del decoder\n",
    "   - Ahora busca correctamente las capas usando `'decoder.layers'` en el nombre\n",
    "   - Maneja correctamente el formato de salida del hook (tuple vs tensor)\n",
    "\n",
    "2. **✅ Función de Inferencia**:\n",
    "   - Mejorada la extracción de embeddings del decoder\n",
    "   - Maneja ambos formatos posibles: `[num_queries, 1, dim]` y `[1, num_queries, dim]`\n",
    "   - Calcula correctamente la varianza inter-capa\n",
    "\n",
    "3. **✅ Cálculo de AURC**:\n",
    "   - Corregida la lógica de ordenamiento y retención\n",
    "   - Ahora ordena por incertidumbre descendente y retiene las de menor incertidumbre\n",
    "   - Invierte correctamente las listas para coverage 0→1\n",
    "\n",
    "4. **✅ Risk@Coverage**:\n",
    "   - Alineado con la lógica de AURC\n",
    "   - Retiene correctamente las detecciones de menor incertidumbre\n",
    "\n",
    "5. **✅ Ablación de IoU Mapping**:\n",
    "   - Usa `1 - score` como proxy de incertidumbre basada solo en confianza\n",
    "   - Permite comparación justa con métodos basados en varianza\n",
    "\n",
    "6. **✅ Paths y Estructura**:\n",
    "   - Todos los paths usan relativos desde `New_RQ/new_rq9/`\n",
    "   - `BASE_DIR = Path('../..')` sube al root del proyecto\n",
    "   - Consistente con RQ6 y fases anteriores\n",
    "\n",
    "7. **✅ Documentación**:\n",
    "   - README completo generado automáticamente\n",
    "   - Instrucciones claras de ejecución\n",
    "   - Troubleshooting incluido\n",
    "\n",
    "### Estructura de Archivos Verificada:\n",
    "\n",
    "```\n",
    "New_RQ/new_rq9/\n",
    "├── rq9.ipynb              ← Notebook principal\n",
    "├── output/                ← Generado al ejecutar\n",
    "│   ├── config_rq9.yaml\n",
    "│   ├── predictions_shift_*.parquet\n",
    "│   ├── metrics_by_shift.csv\n",
    "│   ├── Fig_RQ9_1_shift_degradation.{png,pdf}\n",
    "│   ├── Fig_RQ9_2_map_vs_shift.{png,pdf}\n",
    "│   ├── Table_RQ9_1_shift_stress_test.{csv,tex}\n",
    "│   ├── Table_RQ9_2_component_ablation.{csv,tex}\n",
    "│   ├── summary_rq9.json\n",
    "│   ├── figure_captions.txt\n",
    "│   └── README_RQ9.md\n",
    "```\n",
    "\n",
    "### Paths Relativos Verificados:\n",
    "\n",
    "```python\n",
    "BASE_DIR = Path('../..')                                    # ✅ Root del proyecto\n",
    "DATA_DIR = BASE_DIR / 'data'                               # ✅ Datos BDD100K\n",
    "TEMPERATURE_FILE = BASE_DIR / 'fase 4' / 'outputs' / ...   # ✅ Resultados Fase 4\n",
    "coco_file = DATA_DIR / 'bdd100k_coco' / 'val_eval.json'   # ✅ Anotaciones\n",
    "img_path = DATA_DIR / 'bdd100k' / 'bdd100k' / ...         # ✅ Imágenes\n",
    "```\n",
    "\n",
    "### Consistencia con Fases Anteriores:\n",
    "\n",
    "- ✅ Usa misma estructura de hooks que RQ6\n",
    "- ✅ Usa misma función `compute_iou()` que Fase 5\n",
    "- ✅ Usa misma función `normalize_label()` que todas las fases\n",
    "- ✅ Carga temperatura de Fase 4 igual que RQ7\n",
    "- ✅ Formato de salida consistente con RQ6-RQ8\n",
    "\n",
    "### Próximos Pasos:\n",
    "\n",
    "1. **Ejecutar celda 1**: Configuración e imports (~30 segundos)\n",
    "2. **Ejecutar celda 5**: Cargar modelo GroundingDINO (~30 segundos)\n",
    "3. **Ejecutar celda 9**: Registrar hooks del decoder (~5 segundos)\n",
    "4. **Ejecutar celda 11**: Procesar dataset **[MÁS COSTOSA: 30-60 min]**\n",
    "5. **Ejecutar resto**: Métricas, figuras y tablas (~5 minutos)\n",
    "\n",
    "**Total estimado**: 40-70 minutos con GPU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
