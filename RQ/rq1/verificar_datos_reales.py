"""
Script de VerificaciÃ³n RÃ¡pida: Datos Reales en Fase 5

Este script verifica si los archivos JSON de la Fase 5 contienen
las incertidumbres reales por capa del decoder.

Uso:
    python verificar_datos_reales.py
"""

import json
import numpy as np
from pathlib import Path


def verificar_datos_reales():
    """Verifica que los datos de Fase 5 contengan layer_uncertainties"""

    print("=" * 80)
    print("VERIFICACIÃ“N DE DATOS REALES PARA RQ1")
    print("=" * 80)

    # Ruta al archivo
    ruta_base = Path(
        __file__
    ).parent.parent.parent  # Sube 3 niveles: rq1 -> rq -> RQ -> base
    ruta_json = (
        ruta_base / "fase 5" / "outputs" / "comparison" / "eval_decoder_variance.json"
    )

    print(f"\nğŸ“‚ Ruta del archivo:")
    print(f"   {ruta_json}")

    # Verificar que existe
    if not ruta_json.exists():
        print(f"\nâŒ ERROR: Archivo no encontrado")
        print(f"   â†’ Debes ejecutar la Fase 5 primero")
        return False

    # Verificar tamaÃ±o
    tamanio_mb = ruta_json.stat().st_size / (1024 * 1024)
    print(f"\nğŸ“Š TamaÃ±o del archivo: {tamanio_mb:.2f} MB")

    if tamanio_mb < 0.5:
        print(f"   âš ï¸  Archivo parece muy pequeÃ±o, puede estar vacÃ­o o incompleto")

    # Cargar datos
    print(f"\nâ³ Cargando datos...")
    try:
        with open(ruta_json, "r") as f:
            data = json.load(f)
    except Exception as e:
        print(f"\nâŒ ERROR al cargar JSON: {e}")
        return False

    print(f"âœ… Datos cargados: {len(data)} predicciones")

    # Verificar estructura
    print(f"\nğŸ”‘ Campos disponibles en la primera predicciÃ³n:")
    for key in data[0].keys():
        tipo = type(data[0][key]).__name__
        if isinstance(data[0][key], list):
            tipo = f"list (len={len(data[0][key])})"
        print(f"   - {key:25s} : {tipo}")

    # Verificar layer_uncertainties
    print(f"\nğŸ” Verificando 'layer_uncertainties'...")

    if "layer_uncertainties" not in data[0]:
        print(f"\nâŒ ERROR: Campo 'layer_uncertainties' NO ENCONTRADO")
        print(f"\nğŸ’¡ SoluciÃ³n:")
        print(f"   1. Abre: fase 5/main.ipynb")
        print(f"   2. Verifica que la funciÃ³n inference_decoder_variance incluya:")
        print(f"      'layer_uncertainties': layer_scores")
        print(f"   3. Re-ejecuta las celdas de decoder_variance")
        print(f"   4. Verifica que el archivo JSON se actualizÃ³ (fecha reciente)")
        return False

    # Contar predicciones con layer_uncertainties
    con_layers = [
        p
        for p in data
        if "layer_uncertainties" in p and len(p.get("layer_uncertainties", [])) > 0
    ]
    porcentaje = len(con_layers) / len(data) * 100 if data else 0

    print(f"âœ… Campo 'layer_uncertainties' ENCONTRADO")
    print(f"   - Total predicciones: {len(data)}")
    print(f"   - Con layer_uncertainties: {len(con_layers)} ({porcentaje:.1f}%)")

    if len(con_layers) == 0:
        print(f"\nâŒ ERROR: Todas las predicciones tienen layer_uncertainties vacÃ­o")
        print(f"\nğŸ’¡ Posibles causas:")
        print(f"   - Los hooks no capturaron las capas del decoder")
        print(f"   - Hay un error en la lÃ³gica de captura")
        print(f"   - El modelo no ejecutÃ³ las capas como se esperaba")
        print(f"\nğŸ’¡ SoluciÃ³n:")
        print(f"   1. Agrega prints de debug en inference_decoder_variance:")
        print(f"      print(f'DEBUG: Capturados {{len(layer_logits)}} layers')")
        print(f"   2. Re-ejecuta y verifica que layer_logits no estÃ© vacÃ­o")
        return False

    # Analizar layer_uncertainties
    num_layers_list = [len(p["layer_uncertainties"]) for p in con_layers]
    num_layers_promedio = np.mean(num_layers_list)
    num_layers_min = min(num_layers_list)
    num_layers_max = max(num_layers_list)

    print(f"\nğŸ“Š EstadÃ­sticas de layer_uncertainties:")
    print(f"   - NÃºmero promedio de capas: {num_layers_promedio:.1f}")
    print(f"   - Rango de capas: [{num_layers_min}, {num_layers_max}]")

    if num_layers_promedio < 4:
        print(
            f"   âš ï¸  Advertencia: Pocas capas capturadas. Se esperaban ~6 capas del decoder"
        )

    # Ejemplos
    print(f"\nğŸ“ Ejemplos de layer_uncertainties:")
    for i in range(min(3, len(con_layers))):
        lu = con_layers[i]["layer_uncertainties"]
        scores_str = [f"{x:.4f}" for x in lu]
        print(f"   {i+1}. {scores_str}")

    # AnÃ¡lisis de valores
    all_layer_unc = [unc for p in con_layers for unc in p["layer_uncertainties"]]

    print(f"\nğŸ“ˆ AnÃ¡lisis de valores:")
    print(f"   - Total de valores: {len(all_layer_unc)}")
    print(f"   - Rango: [{min(all_layer_unc):.6f}, {max(all_layer_unc):.6f}]")
    print(f"   - Promedio: {np.mean(all_layer_unc):.6f}")
    print(f"   - DesviaciÃ³n estÃ¡ndar: {np.std(all_layer_unc):.6f}")

    # Verificar que no son todos iguales
    valores_unicos = len(set(all_layer_unc))
    print(f"   - Valores Ãºnicos: {valores_unicos}")

    if valores_unicos < 10:
        print(
            f"   âš ï¸  Advertencia: Muy pocos valores Ãºnicos. Los datos pueden no ser reales."
        )

    # Verificar patrÃ³n de refinamiento (capas tempranas > capas tardÃ­as)
    if len(con_layers) > 100:
        # Tomar muestra aleatoria
        muestra = np.random.choice(con_layers, size=100, replace=False)
        primeras_capas = np.mean(
            [
                p["layer_uncertainties"][0]
                for p in muestra
                if len(p["layer_uncertainties"]) >= 2
            ]
        )
        ultimas_capas = np.mean(
            [
                p["layer_uncertainties"][-1]
                for p in muestra
                if len(p["layer_uncertainties"]) >= 2
            ]
        )

        print(f"\nğŸ”¬ PatrÃ³n de refinamiento (muestra de 100 predicciones):")
        print(f"   - Promedio primera capa: {primeras_capas:.6f}")
        print(f"   - Promedio Ãºltima capa: {ultimas_capas:.6f}")
        print(f"   - Diferencia: {(primeras_capas - ultimas_capas):.6f}")

        if ultimas_capas < primeras_capas:
            print(
                f"   âœ… PatrÃ³n esperado: Las capas tardÃ­as tienen menor incertidumbre (mÃ¡s refinadas)"
            )
        else:
            print(
                f"   âš ï¸  PatrÃ³n inesperado: Las capas tardÃ­as tienen mayor incertidumbre"
            )

    # Verificar uncertainty (varianza global)
    uncertainties = [p.get("uncertainty", 0) for p in con_layers]
    uncertainties_no_cero = [u for u in uncertainties if u != 0]

    print(f"\nğŸ”¢ VerificaciÃ³n de 'uncertainty' (varianza global):")
    print(
        f"   - Predicciones con uncertainty != 0: {len(uncertainties_no_cero)}/{len(con_layers)}"
    )

    if len(uncertainties_no_cero) > 0:
        print(
            f"   - Rango: [{min(uncertainties_no_cero):.8f}, {max(uncertainties_no_cero):.8f}]"
        )
        print(f"   - Promedio: {np.mean(uncertainties_no_cero):.8f}")
    else:
        print(f"   âš ï¸  Todas las uncertainties son 0. Verifica el cÃ¡lculo de varianza.")

    # ConclusiÃ³n final
    print(f"\n{'='*80}")
    if porcentaje > 95 and num_layers_promedio >= 4 and valores_unicos > 100:
        print(f"âœ…âœ…âœ… DATOS REALES VERIFICADOS - LISTOS PARA RQ1")
        print(f"\nğŸ¯ PrÃ³ximo paso:")
        print(f"   - Ejecuta RQ1 con los datos reales")
        print(f"   - La funciÃ³n simulate_layer_uncertainties() serÃ¡ reemplazada")
        print(f"={'='*80}")
        return True
    else:
        print(f"âš ï¸  ADVERTENCIA: Los datos parecen tener problemas")
        print(f"\nğŸ’¡ RecomendaciÃ³n:")
        print(f"   - Revisa la implementaciÃ³n de inference_decoder_variance()")
        print(f"   - Re-ejecuta la Fase 5 con prints de debug")
        print(f"   - Verifica que los hooks capturen correctamente")
        print(f"={'='*80}")
        return False


if __name__ == "__main__":
    exito = verificar_datos_reales()

    if not exito:
        print(
            f"\nâŒ VerificaciÃ³n fallÃ³. Lee el anÃ¡lisis arriba para resolver problemas."
        )
        exit(1)
    else:
        print(f"\nâœ… VerificaciÃ³n exitosa. Puedes proceder con RQ1.")
        exit(0)
