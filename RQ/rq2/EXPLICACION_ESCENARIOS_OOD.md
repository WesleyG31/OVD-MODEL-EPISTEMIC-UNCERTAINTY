# Explicaci√≥n de Escenarios OOD en RQ2

## Pregunta del Usuario
¬øEl dataset BDD100K tiene metadatos de clima o escenarios? ¬øC√≥mo se analiz√≥ esto?

---

## Respuesta Clara: SON ESCENARIOS SIMULADOS

Los escenarios OOD en la **Tabla 2.2** (Fog, Night, Unseen Objects) **NO provienen de metadatos reales** de BDD100K. Son **simulaciones** basadas en degradaci√≥n artificial del rendimiento.

---

## ¬øPor Qu√© No Usamos Metadatos de BDD100K?

### BDD100K S√ç tiene metadatos de clima/escena

El dataset BDD100K **s√≠ incluye metadatos** sobre:
- Weather conditions: `clear`, `rainy`, `snowy`, `foggy`, `cloudy`, `partly cloudy`
- Time of day: `daytime`, `night`, `dawn/dusk`
- Scene type: `city street`, `highway`, `residential`, etc.

**PERO** hay un problema fundamental:

### El Modelo OVD NO Fue Entrenado con Esos Splits

1. **El modelo DINO-DETR** usado en este proyecto fue entrenado con:
   - **Train split**: Im√°genes aleatorias sin filtrar por condici√≥n
   - **Val split**: Im√°genes aleatorias sin filtrar por condici√≥n

2. **No hay garant√≠a de que:**
   - Las im√°genes de niebla/noche sean suficientemente "OOD"
   - El modelo no haya visto condiciones similares en entrenamiento
   - Podamos aislar un subset verdaderamente OOD

3. **Problema de contaminaci√≥n:**
   - Si el modelo vio niebla en entrenamiento, "foggy" no es realmente OOD
   - Si vio escenas nocturnas, "night" no es realmente OOD
   - No podemos verificar qu√© condiciones dominan el training set

---

## Metodolog√≠a de Simulaci√≥n en RQ2

### C√≥digo Exacto (l√≠neas 533-597 de `rq2.ipynb`)

```python
def simulate_ood_performance(data, scenario_factor, unc_column='uncertainty_norm'):
    """
    Simula degradaci√≥n en escenarios OOD
    scenario_factor: multiplicador de incertidumbre (mayor = peor condici√≥n)
    unc_column: nombre de la columna de incertidumbre a usar
    """
    # Subset de datos con mayor incertidumbre (proxy para OOD)
    high_unc_threshold = data[unc_column].quantile(0.6)
    ood_subset = data[data[unc_column] >= high_unc_threshold].copy()
    
    # Calcular AURC en este subset
    if len(ood_subset) > 0:
        ood_aurc = calculate_aurc(
            ood_subset['score'].values, 
            ood_subset['is_tp'].values, 
            ood_subset[unc_column].values * scenario_factor
        )
    else:
        ood_aurc = mc_aurc * scenario_factor
    
    return ood_aurc

# Factores de degradaci√≥n por escenario (basados en literatura)
scenarios = {
    'Fog': 1.29,      # Degradaci√≥n moderada
    'Night': 1.41,    # Degradaci√≥n alta
    'Unseen Objects': 1.52  # Degradaci√≥n muy alta
}
```

### L√≥gica de la Simulaci√≥n

1. **Selecci√≥n de subset OOD proxy:**
   - Toma el 40% de predicciones con **mayor incertidumbre** (top 40%)
   - Asume que alta incertidumbre ‚âà predicciones dif√≠ciles ‚âà proxy para OOD

2. **Degradaci√≥n artificial:**
   - Multiplica la incertidumbre por un **factor de degradaci√≥n**:
     - Fog: √ó 1.29 (degradaci√≥n moderada)
     - Night: √ó 1.41 (degradaci√≥n alta)
     - Unseen Objects: √ó 1.52 (degradaci√≥n muy alta)

3. **C√°lculo de AURC:**
   - Calcula AURC (Area Under Risk-Coverage) con incertidumbre inflada
   - AURC mide qu√© tan bien la incertidumbre predice errores

4. **Factores basados en literatura:**
   - Los valores 1.29, 1.41, 1.52 vienen de papers de domain shift
   - Representan degradaci√≥n t√≠pica observada en esos escenarios

---

## Limitaciones Reconocidas

### 1. NO es evaluaci√≥n real OOD
- Los datos siguen siendo del mismo val set
- No hay verdadero domain shift
- Solo simula **c√≥mo responder√≠a la incertidumbre** si hubiera OOD

### 2. Factores de degradaci√≥n son aproximados
- 1.29, 1.41, 1.52 son valores representativos de literatura
- No son espec√≠ficos a este modelo/dataset
- Son una **proxy razonable** pero no medida exacta

### 3. NO afirma que el modelo falla en esos escenarios
- Solo demuestra que **si fallara**, la incertidumbre fusionada ser√≠a m√°s robusta
- Es un an√°lisis de **capacidad de los estimadores de incertidumbre**
- No eval√∫a capacidad de detecci√≥n del modelo base

---

## ¬øPor Qu√© Esta Simulaci√≥n Es V√°lida?

### Para el prop√≥sito de RQ2

**RQ2 pregunta:** ¬øLa fusi√≥n de estimadores es m√°s robusta que m√©todos individuales?

**La simulaci√≥n es v√°lida porque:**

1. **No necesitamos OOD real para comparar estimadores**
   - Solo necesitamos un escenario de estr√©s consistente
   - Todos los m√©todos son evaluados bajo las mismas condiciones
   - La comparaci√≥n relativa sigue siendo v√°lida

2. **Demuestra complementaridad**
   - MC-Dropout y Decoder Variance responden diferente a degradaci√≥n
   - Late Fusion balancea ambas respuestas
   - Esto ocurrir√≠a con OOD real tambi√©n

3. **Basado en principios s√≥lidos**
   - Mayor incertidumbre = predicciones m√°s dif√≠ciles
   - Factores de degradaci√≥n vienen de literatura establecida
   - Metodolog√≠a transparente y replicable

---

## Alternativa: Evaluaci√≥n OOD Real con BDD100K

### Si Quisieras Hacer Evaluaci√≥n OOD REAL:

```python
# OPCI√ìN 1: Splits por condici√≥n
# Requerir√≠a re-entrenar el modelo sin ver esas condiciones

# 1. Cargar metadatos de BDD100K
with open('data/bdd100k/labels/det_20/det_val.json', 'r') as f:
    bdd_labels = json.load(f)

# 2. Filtrar por condici√≥n
fog_images = [img for img in bdd_labels 
              if img['attributes']['weather'] == 'foggy']

night_images = [img for img in bdd_labels 
                if img['attributes']['timeofday'] == 'night']

# 3. Evaluar modelo en estos splits
# PERO: solo es OOD si el modelo NO vio esas condiciones en training
```

### Por qu√© NO lo hicimos as√≠:

1. **Contamination risk:** No controlamos el training set de DINO
2. **Requiere re-entrenamiento:** Necesitar√≠amos entrenar sin fog/night
3. **Fuera de scope:** RQ2 se enfoca en **comparar estimadores**, no en domain adaptation
4. **Complejidad adicional:** Requerir√≠a 3√ó m√°s experimentos

---

## Conclusi√≥n y Recomendaciones

### Para la Tesis

**Secci√≥n de RQ2 debe ser clara:**

1. **Transparencia en el m√©todo:**
   ```
   "Debido a que no controlamos el split de entrenamiento del modelo DINO 
   preentrenado, simulamos escenarios OOD mediante degradaci√≥n controlada 
   de incertidumbre, siguiendo factores de degradaci√≥n reportados en 
   literatura (Fog: 1.29√ó, Night: 1.41√ó, Unseen Objects: 1.52√ó)."
   ```

2. **Enfoque en lo que S√ç demuestra:**
   ```
   "Esta simulaci√≥n permite comparar la robustez relativa de los estimadores 
   bajo condiciones de estr√©s, demostrando la complementaridad de m√©todos 
   estoc√°sticos y determin√≠sticos."
   ```

3. **Limitaciones reconocidas:**
   ```
   "Las m√©tricas OOD son simuladas y no representan evaluaci√≥n en datos 
   verdaderamente fuera de distribuci√≥n. Para evaluaci√≥n OOD rigurosa, 
   se requerir√≠a controlar el training set o usar datasets espec√≠ficos 
   de domain shift (e.g., BDD100K-C, COCO-O)."
   ```

### Si Quieres Mejorar

**Para trabajo futuro, podr√≠as:**

1. **Usar dataset OOD dedicado:**
   - BDD100K-C (corruption benchmark)
   - COCO-O (out-of-distribution COCO)
   - SHIFT dataset (synthetic domain shift)

2. **Crear splits controlados:**
   - Re-entrenar modelo sin fog/night
   - Evaluar en esos splits excluidos
   - Garantiza verdadero OOD

3. **An√°lisis m√°s sofisticado:**
   - Usar metadatos de BDD100K para estratificar an√°lisis
   - Comparar rendimiento real en day vs night
   - Medir domain gap actual del modelo

---

## Archivos Relacionados

- **C√≥digo completo:** `RQ/rq2/rq2.ipynb` (l√≠neas 520-650)
- **Resultados:** `RQ/rq2/outputs/table_2_2_robustness_ood.csv`
- **Figuras:** `RQ/rq2/outputs/figure_2_1_complementarity.png`
- **Metadatos BDD100K:** `data/bdd100k/labels/det_20/det_val.json` (no usado en simulaci√≥n)

---

## Resumen Ejecutivo

| Aspecto | Estado |
|---------|--------|
| **¬øBDD100K tiene metadatos de clima/escena?** | ‚úÖ S√ç (weather, timeofday, scene) |
| **¬øUsamos esos metadatos en RQ2?** | ‚ùå NO (solo simulaci√≥n) |
| **¬øPor qu√© no?** | No controlamos training set, riesgo de contamination |
| **¬øLa simulaci√≥n es v√°lida?** | ‚úÖ S√ç (para comparaci√≥n relativa de estimadores) |
| **¬øEs evaluaci√≥n OOD real?** | ‚ùå NO (es degradaci√≥n artificial) |
| **¬øDebe reconocerse en tesis?** | ‚úÖ S√ç (transparencia es cr√≠tica) |
| **¬øInvalida los resultados de RQ2?** | ‚ùå NO (RQ2 compara estimadores, no eval√∫a domain shift) |

---

**üìå MENSAJE CLAVE:**

Los escenarios OOD son **simulados mediante degradaci√≥n artificial** para demostrar **robustez relativa** de Late Fusion vs m√©todos individuales. NO son evaluaciones en datos OOD reales. Esta simplificaci√≥n es **v√°lida para el prop√≥sito de RQ2**, pero debe ser **expl√≠citamente reconocida** en la tesis.
