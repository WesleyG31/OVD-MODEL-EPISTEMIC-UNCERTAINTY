{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d2f7f91",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/awsaf49/bdd100k-dataset\n",
    "https://www.kaggle.com/datasets/solesensei/solesensei_bdd100k?resource=download  (este use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05b1ef19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SP1VEVW\\Desktop\\projects\\OVD-Model-ADAS\\data\n",
      "c:\\Users\\SP1VEVW\\Desktop\\projects\\OVD-Model-ADAS\\data\\bdd100k ; exist: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)  \n",
    "BDD100K_DIR = os.path.join(HOME, \"bdd100k\")\n",
    "os.makedirs(BDD100K_DIR, exist_ok=True)\n",
    "print(BDD100K_DIR, \"; exist:\", os.path.exists(BDD100K_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8349b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycocotools\n",
      "  Using cached pycocotools-2.0.10-cp312-abi3-win_amd64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pycocotools) (2.2.6)\n",
      "Using cached pycocotools-2.0.10-cp312-abi3-win_amd64.whl (76 kB)\n",
      "Installing collected packages: pycocotools\n",
      "Successfully installed pycocotools-2.0.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9469a817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "1. VERIFICANDO DATOS\n",
      "==================================================\n",
      "\n",
      "Imágenes Val: True\n",
      "Labels Val: True\n",
      "Total imágenes Val: 10000\n",
      "Total anotaciones Val: 10000\n",
      "\n",
      "Categorías encontradas: 12\n",
      "  - car: 5062\n",
      "  - lane: 3808\n",
      "  - traffic sign: 1754\n",
      "  - traffic light: 1374\n",
      "  - drivable area: 873\n",
      "  - person: 746\n",
      "  - truck: 212\n",
      "  - bus: 91\n",
      "  - bike: 40\n",
      "  - rider: 35\n",
      "\n",
      "==================================================\n",
      "2. CONVIRTIENDO A FORMATO COCO\n",
      "==================================================\n",
      "\n",
      "Convirtiendo dataset completo...\n",
      "Total anotaciones Val: 10000\n",
      "\n",
      "Categorías encontradas: 12\n",
      "  - car: 5062\n",
      "  - lane: 3808\n",
      "  - traffic sign: 1754\n",
      "  - traffic light: 1374\n",
      "  - drivable area: 873\n",
      "  - person: 746\n",
      "  - truck: 212\n",
      "  - bus: 91\n",
      "  - bike: 40\n",
      "  - rider: 35\n",
      "\n",
      "==================================================\n",
      "2. CONVIRTIENDO A FORMATO COCO\n",
      "==================================================\n",
      "\n",
      "Convirtiendo dataset completo...\n",
      "Total imágenes procesadas: 10000\n",
      "Total anotaciones: 185074\n",
      "\n",
      "==================================================\n",
      "3. DIVIDIENDO EN 80% TRAIN / 20% VAL\n",
      "==================================================\n",
      "\n",
      "Total: 10000 imágenes\n",
      "Train: 8000 imágenes (80%)\n",
      "Val: 2000 imágenes (20%)\n",
      "\n",
      "Train: 8000 imgs, 148515 anns\n",
      "Val: 2000 imgs, 36559 anns\n",
      "\n",
      "==================================================\n",
      "4. GUARDANDO ARCHIVOS COCO\n",
      "==================================================\n",
      "Total imágenes procesadas: 10000\n",
      "Total anotaciones: 185074\n",
      "\n",
      "==================================================\n",
      "3. DIVIDIENDO EN 80% TRAIN / 20% VAL\n",
      "==================================================\n",
      "\n",
      "Total: 10000 imágenes\n",
      "Train: 8000 imágenes (80%)\n",
      "Val: 2000 imágenes (20%)\n",
      "\n",
      "Train: 8000 imgs, 148515 anns\n",
      "Val: 2000 imgs, 36559 anns\n",
      "\n",
      "==================================================\n",
      "4. GUARDANDO ARCHIVOS COCO\n",
      "==================================================\n",
      "\n",
      "✓ Train guardado: c:\\Users\\SP1VEVW\\Desktop\\projects\\OVD-Model-ADAS\\data\\bdd100k_coco\\val_calib.json\n",
      "\n",
      "✓ Train guardado: c:\\Users\\SP1VEVW\\Desktop\\projects\\OVD-Model-ADAS\\data\\bdd100k_coco\\val_calib.json\n",
      "✓ Val guardado: c:\\Users\\SP1VEVW\\Desktop\\projects\\OVD-Model-ADAS\\data\\bdd100k_coco\\val_eval.json\n",
      "\n",
      "==================================================\n",
      "5. ESTADÍSTICAS FINALES\n",
      "==================================================\n",
      "\n",
      "TRAIN:\n",
      "  Imágenes: 8000\n",
      "  Anotaciones: 148515\n",
      "  Promedio ann/img: 18.56\n",
      "  Top 5 categorías:\n",
      "    - car: 81743\n",
      "    - traffic sign: 28119\n",
      "    - traffic light: 21832\n",
      "    - person: 10716\n",
      "    - truck: 3470\n",
      "\n",
      "VAL:\n",
      "  Imágenes: 2000\n",
      "  Anotaciones: 36559\n",
      "  Promedio ann/img: 18.28\n",
      "  Top 5 categorías:\n",
      "    - car: 20763\n",
      "    - traffic sign: 6789\n",
      "    - traffic light: 5053\n",
      "    - person: 2546\n",
      "    - truck: 775\n",
      "\n",
      "==================================================\n",
      "✓ PROCESO COMPLETADO\n",
      "==================================================\n",
      "\n",
      "Archivos generados:\n",
      "1. c:\\Users\\SP1VEVW\\Desktop\\projects\\OVD-Model-ADAS\\data\\bdd100k_coco\\val_calib.json\n",
      "2. c:\\Users\\SP1VEVW\\Desktop\\projects\\OVD-Model-ADAS\\data\\bdd100k_coco\\val_eval.json\n",
      "\n",
      "Ahora puedes usar COCOeval para calcular mAP, AP@50, F1, etc.\n",
      "\n",
      "==================================================\n",
      "6. VALIDANDO CON PYCOCOTOOLS\n",
      "==================================================\n",
      "\n",
      "✓ Validando val_calib.json (80%)...\n",
      "loading annotations into memory...\n",
      "✓ Val guardado: c:\\Users\\SP1VEVW\\Desktop\\projects\\OVD-Model-ADAS\\data\\bdd100k_coco\\val_eval.json\n",
      "\n",
      "==================================================\n",
      "5. ESTADÍSTICAS FINALES\n",
      "==================================================\n",
      "\n",
      "TRAIN:\n",
      "  Imágenes: 8000\n",
      "  Anotaciones: 148515\n",
      "  Promedio ann/img: 18.56\n",
      "  Top 5 categorías:\n",
      "    - car: 81743\n",
      "    - traffic sign: 28119\n",
      "    - traffic light: 21832\n",
      "    - person: 10716\n",
      "    - truck: 3470\n",
      "\n",
      "VAL:\n",
      "  Imágenes: 2000\n",
      "  Anotaciones: 36559\n",
      "  Promedio ann/img: 18.28\n",
      "  Top 5 categorías:\n",
      "    - car: 20763\n",
      "    - traffic sign: 6789\n",
      "    - traffic light: 5053\n",
      "    - person: 2546\n",
      "    - truck: 775\n",
      "\n",
      "==================================================\n",
      "✓ PROCESO COMPLETADO\n",
      "==================================================\n",
      "\n",
      "Archivos generados:\n",
      "1. c:\\Users\\SP1VEVW\\Desktop\\projects\\OVD-Model-ADAS\\data\\bdd100k_coco\\val_calib.json\n",
      "2. c:\\Users\\SP1VEVW\\Desktop\\projects\\OVD-Model-ADAS\\data\\bdd100k_coco\\val_eval.json\n",
      "\n",
      "Ahora puedes usar COCOeval para calcular mAP, AP@50, F1, etc.\n",
      "\n",
      "==================================================\n",
      "6. VALIDANDO CON PYCOCOTOOLS\n",
      "==================================================\n",
      "\n",
      "✓ Validando val_calib.json (80%)...\n",
      "loading annotations into memory...\n",
      "Done (t=0.43s)\n",
      "creating index...\n",
      "Done (t=0.43s)\n",
      "creating index...\n",
      "index created!\n",
      "  - Cargado exitosamente\n",
      "  - Imágenes: 8000\n",
      "  - Categorías: 10\n",
      "  - Anotaciones: 148515\n",
      "\n",
      "✓ Validando val_eval.json (20%)...\n",
      "loading annotations into memory...\n",
      "Done (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "  - Cargado exitosamente\n",
      "  - Imágenes: 2000\n",
      "  - Categorías: 10\n",
      "  - Anotaciones: 36559\n",
      "\n",
      "✓ Categorías disponibles:\n",
      "  - ID 1: person\n",
      "  - ID 2: rider\n",
      "  - ID 3: car\n",
      "  - ID 4: truck\n",
      "  - ID 5: bus\n",
      "  - ID 6: train\n",
      "  - ID 7: motorcycle\n",
      "  - ID 8: bicycle\n",
      "  - ID 9: traffic light\n",
      "  - ID 10: traffic sign\n",
      "\n",
      "✓ Archivos COCO validados correctamente con pycocotools\n",
      "  Listos para usar con COCOeval para calcular métricas\n",
      "index created!\n",
      "  - Cargado exitosamente\n",
      "  - Imágenes: 8000\n",
      "  - Categorías: 10\n",
      "  - Anotaciones: 148515\n",
      "\n",
      "✓ Validando val_eval.json (20%)...\n",
      "loading annotations into memory...\n",
      "Done (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "  - Cargado exitosamente\n",
      "  - Imágenes: 2000\n",
      "  - Categorías: 10\n",
      "  - Anotaciones: 36559\n",
      "\n",
      "✓ Categorías disponibles:\n",
      "  - ID 1: person\n",
      "  - ID 2: rider\n",
      "  - ID 3: car\n",
      "  - ID 4: truck\n",
      "  - ID 5: bus\n",
      "  - ID 6: train\n",
      "  - ID 7: motorcycle\n",
      "  - ID 8: bicycle\n",
      "  - ID 9: traffic light\n",
      "  - ID 10: traffic sign\n",
      "\n",
      "✓ Archivos COCO validados correctamente con pycocotools\n",
      "  Listos para usar con COCOeval para calcular métricas\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import random\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "# ====== 1. VERIFICAR DATOS ======\n",
    "print(\"=\"*50)\n",
    "print(\"1. VERIFICANDO DATOS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Rutas\n",
    "VAL_IMAGES_DIR = os.path.join(BDD100K_DIR, \"bdd100k/bdd100k/images/100k/val\")\n",
    "VAL_LABELS_FILE = os.path.join(BDD100K_DIR, \"bdd100k_labels_release/bdd100k/labels/bdd100k_labels_images_val.json\")\n",
    "\n",
    "# Verificar existencia\n",
    "print(f\"\\nImágenes Val: {os.path.exists(VAL_IMAGES_DIR)}\")\n",
    "print(f\"Labels Val: {os.path.exists(VAL_LABELS_FILE)}\")\n",
    "\n",
    "# Contar imágenes\n",
    "val_images = [f for f in os.listdir(VAL_IMAGES_DIR) if f.endswith('.jpg')]\n",
    "print(f\"Total imágenes Val: {len(val_images)}\")\n",
    "\n",
    "# Cargar labels\n",
    "with open(VAL_LABELS_FILE, 'r') as f:\n",
    "    val_labels = json.load(f)\n",
    "print(f\"Total anotaciones Val: {len(val_labels)}\")\n",
    "\n",
    "# Categorías en BDD100K\n",
    "categories_bdd = {}\n",
    "for item in val_labels[:500]:  # Verificar primeras 500\n",
    "    for label in item.get('labels', []):\n",
    "        cat = label.get('category')\n",
    "        if cat:\n",
    "            categories_bdd[cat] = categories_bdd.get(cat, 0) + 1\n",
    "\n",
    "print(f\"\\nCategorías encontradas: {len(categories_bdd)}\")\n",
    "for cat, count in sorted(categories_bdd.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(f\"  - {cat}: {count}\")\n",
    "\n",
    "# ====== 2. CONVERTIR A FORMATO COCO ======\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"2. CONVIRTIENDO A FORMATO COCO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Mapeo de categorías BDD100K a IDs\n",
    "# Nota: BDD100K usa 'bike', no 'bicycle'\n",
    "CATEGORY_MAP = {\n",
    "    'person': 1, 'rider': 2, 'car': 3, 'truck': 4, 'bus': 5,\n",
    "    'train': 6, 'motorcycle': 7, 'bicycle': 8, 'traffic light': 9,\n",
    "    'traffic sign': 10\n",
    "}\n",
    "\n",
    "# Alias para categorías alternativas\n",
    "CATEGORY_ALIASES = {\n",
    "    'bike': 'bicycle'\n",
    "}\n",
    "\n",
    "def convert_to_coco(bdd_labels, images_dir, split_name):\n",
    "    \"\"\"Convierte BDD100K a formato COCO\"\"\"\n",
    "    coco_format = {\n",
    "        \"info\": {\n",
    "            \"description\": f\"BDD100K {split_name} Dataset - COCO Format\",\n",
    "            \"version\": \"1.0\",\n",
    "            \"year\": 2024,\n",
    "            \"date_created\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        },\n",
    "        \"licenses\": [],\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": []\n",
    "    }\n",
    "    \n",
    "    # Categorías\n",
    "    for cat_name, cat_id in CATEGORY_MAP.items():\n",
    "        coco_format[\"categories\"].append({\n",
    "            \"id\": cat_id,\n",
    "            \"name\": cat_name,\n",
    "            \"supercategory\": \"object\"\n",
    "        })\n",
    "    \n",
    "    annotation_id = 0\n",
    "    \n",
    "    # Procesar cada imagen\n",
    "    for img_idx, item in enumerate(bdd_labels):\n",
    "        img_name = item['name']\n",
    "        img_path = os.path.join(images_dir, img_name)\n",
    "        \n",
    "        # Verificar que la imagen existe\n",
    "        if not os.path.exists(img_path):\n",
    "            continue\n",
    "        \n",
    "        # Información de imagen\n",
    "        image_info = {\n",
    "            \"id\": img_idx,\n",
    "            \"file_name\": img_name,\n",
    "            \"width\": 1280,  # BDD100K estándar\n",
    "            \"height\": 720\n",
    "        }\n",
    "        coco_format[\"images\"].append(image_info)\n",
    "        \n",
    "        # Procesar anotaciones\n",
    "        for label in item.get('labels', []):\n",
    "            category = label.get('category')\n",
    "            \n",
    "            # Aplicar alias si existe (ej: bike -> bicycle)\n",
    "            if category in CATEGORY_ALIASES:\n",
    "                category = CATEGORY_ALIASES[category]\n",
    "            \n",
    "            if category not in CATEGORY_MAP:\n",
    "                continue\n",
    "            \n",
    "            box2d = label.get('box2d')\n",
    "            if not box2d:\n",
    "                continue\n",
    "            \n",
    "            # Calcular bbox COCO (x, y, width, height)\n",
    "            x1 = box2d['x1']\n",
    "            y1 = box2d['y1']\n",
    "            x2 = box2d['x2']\n",
    "            y2 = box2d['y2']\n",
    "            \n",
    "            width = x2 - x1\n",
    "            height = y2 - y1\n",
    "            area = width * height\n",
    "            \n",
    "            # Validar bbox\n",
    "            if width <= 0 or height <= 0:\n",
    "                continue\n",
    "            \n",
    "            annotation = {\n",
    "                \"id\": annotation_id,\n",
    "                \"image_id\": img_idx,\n",
    "                \"category_id\": CATEGORY_MAP[category],\n",
    "                \"bbox\": [x1, y1, width, height],\n",
    "                \"area\": area,\n",
    "                \"iscrowd\": 0,\n",
    "                \"segmentation\": []\n",
    "            }\n",
    "            coco_format[\"annotations\"].append(annotation)\n",
    "            annotation_id += 1\n",
    "    \n",
    "    return coco_format\n",
    "\n",
    "# Convertir dataset completo\n",
    "print(\"\\nConvirtiendo dataset completo...\")\n",
    "coco_val_full = convert_to_coco(val_labels, VAL_IMAGES_DIR, \"validation_full\")\n",
    "\n",
    "print(f\"Total imágenes procesadas: {len(coco_val_full['images'])}\")\n",
    "print(f\"Total anotaciones: {len(coco_val_full['annotations'])}\")\n",
    "\n",
    "# ====== 3. DIVIDIR EN 80% TRAIN / 20% VAL ======\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"3. DIVIDIENDO EN 80% TRAIN / 20% VAL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Mezclar imágenes\n",
    "all_images = coco_val_full['images'].copy()\n",
    "random.seed(42)  # Para reproducibilidad\n",
    "random.shuffle(all_images)\n",
    "\n",
    "# Calcular split\n",
    "total_imgs = len(all_images)\n",
    "train_size = int(total_imgs * 0.8)\n",
    "val_size = total_imgs - train_size\n",
    "\n",
    "train_images = all_images[:train_size]\n",
    "val_images = all_images[train_size:]\n",
    "\n",
    "print(f\"\\nTotal: {total_imgs} imágenes\")\n",
    "print(f\"Train: {train_size} imágenes (80%)\")\n",
    "print(f\"Val: {val_size} imágenes (20%)\")\n",
    "\n",
    "# Crear diccionarios de IDs\n",
    "train_img_ids = {img['id'] for img in train_images}\n",
    "val_img_ids = {img['id'] for img in val_images}\n",
    "\n",
    "# Función para crear split\n",
    "def create_split(images, img_ids, split_name):\n",
    "    split_data = {\n",
    "        \"info\": coco_val_full[\"info\"].copy(),\n",
    "        \"licenses\": coco_val_full[\"licenses\"],\n",
    "        \"images\": images,\n",
    "        \"annotations\": [],\n",
    "        \"categories\": coco_val_full[\"categories\"]\n",
    "    }\n",
    "    split_data[\"info\"][\"description\"] = f\"BDD100K {split_name} Dataset - COCO Format\"\n",
    "    \n",
    "    # Filtrar anotaciones\n",
    "    for ann in coco_val_full['annotations']:\n",
    "        if ann['image_id'] in img_ids:\n",
    "            split_data['annotations'].append(ann)\n",
    "    \n",
    "    return split_data\n",
    "\n",
    "# Crear splits\n",
    "train_coco = create_split(train_images, train_img_ids, \"train\")\n",
    "val_coco = create_split(val_images, val_img_ids, \"val\")\n",
    "\n",
    "print(f\"\\nTrain: {len(train_coco['images'])} imgs, {len(train_coco['annotations'])} anns\")\n",
    "print(f\"Val: {len(val_coco['images'])} imgs, {len(val_coco['annotations'])} anns\")\n",
    "\n",
    "# ====== 4. GUARDAR ARCHIVOS COCO ======\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"4. GUARDANDO ARCHIVOS COCO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Crear directorio de salida\n",
    "COCO_OUTPUT_DIR = os.path.join(HOME, \"bdd100k_coco\")\n",
    "os.makedirs(COCO_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Guardar archivos\n",
    "train_file = os.path.join(COCO_OUTPUT_DIR, \"val_calib.json\")\n",
    "val_file = os.path.join(COCO_OUTPUT_DIR, \"val_eval.json\")\n",
    "\n",
    "with open(train_file, 'w') as f:\n",
    "    json.dump(train_coco, f)\n",
    "print(f\"\\n✓ Train guardado: {train_file}\")\n",
    "\n",
    "with open(val_file, 'w') as f:\n",
    "    json.dump(val_coco, f)\n",
    "print(f\"✓ Val guardado: {val_file}\")\n",
    "\n",
    "# ====== 5. ESTADÍSTICAS FINALES ======\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"5. ESTADÍSTICAS FINALES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def print_stats(data, name):\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Imágenes: {len(data['images'])}\")\n",
    "    print(f\"  Anotaciones: {len(data['annotations'])}\")\n",
    "    print(f\"  Promedio ann/img: {len(data['annotations'])/len(data['images']):.2f}\")\n",
    "    \n",
    "    # Distribución por categoría\n",
    "    cat_dist = {}\n",
    "    for ann in data['annotations']:\n",
    "        cat_id = ann['category_id']\n",
    "        cat_name = next(c['name'] for c in data['categories'] if c['id'] == cat_id)\n",
    "        cat_dist[cat_name] = cat_dist.get(cat_name, 0) + 1\n",
    "    \n",
    "    print(\"  Top 5 categorías:\")\n",
    "    for cat, count in sorted(cat_dist.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "        print(f\"    - {cat}: {count}\")\n",
    "\n",
    "print_stats(train_coco, \"TRAIN\")\n",
    "print_stats(val_coco, \"VAL\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"✓ PROCESO COMPLETADO\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nArchivos generados:\")\n",
    "print(f\"1. {train_file}\")\n",
    "print(f\"2. {val_file}\")\n",
    "print(f\"\\nAhora puedes usar COCOeval para calcular mAP, AP@50, F1, etc.\")\n",
    "\n",
    "# ====== 6. VALIDAR CON PYCOCOTOOLS ======\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"6. VALIDANDO CON PYCOCOTOOLS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Validar archivo de calibración (80%)\n",
    "print(\"\\n✓ Validando val_calib.json (80%)...\")\n",
    "coco_calib = COCO(train_file)\n",
    "print(f\"  - Cargado exitosamente\")\n",
    "print(f\"  - Imágenes: {len(coco_calib.getImgIds())}\")\n",
    "print(f\"  - Categorías: {len(coco_calib.getCatIds())}\")\n",
    "print(f\"  - Anotaciones: {len(coco_calib.getAnnIds())}\")\n",
    "    \n",
    "# Validar archivo de evaluación (20%)\n",
    "print(\"\\n✓ Validando val_eval.json (20%)...\")\n",
    "coco_eval = COCO(val_file)\n",
    "print(f\"  - Cargado exitosamente\")\n",
    "print(f\"  - Imágenes: {len(coco_eval.getImgIds())}\")\n",
    "print(f\"  - Categorías: {len(coco_eval.getCatIds())}\")\n",
    "print(f\"  - Anotaciones: {len(coco_eval.getAnnIds())}\")\n",
    "    \n",
    "# Mostrar categorías\n",
    "print(\"\\n✓ Categorías disponibles:\")\n",
    "for cat in coco_calib.loadCats(coco_calib.getCatIds()):\n",
    "    print(f\"  - ID {cat['id']}: {cat['name']}\")\n",
    "    \n",
    "print(\"\\n✓ Archivos COCO validados correctamente con pycocotools\")\n",
    "print(\"  Listos para usar con COCOeval para calcular métricas\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e39d6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787d9522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataset_huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
