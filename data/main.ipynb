{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d2f7f91",
   "metadata": {},
   "source": [
    "# BDD100K to COCO Format Conversion\n",
    "\n",
    "Este notebook convierte el dataset BDD100K al formato COCO y lo divide en:\n",
    "- **val_calib.json** (80%): Para calibraci√≥n de Temperature Scaling\n",
    "- **val_eval.json** (20%): Para evaluaci√≥n final\n",
    "\n",
    "## Fuentes del Dataset:\n",
    "- https://www.kaggle.com/datasets/awsaf49/bdd100k-dataset\n",
    "- https://www.kaggle.com/datasets/solesensei/solesensei_bdd100k?resource=download ‚úì (usado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781834bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "# Configuraci√≥n de rutas\n",
    "BASE_DIR = Path(r\"C:\\Users\\SP1VEVW\\Desktop\\projects\\OVD-MODEL-EPISTEMIC-UNCERTAINTY\\data\")\n",
    "BDD_DIR = BASE_DIR / \"bdd100k\"\n",
    "COCO_DIR = BASE_DIR / \"bdd100k_coco\"\n",
    "\n",
    "# Crear directorio de salida\n",
    "COCO_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(f\"‚úì Base directory: {BASE_DIR}\")\n",
    "print(f\"‚úì BDD100K directory: {BDD_DIR}\")\n",
    "print(f\"‚úì COCO output directory: {COCO_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89ba5a3",
   "metadata": {},
   "source": [
    "## 1. Verificar Estructura del Dataset\n",
    "\n",
    "Verificamos que tenemos las anotaciones y las im√°genes de validaci√≥n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3225002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas esperadas\n",
    "labels_val = BDD_DIR / \"labels\" / \"det_20\" / \"det_val.json\"\n",
    "images_val_dir = BDD_DIR / \"images\" / \"100k\" / \"val\"\n",
    "\n",
    "# Verificar existencia\n",
    "if labels_val.exists():\n",
    "    print(f\"‚úì Anotaciones encontradas: {labels_val}\")\n",
    "    with open(labels_val) as f:\n",
    "        annotations = json.load(f)\n",
    "    print(f\"  Total de im√°genes anotadas: {len(annotations)}\")\n",
    "else:\n",
    "    print(f\"‚úó No se encontraron anotaciones en: {labels_val}\")\n",
    "\n",
    "if images_val_dir.exists():\n",
    "    image_files = list(images_val_dir.glob(\"*.jpg\"))\n",
    "    print(f\"‚úì Directorio de im√°genes: {images_val_dir}\")\n",
    "    print(f\"  Total de im√°genes: {len(image_files)}\")\n",
    "else:\n",
    "    print(f\"‚úó No se encontr√≥ el directorio de im√°genes: {images_val_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8391291c",
   "metadata": {},
   "source": [
    "## 2. Mapeo de Categor√≠as BDD100K ‚Üí COCO\n",
    "\n",
    "BDD100K tiene 10 clases de objetos. Las mapeamos a formato COCO con IDs consecutivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e6aa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categor√≠as de BDD100K (10 clases)\n",
    "BDD_CATEGORIES = [\n",
    "    \"pedestrian\",\n",
    "    \"rider\",\n",
    "    \"car\",\n",
    "    \"truck\",\n",
    "    \"bus\",\n",
    "    \"train\",\n",
    "    \"motorcycle\",\n",
    "    \"bicycle\",\n",
    "    \"traffic light\",\n",
    "    \"traffic sign\"\n",
    "]\n",
    "\n",
    "# Crear mapeo a formato COCO\n",
    "categories_coco = []\n",
    "category_name_to_id = {}\n",
    "\n",
    "for idx, cat_name in enumerate(BDD_CATEGORIES, start=1):\n",
    "    categories_coco.append({\n",
    "        \"id\": idx,\n",
    "        \"name\": cat_name,\n",
    "        \"supercategory\": \"object\"\n",
    "    })\n",
    "    category_name_to_id[cat_name] = idx\n",
    "\n",
    "print(\"Categor√≠as COCO:\")\n",
    "for cat in categories_coco:\n",
    "    print(f\"  ID {cat['id']}: {cat['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea20b6a5",
   "metadata": {},
   "source": [
    "## 3. Funci√≥n de Conversi√≥n BDD100K ‚Üí COCO\n",
    "\n",
    "Convertimos las anotaciones de BDD100K (formato personalizado) al formato est√°ndar COCO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b465402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bdd_to_coco(bdd_annotations, images_dir, category_mapping):\n",
    "    \"\"\"\n",
    "    Convierte anotaciones de BDD100K a formato COCO.\n",
    "    \n",
    "    Args:\n",
    "        bdd_annotations: Lista de anotaciones en formato BDD100K\n",
    "        images_dir: Directorio con las im√°genes\n",
    "        category_mapping: Diccionario {nombre_categoria: id_coco}\n",
    "    \n",
    "    Returns:\n",
    "        Diccionario en formato COCO\n",
    "    \"\"\"\n",
    "    coco_output = {\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": categories_coco\n",
    "    }\n",
    "    \n",
    "    annotation_id = 1\n",
    "    skipped_images = 0\n",
    "    \n",
    "    for img_idx, bdd_img in enumerate(tqdm(bdd_annotations, desc=\"Convirtiendo\")):\n",
    "        img_name = bdd_img[\"name\"]\n",
    "        img_path = images_dir / img_name\n",
    "        \n",
    "        # Verificar que la imagen existe\n",
    "        if not img_path.exists():\n",
    "            skipped_images += 1\n",
    "            continue\n",
    "        \n",
    "        # Obtener dimensiones de la imagen\n",
    "        try:\n",
    "            with Image.open(img_path) as img:\n",
    "                width, height = img.size\n",
    "        except Exception as e:\n",
    "            print(f\"Error abriendo imagen {img_name}: {e}\")\n",
    "            skipped_images += 1\n",
    "            continue\n",
    "        \n",
    "        # Agregar informaci√≥n de imagen\n",
    "        image_id = img_idx + 1\n",
    "        coco_output[\"images\"].append({\n",
    "            \"id\": image_id,\n",
    "            \"file_name\": img_name,\n",
    "            \"width\": width,\n",
    "            \"height\": height\n",
    "        })\n",
    "        \n",
    "        # Convertir anotaciones (labels)\n",
    "        if \"labels\" in bdd_img:\n",
    "            for label in bdd_img[\"labels\"]:\n",
    "                category = label.get(\"category\")\n",
    "                \n",
    "                # Verificar que la categor√≠a existe en nuestro mapeo\n",
    "                if category not in category_mapping:\n",
    "                    continue\n",
    "                \n",
    "                # Obtener bounding box\n",
    "                box2d = label.get(\"box2d\")\n",
    "                if not box2d:\n",
    "                    continue\n",
    "                \n",
    "                x1 = box2d[\"x1\"]\n",
    "                y1 = box2d[\"y1\"]\n",
    "                x2 = box2d[\"x2\"]\n",
    "                y2 = box2d[\"y2\"]\n",
    "                \n",
    "                # Calcular ancho y alto\n",
    "                bbox_width = x2 - x1\n",
    "                bbox_height = y2 - y1\n",
    "                \n",
    "                # Validar bbox\n",
    "                if bbox_width <= 0 or bbox_height <= 0:\n",
    "                    continue\n",
    "                \n",
    "                # Crear anotaci√≥n COCO\n",
    "                coco_output[\"annotations\"].append({\n",
    "                    \"id\": annotation_id,\n",
    "                    \"image_id\": image_id,\n",
    "                    \"category_id\": category_mapping[category],\n",
    "                    \"bbox\": [x1, y1, bbox_width, bbox_height],\n",
    "                    \"area\": bbox_width * bbox_height,\n",
    "                    \"iscrowd\": 0\n",
    "                })\n",
    "                annotation_id += 1\n",
    "    \n",
    "    print(f\"\\n‚úì Im√°genes procesadas: {len(coco_output['images'])}\")\n",
    "    print(f\"‚úì Anotaciones creadas: {len(coco_output['annotations'])}\")\n",
    "    if skipped_images > 0:\n",
    "        print(f\"‚ö† Im√°genes omitidas: {skipped_images}\")\n",
    "    \n",
    "    return coco_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2770ebaf",
   "metadata": {},
   "source": [
    "## 4. Convertir el Dataset Completo\n",
    "\n",
    "Convertimos todas las im√°genes de validaci√≥n de BDD100K a formato COCO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8c2930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar anotaciones BDD100K\n",
    "with open(labels_val) as f:\n",
    "    bdd_val_annotations = json.load(f)\n",
    "\n",
    "print(f\"Total de im√°genes en BDD100K val: {len(bdd_val_annotations)}\\n\")\n",
    "\n",
    "# Convertir a COCO\n",
    "coco_val_full = convert_bdd_to_coco(\n",
    "    bdd_val_annotations, \n",
    "    images_val_dir, \n",
    "    category_name_to_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66e3705",
   "metadata": {},
   "source": [
    "## 5. Dividir en Calibraci√≥n y Evaluaci√≥n\n",
    "\n",
    "Dividimos el set de validaci√≥n en:\n",
    "- **val_calib.json** (80%): Para calibrar Temperature Scaling\n",
    "- **val_eval.json** (20%): Para evaluaci√≥n final del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71652ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar split\n",
    "np.random.seed(42)\n",
    "split_ratio = 0.8\n",
    "\n",
    "# Obtener IDs de im√°genes y mezclar\n",
    "image_ids = [img[\"id\"] for img in coco_val_full[\"images\"]]\n",
    "np.random.shuffle(image_ids)\n",
    "\n",
    "# Dividir\n",
    "split_idx = int(len(image_ids) * split_ratio)\n",
    "calib_ids = set(image_ids[:split_idx])\n",
    "eval_ids = set(image_ids[split_idx:])\n",
    "\n",
    "print(f\"Total de im√°genes: {len(image_ids)}\")\n",
    "print(f\"Calibraci√≥n (80%): {len(calib_ids)} im√°genes\")\n",
    "print(f\"Evaluaci√≥n (20%): {len(eval_ids)} im√°genes\")\n",
    "\n",
    "# Crear subsets\n",
    "def create_subset(coco_data, image_ids_subset):\n",
    "    \"\"\"Crea un subset de COCO con las im√°genes especificadas\"\"\"\n",
    "    subset = {\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": coco_data[\"categories\"]\n",
    "    }\n",
    "    \n",
    "    for img in coco_data[\"images\"]:\n",
    "        if img[\"id\"] in image_ids_subset:\n",
    "            subset[\"images\"].append(img)\n",
    "    \n",
    "    for ann in coco_data[\"annotations\"]:\n",
    "        if ann[\"image_id\"] in image_ids_subset:\n",
    "            subset[\"annotations\"].append(ann)\n",
    "    \n",
    "    return subset\n",
    "\n",
    "# Crear splits\n",
    "coco_val_calib = create_subset(coco_val_full, calib_ids)\n",
    "coco_val_eval = create_subset(coco_val_full, eval_ids)\n",
    "\n",
    "print(f\"\\n‚úì val_calib: {len(coco_val_calib['images'])} im√°genes, {len(coco_val_calib['annotations'])} anotaciones\")\n",
    "print(f\"‚úì val_eval: {len(coco_val_eval['images'])} im√°genes, {len(coco_val_eval['annotations'])} anotaciones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2a578c",
   "metadata": {},
   "source": [
    "## 6. Guardar Archivos COCO\n",
    "\n",
    "Guardamos los tres archivos JSON en formato COCO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fa4998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar archivos\n",
    "output_files = {\n",
    "    \"val_full.json\": coco_val_full,\n",
    "    \"val_calib.json\": coco_val_calib,\n",
    "    \"val_eval.json\": coco_val_eval\n",
    "}\n",
    "\n",
    "for filename, data in output_files.items():\n",
    "    output_path = COCO_DIR / filename\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    print(f\"‚úì Guardado: {output_path}\")\n",
    "    print(f\"  - {len(data['images'])} im√°genes\")\n",
    "    print(f\"  - {len(data['annotations'])} anotaciones\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e95b17",
   "metadata": {},
   "source": [
    "## 7. Verificaci√≥n Final\n",
    "\n",
    "Verificamos que los archivos se hayan creado correctamente y mostramos estad√≠sticas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb34890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad√≠sticas por categor√≠a\n",
    "def get_category_stats(coco_data):\n",
    "    \"\"\"Obtiene estad√≠sticas de anotaciones por categor√≠a\"\"\"\n",
    "    category_counts = defaultdict(int)\n",
    "    for ann in coco_data[\"annotations\"]:\n",
    "        category_counts[ann[\"category_id\"]] += 1\n",
    "    return category_counts\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ESTAD√çSTICAS POR CATEGOR√çA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for split_name, coco_data in [(\"val_calib\", coco_val_calib), (\"val_eval\", coco_val_eval)]:\n",
    "    print(f\"\\n{split_name.upper()}:\")\n",
    "    stats = get_category_stats(coco_data)\n",
    "    for cat in categories_coco:\n",
    "        count = stats.get(cat[\"id\"], 0)\n",
    "        print(f\"  {cat['name']:20s}: {count:5d} anotaciones\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RESUMEN\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"‚úì Dataset convertido exitosamente a formato COCO\")\n",
    "print(f\"‚úì Archivos guardados en: {COCO_DIR}\")\n",
    "print(f\"‚úì val_calib: {len(coco_val_calib['images'])} im√°genes (80%)\")\n",
    "print(f\"‚úì val_eval: {len(coco_val_eval['images'])} im√°genes (20%)\")\n",
    "print(f\"‚úì Total de categor√≠as: {len(categories_coco)}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dffc231",
   "metadata": {},
   "source": [
    "## üìå Pr√≥ximos Pasos\n",
    "\n",
    "Los archivos COCO generados est√°n listos para ser usados:\n",
    "\n",
    "1. **val_calib.json** ‚Üí Para entrenar/calibrar Temperature Scaling (Fase 5)\n",
    "2. **val_eval.json** ‚Üí Para evaluaci√≥n final del modelo con incertidumbre calibrada\n",
    "\n",
    "### Uso en Fases siguientes:\n",
    "\n",
    "```python\n",
    "# Fase 5: Cargar datos de calibraci√≥n\n",
    "calib_data = \"data/bdd100k_coco/val_calib.json\"\n",
    "\n",
    "# Fase 5: Cargar datos de evaluaci√≥n\n",
    "eval_data = \"data/bdd100k_coco/val_eval.json\"\n",
    "```\n",
    "\n",
    "### Notas importantes:\n",
    "\n",
    "- ‚úì Las im√°genes permanecen en `data/bdd100k/images/100k/val/`\n",
    "- ‚úì Los archivos JSON solo contienen las anotaciones y referencias a las im√°genes\n",
    "- ‚úì El split es reproducible (seed=42)\n",
    "- ‚úì No hay overlap entre calibraci√≥n y evaluaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05b1ef19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SP1VEVW\\Desktop\\projects\\OVD-Model-ADAS\\data\n",
      "c:\\Users\\SP1VEVW\\Desktop\\projects\\OVD-Model-ADAS\\data\\bdd100k ; exist: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)  \n",
    "BDD100K_DIR = os.path.join(HOME, \"bdd100k\")\n",
    "os.makedirs(BDD100K_DIR, exist_ok=True)\n",
    "print(BDD100K_DIR, \"; exist:\", os.path.exists(BDD100K_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8349b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycocotools\n",
      "  Using cached pycocotools-2.0.10-cp312-abi3-win_amd64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pycocotools) (2.2.6)\n",
      "Using cached pycocotools-2.0.10-cp312-abi3-win_amd64.whl (76 kB)\n",
      "Installing collected packages: pycocotools\n",
      "Successfully installed pycocotools-2.0.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9469a817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "1. VERIFICANDO DATOS\n",
      "==================================================\n",
      "\n",
      "Im√°genes Val: True\n",
      "Labels Val: True\n",
      "Total im√°genes Val: 10000\n",
      "Total anotaciones Val: 10000\n",
      "\n",
      "Categor√≠as encontradas: 12\n",
      "  - car: 5062\n",
      "  - lane: 3808\n",
      "  - traffic sign: 1754\n",
      "  - traffic light: 1374\n",
      "  - drivable area: 873\n",
      "  - person: 746\n",
      "  - truck: 212\n",
      "  - bus: 91\n",
      "  - bike: 40\n",
      "  - rider: 35\n",
      "\n",
      "==================================================\n",
      "2. CONVIRTIENDO A FORMATO COCO\n",
      "==================================================\n",
      "\n",
      "Convirtiendo dataset completo...\n",
      "Total anotaciones Val: 10000\n",
      "\n",
      "Categor√≠as encontradas: 12\n",
      "  - car: 5062\n",
      "  - lane: 3808\n",
      "  - traffic sign: 1754\n",
      "  - traffic light: 1374\n",
      "  - drivable area: 873\n",
      "  - person: 746\n",
      "  - truck: 212\n",
      "  - bus: 91\n",
      "  - bike: 40\n",
      "  - rider: 35\n",
      "\n",
      "==================================================\n",
      "2. CONVIRTIENDO A FORMATO COCO\n",
      "==================================================\n",
      "\n",
      "Convirtiendo dataset completo...\n",
      "Total im√°genes procesadas: 10000\n",
      "Total anotaciones: 185074\n",
      "\n",
      "==================================================\n",
      "3. DIVIDIENDO EN 80% TRAIN / 20% VAL\n",
      "==================================================\n",
      "\n",
      "Total: 10000 im√°genes\n",
      "Train: 8000 im√°genes (80%)\n",
      "Val: 2000 im√°genes (20%)\n",
      "\n",
      "Train: 8000 imgs, 148515 anns\n",
      "Val: 2000 imgs, 36559 anns\n",
      "\n",
      "==================================================\n",
      "4. GUARDANDO ARCHIVOS COCO\n",
      "==================================================\n",
      "Total im√°genes procesadas: 10000\n",
      "Total anotaciones: 185074\n",
      "\n",
      "==================================================\n",
      "3. DIVIDIENDO EN 80% TRAIN / 20% VAL\n",
      "==================================================\n",
      "\n",
      "Total: 10000 im√°genes\n",
      "Train: 8000 im√°genes (80%)\n",
      "Val: 2000 im√°genes (20%)\n",
      "\n",
      "Train: 8000 imgs, 148515 anns\n",
      "Val: 2000 imgs, 36559 anns\n",
      "\n",
      "==================================================\n",
      "4. GUARDANDO ARCHIVOS COCO\n",
      "==================================================\n",
      "\n",
      "‚úì Train guardado: c:\\Users\\SP1VEVW\\Desktop\\projects\\OVD-Model-ADAS\\data\\bdd100k_coco\\val_calib.json\n",
      "\n",
      "‚úì Train guardado: c:\\Users\\SP1VEVW\\Desktop\\projects\\OVD-Model-ADAS\\data\\bdd100k_coco\\val_calib.json\n",
      "‚úì Val guardado: c:\\Users\\SP1VEVW\\Desktop\\projects\\OVD-Model-ADAS\\data\\bdd100k_coco\\val_eval.json\n",
      "\n",
      "==================================================\n",
      "5. ESTAD√çSTICAS FINALES\n",
      "==================================================\n",
      "\n",
      "TRAIN:\n",
      "  Im√°genes: 8000\n",
      "  Anotaciones: 148515\n",
      "  Promedio ann/img: 18.56\n",
      "  Top 5 categor√≠as:\n",
      "    - car: 81743\n",
      "    - traffic sign: 28119\n",
      "    - traffic light: 21832\n",
      "    - person: 10716\n",
      "    - truck: 3470\n",
      "\n",
      "VAL:\n",
      "  Im√°genes: 2000\n",
      "  Anotaciones: 36559\n",
      "  Promedio ann/img: 18.28\n",
      "  Top 5 categor√≠as:\n",
      "    - car: 20763\n",
      "    - traffic sign: 6789\n",
      "    - traffic light: 5053\n",
      "    - person: 2546\n",
      "    - truck: 775\n",
      "\n",
      "==================================================\n",
      "‚úì PROCESO COMPLETADO\n",
      "==================================================\n",
      "\n",
      "Archivos generados:\n",
      "1. c:\\Users\\SP1VEVW\\Desktop\\projects\\OVD-Model-ADAS\\data\\bdd100k_coco\\val_calib.json\n",
      "2. c:\\Users\\SP1VEVW\\Desktop\\projects\\OVD-Model-ADAS\\data\\bdd100k_coco\\val_eval.json\n",
      "\n",
      "Ahora puedes usar COCOeval para calcular mAP, AP@50, F1, etc.\n",
      "\n",
      "==================================================\n",
      "6. VALIDANDO CON PYCOCOTOOLS\n",
      "==================================================\n",
      "\n",
      "‚úì Validando val_calib.json (80%)...\n",
      "loading annotations into memory...\n",
      "‚úì Val guardado: c:\\Users\\SP1VEVW\\Desktop\\projects\\OVD-Model-ADAS\\data\\bdd100k_coco\\val_eval.json\n",
      "\n",
      "==================================================\n",
      "5. ESTAD√çSTICAS FINALES\n",
      "==================================================\n",
      "\n",
      "TRAIN:\n",
      "  Im√°genes: 8000\n",
      "  Anotaciones: 148515\n",
      "  Promedio ann/img: 18.56\n",
      "  Top 5 categor√≠as:\n",
      "    - car: 81743\n",
      "    - traffic sign: 28119\n",
      "    - traffic light: 21832\n",
      "    - person: 10716\n",
      "    - truck: 3470\n",
      "\n",
      "VAL:\n",
      "  Im√°genes: 2000\n",
      "  Anotaciones: 36559\n",
      "  Promedio ann/img: 18.28\n",
      "  Top 5 categor√≠as:\n",
      "    - car: 20763\n",
      "    - traffic sign: 6789\n",
      "    - traffic light: 5053\n",
      "    - person: 2546\n",
      "    - truck: 775\n",
      "\n",
      "==================================================\n",
      "‚úì PROCESO COMPLETADO\n",
      "==================================================\n",
      "\n",
      "Archivos generados:\n",
      "1. c:\\Users\\SP1VEVW\\Desktop\\projects\\OVD-Model-ADAS\\data\\bdd100k_coco\\val_calib.json\n",
      "2. c:\\Users\\SP1VEVW\\Desktop\\projects\\OVD-Model-ADAS\\data\\bdd100k_coco\\val_eval.json\n",
      "\n",
      "Ahora puedes usar COCOeval para calcular mAP, AP@50, F1, etc.\n",
      "\n",
      "==================================================\n",
      "6. VALIDANDO CON PYCOCOTOOLS\n",
      "==================================================\n",
      "\n",
      "‚úì Validando val_calib.json (80%)...\n",
      "loading annotations into memory...\n",
      "Done (t=0.43s)\n",
      "creating index...\n",
      "Done (t=0.43s)\n",
      "creating index...\n",
      "index created!\n",
      "  - Cargado exitosamente\n",
      "  - Im√°genes: 8000\n",
      "  - Categor√≠as: 10\n",
      "  - Anotaciones: 148515\n",
      "\n",
      "‚úì Validando val_eval.json (20%)...\n",
      "loading annotations into memory...\n",
      "Done (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "  - Cargado exitosamente\n",
      "  - Im√°genes: 2000\n",
      "  - Categor√≠as: 10\n",
      "  - Anotaciones: 36559\n",
      "\n",
      "‚úì Categor√≠as disponibles:\n",
      "  - ID 1: person\n",
      "  - ID 2: rider\n",
      "  - ID 3: car\n",
      "  - ID 4: truck\n",
      "  - ID 5: bus\n",
      "  - ID 6: train\n",
      "  - ID 7: motorcycle\n",
      "  - ID 8: bicycle\n",
      "  - ID 9: traffic light\n",
      "  - ID 10: traffic sign\n",
      "\n",
      "‚úì Archivos COCO validados correctamente con pycocotools\n",
      "  Listos para usar con COCOeval para calcular m√©tricas\n",
      "index created!\n",
      "  - Cargado exitosamente\n",
      "  - Im√°genes: 8000\n",
      "  - Categor√≠as: 10\n",
      "  - Anotaciones: 148515\n",
      "\n",
      "‚úì Validando val_eval.json (20%)...\n",
      "loading annotations into memory...\n",
      "Done (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "  - Cargado exitosamente\n",
      "  - Im√°genes: 2000\n",
      "  - Categor√≠as: 10\n",
      "  - Anotaciones: 36559\n",
      "\n",
      "‚úì Categor√≠as disponibles:\n",
      "  - ID 1: person\n",
      "  - ID 2: rider\n",
      "  - ID 3: car\n",
      "  - ID 4: truck\n",
      "  - ID 5: bus\n",
      "  - ID 6: train\n",
      "  - ID 7: motorcycle\n",
      "  - ID 8: bicycle\n",
      "  - ID 9: traffic light\n",
      "  - ID 10: traffic sign\n",
      "\n",
      "‚úì Archivos COCO validados correctamente con pycocotools\n",
      "  Listos para usar con COCOeval para calcular m√©tricas\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import random\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "# ====== 1. VERIFICAR DATOS ======\n",
    "print(\"=\"*50)\n",
    "print(\"1. VERIFICANDO DATOS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Rutas\n",
    "VAL_IMAGES_DIR = os.path.join(BDD100K_DIR, \"bdd100k/bdd100k/images/100k/val\")\n",
    "VAL_LABELS_FILE = os.path.join(BDD100K_DIR, \"bdd100k_labels_release/bdd100k/labels/bdd100k_labels_images_val.json\")\n",
    "\n",
    "# Verificar existencia\n",
    "print(f\"\\nIm√°genes Val: {os.path.exists(VAL_IMAGES_DIR)}\")\n",
    "print(f\"Labels Val: {os.path.exists(VAL_LABELS_FILE)}\")\n",
    "\n",
    "# Contar im√°genes\n",
    "val_images = [f for f in os.listdir(VAL_IMAGES_DIR) if f.endswith('.jpg')]\n",
    "print(f\"Total im√°genes Val: {len(val_images)}\")\n",
    "\n",
    "# Cargar labels\n",
    "with open(VAL_LABELS_FILE, 'r') as f:\n",
    "    val_labels = json.load(f)\n",
    "print(f\"Total anotaciones Val: {len(val_labels)}\")\n",
    "\n",
    "# Categor√≠as en BDD100K\n",
    "categories_bdd = {}\n",
    "for item in val_labels[:500]:  # Verificar primeras 500\n",
    "    for label in item.get('labels', []):\n",
    "        cat = label.get('category')\n",
    "        if cat:\n",
    "            categories_bdd[cat] = categories_bdd.get(cat, 0) + 1\n",
    "\n",
    "print(f\"\\nCategor√≠as encontradas: {len(categories_bdd)}\")\n",
    "for cat, count in sorted(categories_bdd.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(f\"  - {cat}: {count}\")\n",
    "\n",
    "# ====== 2. CONVERTIR A FORMATO COCO ======\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"2. CONVIRTIENDO A FORMATO COCO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Mapeo de categor√≠as BDD100K a IDs\n",
    "# Nota: BDD100K usa 'bike', no 'bicycle'\n",
    "CATEGORY_MAP = {\n",
    "    'person': 1, 'rider': 2, 'car': 3, 'truck': 4, 'bus': 5,\n",
    "    'train': 6, 'motorcycle': 7, 'bicycle': 8, 'traffic light': 9,\n",
    "    'traffic sign': 10\n",
    "}\n",
    "\n",
    "# Alias para categor√≠as alternativas\n",
    "CATEGORY_ALIASES = {\n",
    "    'bike': 'bicycle'\n",
    "}\n",
    "\n",
    "def convert_to_coco(bdd_labels, images_dir, split_name):\n",
    "    \"\"\"Convierte BDD100K a formato COCO\"\"\"\n",
    "    coco_format = {\n",
    "        \"info\": {\n",
    "            \"description\": f\"BDD100K {split_name} Dataset - COCO Format\",\n",
    "            \"version\": \"1.0\",\n",
    "            \"year\": 2024,\n",
    "            \"date_created\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        },\n",
    "        \"licenses\": [],\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": []\n",
    "    }\n",
    "    \n",
    "    # Categor√≠as\n",
    "    for cat_name, cat_id in CATEGORY_MAP.items():\n",
    "        coco_format[\"categories\"].append({\n",
    "            \"id\": cat_id,\n",
    "            \"name\": cat_name,\n",
    "            \"supercategory\": \"object\"\n",
    "        })\n",
    "    \n",
    "    annotation_id = 0\n",
    "    \n",
    "    # Procesar cada imagen\n",
    "    for img_idx, item in enumerate(bdd_labels):\n",
    "        img_name = item['name']\n",
    "        img_path = os.path.join(images_dir, img_name)\n",
    "        \n",
    "        # Verificar que la imagen existe\n",
    "        if not os.path.exists(img_path):\n",
    "            continue\n",
    "        \n",
    "        # Informaci√≥n de imagen\n",
    "        image_info = {\n",
    "            \"id\": img_idx,\n",
    "            \"file_name\": img_name,\n",
    "            \"width\": 1280,  # BDD100K est√°ndar\n",
    "            \"height\": 720\n",
    "        }\n",
    "        coco_format[\"images\"].append(image_info)\n",
    "        \n",
    "        # Procesar anotaciones\n",
    "        for label in item.get('labels', []):\n",
    "            category = label.get('category')\n",
    "            \n",
    "            # Aplicar alias si existe (ej: bike -> bicycle)\n",
    "            if category in CATEGORY_ALIASES:\n",
    "                category = CATEGORY_ALIASES[category]\n",
    "            \n",
    "            if category not in CATEGORY_MAP:\n",
    "                continue\n",
    "            \n",
    "            box2d = label.get('box2d')\n",
    "            if not box2d:\n",
    "                continue\n",
    "            \n",
    "            # Calcular bbox COCO (x, y, width, height)\n",
    "            x1 = box2d['x1']\n",
    "            y1 = box2d['y1']\n",
    "            x2 = box2d['x2']\n",
    "            y2 = box2d['y2']\n",
    "            \n",
    "            width = x2 - x1\n",
    "            height = y2 - y1\n",
    "            area = width * height\n",
    "            \n",
    "            # Validar bbox\n",
    "            if width <= 0 or height <= 0:\n",
    "                continue\n",
    "            \n",
    "            annotation = {\n",
    "                \"id\": annotation_id,\n",
    "                \"image_id\": img_idx,\n",
    "                \"category_id\": CATEGORY_MAP[category],\n",
    "                \"bbox\": [x1, y1, width, height],\n",
    "                \"area\": area,\n",
    "                \"iscrowd\": 0,\n",
    "                \"segmentation\": []\n",
    "            }\n",
    "            coco_format[\"annotations\"].append(annotation)\n",
    "            annotation_id += 1\n",
    "    \n",
    "    return coco_format\n",
    "\n",
    "# Convertir dataset completo\n",
    "print(\"\\nConvirtiendo dataset completo...\")\n",
    "coco_val_full = convert_to_coco(val_labels, VAL_IMAGES_DIR, \"validation_full\")\n",
    "\n",
    "print(f\"Total im√°genes procesadas: {len(coco_val_full['images'])}\")\n",
    "print(f\"Total anotaciones: {len(coco_val_full['annotations'])}\")\n",
    "\n",
    "# ====== 3. DIVIDIR EN 80% TRAIN / 20% VAL ======\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"3. DIVIDIENDO EN 80% TRAIN / 20% VAL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Mezclar im√°genes\n",
    "all_images = coco_val_full['images'].copy()\n",
    "random.seed(42)  # Para reproducibilidad\n",
    "random.shuffle(all_images)\n",
    "\n",
    "# Calcular split\n",
    "total_imgs = len(all_images)\n",
    "train_size = int(total_imgs * 0.8)\n",
    "val_size = total_imgs - train_size\n",
    "\n",
    "train_images = all_images[:train_size]\n",
    "val_images = all_images[train_size:]\n",
    "\n",
    "print(f\"\\nTotal: {total_imgs} im√°genes\")\n",
    "print(f\"Train: {train_size} im√°genes (80%)\")\n",
    "print(f\"Val: {val_size} im√°genes (20%)\")\n",
    "\n",
    "# Crear diccionarios de IDs\n",
    "train_img_ids = {img['id'] for img in train_images}\n",
    "val_img_ids = {img['id'] for img in val_images}\n",
    "\n",
    "# Funci√≥n para crear split\n",
    "def create_split(images, img_ids, split_name):\n",
    "    split_data = {\n",
    "        \"info\": coco_val_full[\"info\"].copy(),\n",
    "        \"licenses\": coco_val_full[\"licenses\"],\n",
    "        \"images\": images,\n",
    "        \"annotations\": [],\n",
    "        \"categories\": coco_val_full[\"categories\"]\n",
    "    }\n",
    "    split_data[\"info\"][\"description\"] = f\"BDD100K {split_name} Dataset - COCO Format\"\n",
    "    \n",
    "    # Filtrar anotaciones\n",
    "    for ann in coco_val_full['annotations']:\n",
    "        if ann['image_id'] in img_ids:\n",
    "            split_data['annotations'].append(ann)\n",
    "    \n",
    "    return split_data\n",
    "\n",
    "# Crear splits\n",
    "train_coco = create_split(train_images, train_img_ids, \"train\")\n",
    "val_coco = create_split(val_images, val_img_ids, \"val\")\n",
    "\n",
    "print(f\"\\nTrain: {len(train_coco['images'])} imgs, {len(train_coco['annotations'])} anns\")\n",
    "print(f\"Val: {len(val_coco['images'])} imgs, {len(val_coco['annotations'])} anns\")\n",
    "\n",
    "# ====== 4. GUARDAR ARCHIVOS COCO ======\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"4. GUARDANDO ARCHIVOS COCO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Crear directorio de salida\n",
    "COCO_OUTPUT_DIR = os.path.join(HOME, \"bdd100k_coco\")\n",
    "os.makedirs(COCO_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Guardar archivos\n",
    "train_file = os.path.join(COCO_OUTPUT_DIR, \"val_calib.json\")\n",
    "val_file = os.path.join(COCO_OUTPUT_DIR, \"val_eval.json\")\n",
    "\n",
    "with open(train_file, 'w') as f:\n",
    "    json.dump(train_coco, f)\n",
    "print(f\"\\n‚úì Train guardado: {train_file}\")\n",
    "\n",
    "with open(val_file, 'w') as f:\n",
    "    json.dump(val_coco, f)\n",
    "print(f\"‚úì Val guardado: {val_file}\")\n",
    "\n",
    "# ====== 5. ESTAD√çSTICAS FINALES ======\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"5. ESTAD√çSTICAS FINALES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def print_stats(data, name):\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Im√°genes: {len(data['images'])}\")\n",
    "    print(f\"  Anotaciones: {len(data['annotations'])}\")\n",
    "    print(f\"  Promedio ann/img: {len(data['annotations'])/len(data['images']):.2f}\")\n",
    "    \n",
    "    # Distribuci√≥n por categor√≠a\n",
    "    cat_dist = {}\n",
    "    for ann in data['annotations']:\n",
    "        cat_id = ann['category_id']\n",
    "        cat_name = next(c['name'] for c in data['categories'] if c['id'] == cat_id)\n",
    "        cat_dist[cat_name] = cat_dist.get(cat_name, 0) + 1\n",
    "    \n",
    "    print(\"  Top 5 categor√≠as:\")\n",
    "    for cat, count in sorted(cat_dist.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "        print(f\"    - {cat}: {count}\")\n",
    "\n",
    "print_stats(train_coco, \"TRAIN\")\n",
    "print_stats(val_coco, \"VAL\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"‚úì PROCESO COMPLETADO\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nArchivos generados:\")\n",
    "print(f\"1. {train_file}\")\n",
    "print(f\"2. {val_file}\")\n",
    "print(f\"\\nAhora puedes usar COCOeval para calcular mAP, AP@50, F1, etc.\")\n",
    "\n",
    "# ====== 6. VALIDAR CON PYCOCOTOOLS ======\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"6. VALIDANDO CON PYCOCOTOOLS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Validar archivo de calibraci√≥n (80%)\n",
    "print(\"\\n‚úì Validando val_calib.json (80%)...\")\n",
    "coco_calib = COCO(train_file)\n",
    "print(f\"  - Cargado exitosamente\")\n",
    "print(f\"  - Im√°genes: {len(coco_calib.getImgIds())}\")\n",
    "print(f\"  - Categor√≠as: {len(coco_calib.getCatIds())}\")\n",
    "print(f\"  - Anotaciones: {len(coco_calib.getAnnIds())}\")\n",
    "    \n",
    "# Validar archivo de evaluaci√≥n (20%)\n",
    "print(\"\\n‚úì Validando val_eval.json (20%)...\")\n",
    "coco_eval = COCO(val_file)\n",
    "print(f\"  - Cargado exitosamente\")\n",
    "print(f\"  - Im√°genes: {len(coco_eval.getImgIds())}\")\n",
    "print(f\"  - Categor√≠as: {len(coco_eval.getCatIds())}\")\n",
    "print(f\"  - Anotaciones: {len(coco_eval.getAnnIds())}\")\n",
    "    \n",
    "# Mostrar categor√≠as\n",
    "print(\"\\n‚úì Categor√≠as disponibles:\")\n",
    "for cat in coco_calib.loadCats(coco_calib.getCatIds()):\n",
    "    print(f\"  - ID {cat['id']}: {cat['name']}\")\n",
    "    \n",
    "print(\"\\n‚úì Archivos COCO validados correctamente con pycocotools\")\n",
    "print(\"  Listos para usar con COCOeval para calcular m√©tricas\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e39d6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787d9522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataset_huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
