{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "041e1452",
   "metadata": {},
   "source": [
    "# Baseline OVD - BDD100K Detection Pipeline\n",
    "\n",
    "Pipeline completo para establecer el baseline de detección con Grounding-DINO en BDD100K.\n",
    "\n",
    "**Fases:**\n",
    "1. Configuración del modelo y dataset\n",
    "2. Inferencia sobre val_eval\n",
    "3. Evaluación de métricas\n",
    "4. Preparación para calibración\n",
    "5. Generación de artefactos\n",
    "\n",
    "**Hardware requerido:** GPU con CUDA (mínimo 8GB VRAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41b56ec",
   "metadata": {},
   "source": [
    "## 1. Imports y Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62eb21cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from seaborn) (2.2.6)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from seaborn) (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f367695a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.9.0-cp312-cp312-win_amd64.whl.metadata (30 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.24.0-cp312-cp312-win_amd64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from torch) (4.15.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from torchvision) (12.0.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Using cached torch-2.9.0-cp312-cp312-win_amd64.whl (109.3 MB)\n",
      "Using cached torchvision-0.24.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, torch, torchvision\n",
      "\n",
      "   ---------------------------------------- 0/4 [mpmath]\n",
      "   ---------------------------------------- 0/4 [mpmath]\n",
      "   ---------------------------------------- 0/4 [mpmath]\n",
      "   ---------------------------------------- 0/4 [mpmath]\n",
      "   ---------------------------------------- 0/4 [mpmath]\n",
      "   ---------------------------------------- 0/4 [mpmath]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ---------------------------------------- 4/4 [torchvision]\n",
      "\n",
      "Successfully installed mpmath-1.3.0 sympy-1.14.0 torch-2.9.0 torchvision-0.24.0\n",
      "Requirement already satisfied: pycocotools in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (2.0.10)\n",
      "Requirement already satisfied: numpy in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pycocotools) (2.2.6)\n",
      "Requirement already satisfied: pycocotools in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (2.0.10)\n",
      "Requirement already satisfied: numpy in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pycocotools) (2.2.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (3.10.7)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Requirement already satisfied: pandas in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (3.10.7)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Requirement already satisfied: Pillow in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (12.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (6.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: Pillow in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (12.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (6.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "#!pip install torch torchvision\n",
    "#!pip install pycocotools\n",
    "#!pip install pandas matplotlib seaborn\n",
    "#!pip install Pillow tqdm pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecdd564",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All required packages are installed.\")\n",
    "#pip install ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cf281a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.3.3 tzdata-2025.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeb31b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import yaml\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a8de9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundingDINO en: /opt/conda/lib/python3.10/site-packages/groundingdino-0.1.0-py3.10-linux-x86_64.egg/groundingdino\n"
     ]
    }
   ],
   "source": [
    "import groundingdino, os\n",
    "print(\"GroundingDINO en:\", os.path.dirname(groundingdino.__file__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac8dd91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /opt/conda/lib/python310.zip\n",
      "1 /opt/conda/lib/python3.10\n",
      "2 /opt/conda/lib/python3.10/lib-dynload\n",
      "3 \n",
      "4 /opt/conda/lib/python3.10/site-packages\n",
      "5 /opt/conda/lib/python3.10/site-packages/groundingdino-0.1.0-py3.10-linux-x86_64.egg\n",
      "6 /opt/program/GroundingDINO\n"
     ]
    }
   ],
   "source": [
    "for i, p in enumerate(sys.path):\n",
    "    print(i, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f8e663f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "#sys.path.append('../installing_dino/GroundingDINO')\n",
    "from groundingdino.util.inference import load_model, load_image, predict\n",
    "from groundingdino.util import box_ops\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f22fbfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "PyTorch: 2.3.1+cu121\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "CUDA version: 12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43576c1a",
   "metadata": {},
   "source": [
    "## 2. Configuración Baseline (1.1, 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9752ae9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración baseline:\n",
      "dataset:\n",
      "  image_dir: ../data/bdd100k/bdd100k/bdd100k/images/100k/val\n",
      "  val_calib_json: ../data/bdd100k_coco/val_calib.json\n",
      "  val_eval_json: ../data/bdd100k_coco/val_eval.json\n",
      "inference:\n",
      "  batch_size: 1\n",
      "  conf_threshold: 0.3\n",
      "  max_detections: 300\n",
      "  nms_iou: 0.65\n",
      "model:\n",
      "  architecture: SwinT-OGC\n",
      "  checkpoint: /opt/program/GroundingDINO/weights/groundingdino_swint_ogc.pth\n",
      "  config: /opt/program/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\n",
      "  device: cuda\n",
      "  input_size:\n",
      "  - 800\n",
      "  - 1333\n",
      "  name: Grounding-DINO\n",
      "prompts_file: ../data/prompts/bdd100k.txt\n",
      "seed: 42\n",
      "timestamp: '2025-11-10T22:42:10.653385'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path('../data')\n",
    "OUTPUT_DIR = Path('./outputs/baseline')\n",
    "QUALITATIVE_DIR = Path('./outputs/qualitative/baseline')\n",
    "CONFIG_DIR = Path('./configs')\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "QUALITATIVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CONFIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "baseline_config = {\n",
    "    'model': {\n",
    "        'name': 'Grounding-DINO',\n",
    "        'checkpoint': '/opt/program/GroundingDINO/weights/groundingdino_swint_ogc.pth',\n",
    "        'config': '/opt/program/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py',\n",
    "        'architecture': 'SwinT-OGC',\n",
    "        'input_size': [800, 1333],\n",
    "        'device': str(device)\n",
    "    },\n",
    "    'dataset': {\n",
    "        'image_dir': str(BASE_DIR / 'bdd100k/bdd100k/bdd100k/images/100k/val'),\n",
    "        'val_eval_json': str(BASE_DIR / 'bdd100k_coco/val_eval.json'),\n",
    "        'val_calib_json': str(BASE_DIR / 'bdd100k_coco/val_calib.json')\n",
    "    },\n",
    "    'inference': {\n",
    "        'conf_threshold': 0.30,\n",
    "        'nms_iou': 0.65,\n",
    "        'batch_size': 1,\n",
    "        'max_detections': 300\n",
    "    },\n",
    "    'prompts_file': str(BASE_DIR / 'prompts/bdd100k.txt'),\n",
    "    'seed': 42,\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "with open(CONFIG_DIR / 'baseline.yaml', 'w') as f:\n",
    "    yaml.dump(baseline_config, f, default_flow_style=False)\n",
    "\n",
    "print(\"Configuración baseline:\")\n",
    "print(yaml.dump(baseline_config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8381fa37",
   "metadata": {},
   "source": [
    "## 3. Definición del Vocabulario (1.3, 1.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d813d7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases BDD100K COCO: 10\n",
      "Text prompt para Grounding-DINO:\n",
      "person. rider. car. truck. bus. train. motorcycle. bicycle. traffic light. traffic sign.\n",
      "\n",
      "Mapeo guardado en: ../data/prompts/bdd100k.txt\n"
     ]
    }
   ],
   "source": [
    "BDD_COCO_CATEGORIES = {\n",
    "    1: 'person',\n",
    "    2: 'rider',\n",
    "    3: 'car',\n",
    "    4: 'truck',\n",
    "    5: 'bus',\n",
    "    6: 'train',\n",
    "    7: 'motorcycle',\n",
    "    8: 'bicycle',\n",
    "    9: 'traffic light',\n",
    "    10: 'traffic sign'\n",
    "}\n",
    "\n",
    "PROMPTS = [\n",
    "    'person',\n",
    "    'rider',\n",
    "    'car',\n",
    "    'truck',\n",
    "    'bus',\n",
    "    'train',\n",
    "    'motorcycle',\n",
    "    'bicycle',\n",
    "    'traffic light',\n",
    "    'traffic sign'\n",
    "]\n",
    "\n",
    "PROMPT_SYNONYMS = {\n",
    "    'bike': 'bicycle',\n",
    "    'motorbike': 'motorcycle',\n",
    "    'motor': 'motorcycle',\n",
    "    'stop sign': 'traffic sign',\n",
    "    'red light': 'traffic light',\n",
    "    'signal': 'traffic light',\n",
    "    'pedestrian': 'person',\n",
    "    'vehicle': 'car',\n",
    "    'bicyclist': 'rider'\n",
    "}\n",
    "\n",
    "CAT_ID_TO_PROMPT = {cat_id: name for cat_id, name in BDD_COCO_CATEGORIES.items()}\n",
    "PROMPT_TO_CAT_ID = {name: cat_id for cat_id, name in BDD_COCO_CATEGORIES.items()}\n",
    "PROMPT_IDX_TO_CAT_ID = {i: i+1 for i in range(len(PROMPTS))}\n",
    "\n",
    "PROMPTS_DIR = BASE_DIR / 'prompts'\n",
    "PROMPTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(PROMPTS_DIR / 'bdd100k.txt', 'w') as f:\n",
    "    for prompt in PROMPTS:\n",
    "        f.write(f\"{prompt}\\n\")\n",
    "\n",
    "TEXT_PROMPT = '. '.join(PROMPTS) + '.'\n",
    "\n",
    "print(f\"Clases BDD100K COCO: {len(BDD_COCO_CATEGORIES)}\")\n",
    "print(f\"Text prompt para Grounding-DINO:\\n{TEXT_PROMPT}\")\n",
    "print(f\"\\nMapeo guardado en: {PROMPTS_DIR / 'bdd100k.txt'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8026fd3d",
   "metadata": {},
   "source": [
    "## 4. Carga del Modelo Grounding-DINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "858b6e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando Grounding-DINO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado exitosamente\n"
     ]
    }
   ],
   "source": [
    "print(\"Cargando Grounding-DINO...\")\n",
    "model = load_model(baseline_config['model']['config'],baseline_config['model']['checkpoint'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(\"Modelo cargado exitosamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8aa772fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primer parámetro (transformer.level_embed) en: cuda:0\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Primer parámetro ({name}) en:\", param.device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf331b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ El modelo está en GPU (CUDA)\n"
     ]
    }
   ],
   "source": [
    "if next(model.parameters()).is_cuda:\n",
    "    print(\"✅ El modelo está en GPU (CUDA)\")\n",
    "else:\n",
    "    print(\"⚠️ El modelo está en CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78bc72d",
   "metadata": {},
   "source": [
    "## 5. Funciones de Post-procesamiento (2.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c474d06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funciones de post-procesamiento definidas\n"
     ]
    }
   ],
   "source": [
    "def normalize_label(label):\n",
    "    label_lower = label.lower().strip()\n",
    "    if label_lower in PROMPT_SYNONYMS:\n",
    "        return PROMPT_SYNONYMS[label_lower]\n",
    "    for canonical in PROMPTS:\n",
    "        if canonical in label_lower:\n",
    "            return canonical\n",
    "    return label_lower\n",
    "\n",
    "def cxcywh_to_xywh(bbox):\n",
    "    cx, cy, w, h = bbox\n",
    "    x = cx - w / 2\n",
    "    y = cy - h / 2\n",
    "    return [x, y, w, h]\n",
    "\n",
    "def clip_bbox(bbox, img_w, img_h):\n",
    "    x, y, w, h = bbox\n",
    "    x = max(0, min(x, img_w))\n",
    "    y = max(0, min(y, img_h))\n",
    "    w = max(0, min(w, img_w - x))\n",
    "    h = max(0, min(h, img_h - y))\n",
    "    return [x, y, w, h]\n",
    "\n",
    "def apply_nms(boxes, scores, labels, iou_threshold=0.65):\n",
    "    if len(boxes) == 0:\n",
    "        return boxes, scores, labels\n",
    "    \n",
    "    keep_indices = []\n",
    "    boxes_tensor = torch.tensor(boxes)\n",
    "    scores_tensor = torch.tensor(scores)\n",
    "    labels_tensor = torch.tensor(labels)\n",
    "    \n",
    "    for label_id in torch.unique(labels_tensor):\n",
    "        mask = labels_tensor == label_id\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        \n",
    "        class_boxes = boxes_tensor[mask]\n",
    "        class_scores = scores_tensor[mask]\n",
    "        class_indices = torch.where(mask)[0]\n",
    "        \n",
    "        x1 = class_boxes[:, 0]\n",
    "        y1 = class_boxes[:, 1]\n",
    "        x2 = class_boxes[:, 0] + class_boxes[:, 2]\n",
    "        y2 = class_boxes[:, 1] + class_boxes[:, 3]\n",
    "        areas = class_boxes[:, 2] * class_boxes[:, 3]\n",
    "        \n",
    "        order = class_scores.argsort(descending=True)\n",
    "        \n",
    "        keep = []\n",
    "        while order.numel() > 0:\n",
    "            if order.numel() == 1:\n",
    "                keep.append(order.item())\n",
    "                break\n",
    "            \n",
    "            i = order[0].item()\n",
    "            keep.append(i)\n",
    "            \n",
    "            xx1 = torch.maximum(x1[i], x1[order[1:]])\n",
    "            yy1 = torch.maximum(y1[i], y1[order[1:]])\n",
    "            xx2 = torch.minimum(x2[i], x2[order[1:]])\n",
    "            yy2 = torch.minimum(y2[i], y2[order[1:]])\n",
    "            \n",
    "            w = torch.maximum(torch.tensor(0.0), xx2 - xx1)\n",
    "            h = torch.maximum(torch.tensor(0.0), yy2 - yy1)\n",
    "            inter = w * h\n",
    "            \n",
    "            iou = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "            \n",
    "            mask_keep = iou <= iou_threshold\n",
    "            order = order[1:][mask_keep]\n",
    "        \n",
    "        keep_indices.extend(class_indices[keep].tolist())\n",
    "    \n",
    "    keep_indices = sorted(keep_indices)\n",
    "    return (\n",
    "        [boxes[i] for i in keep_indices],\n",
    "        [scores[i] for i in keep_indices],\n",
    "        [labels[i] for i in keep_indices]\n",
    "    )\n",
    "\n",
    "print(\"Funciones de post-procesamiento definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e247a626",
   "metadata": {},
   "source": [
    "## 6. Inferencia sobre val_eval (2.1, 2.3, 2.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6569e391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "Iniciando inferencia sobre 2000 imágenes de val_eval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "100%|██████████| 2000/2000 [12:05<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inferencia completada!\n",
      "Total predicciones: 22162\n",
      "Predicciones guardadas en: outputs/baseline/preds_raw.json\n",
      "Tiempo promedio por imagen: 0.275s\n",
      "FPS: 3.64\n",
      "Detecciones promedio por imagen: 11.1\n"
     ]
    }
   ],
   "source": [
    "coco_val = COCO(baseline_config['dataset']['val_eval_json'])\n",
    "image_ids = sorted(coco_val.getImgIds())\n",
    "\n",
    "predictions = []\n",
    "perf_metrics = {\n",
    "    'times': [],\n",
    "    'num_detections': [],\n",
    "    'gpu_memory_mb': []\n",
    "}\n",
    "\n",
    "print(f\"Iniciando inferencia sobre {len(image_ids)} imágenes de val_eval...\")\n",
    "\n",
    "sample_images = []\n",
    "sample_interval = len(image_ids) // 50 if len(image_ids) > 50 else 1\n",
    "\n",
    "for idx, img_id in enumerate(tqdm(image_ids)):\n",
    "    img_info = coco_val.loadImgs(img_id)[0]\n",
    "    img_path = Path(baseline_config['dataset']['image_dir']) / img_info['file_name']\n",
    "    \n",
    "    if not img_path.exists():\n",
    "        continue\n",
    "    \n",
    "    image_pil = Image.open(img_path).convert('RGB')\n",
    "    img_w, img_h = image_pil.size\n",
    "    \n",
    "    image_source, image_transformed = load_image(str(img_path))\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        boxes, logits, phrases = predict(\n",
    "            model=model,\n",
    "            image=image_transformed,\n",
    "            caption=TEXT_PROMPT,\n",
    "            box_threshold=baseline_config['inference']['conf_threshold'],\n",
    "            text_threshold=0.25,\n",
    "            device=device\n",
    "        )\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    elapsed = time.time() - start_time\n",
    "    perf_metrics['times'].append(elapsed)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        perf_metrics['gpu_memory_mb'].append(torch.cuda.max_memory_allocated() / 1024 / 1024)\n",
    "    \n",
    "    boxes_xyxy = box_ops.box_cxcywh_to_xyxy(boxes) * torch.tensor([img_w, img_h, img_w, img_h])\n",
    "    boxes_xywh = []\n",
    "    for box in boxes_xyxy:\n",
    "        x1, y1, x2, y2 = box.tolist()\n",
    "        boxes_xywh.append([x1, y1, x2 - x1, y2 - y1])\n",
    "    \n",
    "    scores = logits.tolist()\n",
    "    labels_raw = [normalize_label(p) for p in phrases]\n",
    "    category_ids = [PROMPT_TO_CAT_ID.get(lbl, -1) for lbl in labels_raw]\n",
    "    \n",
    "    valid_mask = [cid != -1 for cid in category_ids]\n",
    "    boxes_xywh = [b for b, m in zip(boxes_xywh, valid_mask) if m]\n",
    "    scores = [s for s, m in zip(scores, valid_mask) if m]\n",
    "    category_ids = [c for c, m in zip(category_ids, valid_mask) if m]\n",
    "    \n",
    "    if len(boxes_xywh) > 0:\n",
    "        boxes_xywh, scores, category_ids = apply_nms(\n",
    "            boxes_xywh, scores, category_ids, \n",
    "            iou_threshold=baseline_config['inference']['nms_iou']\n",
    "        )\n",
    "    \n",
    "    if len(boxes_xywh) > baseline_config['inference']['max_detections']:\n",
    "        sorted_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)\n",
    "        sorted_indices = sorted_indices[:baseline_config['inference']['max_detections']]\n",
    "        boxes_xywh = [boxes_xywh[i] for i in sorted_indices]\n",
    "        scores = [scores[i] for i in sorted_indices]\n",
    "        category_ids = [category_ids[i] for i in sorted_indices]\n",
    "    \n",
    "    for box, score, cat_id in zip(boxes_xywh, scores, category_ids):\n",
    "        box_clipped = clip_bbox(box, img_w, img_h)\n",
    "        predictions.append({\n",
    "            'image_id': int(img_id),\n",
    "            'category_id': int(cat_id),\n",
    "            'bbox': [float(b) for b in box_clipped],\n",
    "            'score': float(score)\n",
    "        })\n",
    "    \n",
    "    perf_metrics['num_detections'].append(len(boxes_xywh))\n",
    "    \n",
    "    if idx % sample_interval == 0 and len(sample_images) < 50:\n",
    "        sample_images.append({\n",
    "            'image_id': img_id,\n",
    "            'image_path': str(img_path),\n",
    "            'num_dets': len(boxes_xywh)\n",
    "        })\n",
    "\n",
    "preds_path = OUTPUT_DIR / 'preds_raw.json'\n",
    "with open(preds_path, 'w') as f:\n",
    "    json.dump(predictions, f)\n",
    "\n",
    "print(f\"\\nInferencia completada!\")\n",
    "print(f\"Total predicciones: {len(predictions)}\")\n",
    "print(f\"Predicciones guardadas en: {preds_path}\")\n",
    "print(f\"Tiempo promedio por imagen: {np.mean(perf_metrics['times']):.3f}s\")\n",
    "print(f\"FPS: {1.0 / np.mean(perf_metrics['times']):.2f}\")\n",
    "print(f\"Detecciones promedio por imagen: {np.mean(perf_metrics['num_detections']):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2748a226",
   "metadata": {},
   "source": [
    "## 7. Guardado de Métricas de Rendimiento (2.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bbd5ec0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perf_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m perf_summary \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_time_per_image_s\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mperf_metrics\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimes\u001b[39m\u001b[38;5;124m'\u001b[39m])),\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd_time_per_image_s\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mstd(perf_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimes\u001b[39m\u001b[38;5;124m'\u001b[39m])),\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfps\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(perf_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimes\u001b[39m\u001b[38;5;124m'\u001b[39m])),\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_detections_per_image\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(perf_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_detections\u001b[39m\u001b[38;5;124m'\u001b[39m])),\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd_detections_per_image\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mstd(perf_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_detections\u001b[39m\u001b[38;5;124m'\u001b[39m])),\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_predictions\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(predictions),\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_images\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(image_ids)\n\u001b[1;32m      9\u001b[0m }\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m     12\u001b[0m     perf_summary[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_gpu_memory_mb\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(perf_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu_memory_mb\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'perf_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "perf_summary = {\n",
    "    'avg_time_per_image_s': float(np.mean(perf_metrics['times'])),\n",
    "    'std_time_per_image_s': float(np.std(perf_metrics['times'])),\n",
    "    'fps': float(1.0 / np.mean(perf_metrics['times'])),\n",
    "    'avg_detections_per_image': float(np.mean(perf_metrics['num_detections'])),\n",
    "    'std_detections_per_image': float(np.std(perf_metrics['num_detections'])),\n",
    "    'total_predictions': len(predictions),\n",
    "    'total_images': len(image_ids)\n",
    "}\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    perf_summary['avg_gpu_memory_mb'] = float(np.mean(perf_metrics['gpu_memory_mb']))\n",
    "    perf_summary['peak_gpu_memory_mb'] = float(np.max(perf_metrics['gpu_memory_mb']))\n",
    "\n",
    "with open(OUTPUT_DIR / 'perf.txt', 'w') as f:\n",
    "    f.write(\"=\" * 60 + \"\\n\")\n",
    "    f.write(\"BASELINE PERFORMANCE METRICS\\n\")\n",
    "    f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "    for key, value in perf_summary.items():\n",
    "        f.write(f\"{key}: {value}\\n\")\n",
    "    f.write(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "\n",
    "print(\"\\nMétricas de rendimiento guardadas en:\", OUTPUT_DIR / 'perf.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b353ee",
   "metadata": {},
   "source": [
    "## 8. Evaluación COCO (3.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbcbd3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecutando evaluación COCO...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.63s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.73s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.170\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.279\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.171\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.063\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.377\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.284\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.107\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.272\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.540\n",
      "\n",
      "Evaluando métricas por clase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clases:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clases:  10%|█         | 1/10 [00:00<00:03,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=0.33s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.06s).\n",
      "  ⚠️ person: Sin predicciones\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.06s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      "  ⚠️ rider: Sin predicciones\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clases:  30%|███       | 3/10 [00:02<00:05,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=1.49s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.16s).\n",
      "  ⚠️ car: Sin predicciones\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clases:  50%|█████     | 5/10 [00:02<00:02,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=0.19s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      "  ⚠️ truck: Sin predicciones\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.07s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      "  ⚠️ bus: Sin predicciones\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "  ⚠️ train: Sin predicciones\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clases:  70%|███████   | 7/10 [00:02<00:00,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=0.06s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      "  ⚠️ motorcycle: Sin predicciones\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.05s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "  ⚠️ bicycle: Sin predicciones\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clases:  90%|█████████ | 9/10 [00:03<00:00,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=0.55s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.10s).\n",
      "  ⚠️ traffic light: Sin predicciones\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clases: 100%|██████████| 10/10 [00:03<00:00,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=0.50s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.09s).\n",
      "  ⚠️ traffic sign: Sin predicciones\n",
      "\n",
      "============================================================\n",
      "MÉTRICAS GLOBALES\n",
      "============================================================\n",
      "  mAP@[.50:.95]: 0.1705\n",
      "  AP@50: 0.2785\n",
      "  AP@75: 0.1705\n",
      "\n",
      "============================================================\n",
      "MÉTRICAS POR CLASE\n",
      "============================================================\n",
      "  person         : mAP=0.000  AP50=0.000  AP75=0.000\n",
      "  rider          : mAP=0.000  AP50=0.000  AP75=0.000\n",
      "  car            : mAP=0.000  AP50=0.000  AP75=0.000\n",
      "  truck          : mAP=0.000  AP50=0.000  AP75=0.000\n",
      "  bus            : mAP=0.000  AP50=0.000  AP75=0.000\n",
      "  train          : mAP=0.000  AP50=0.000  AP75=0.000\n",
      "  motorcycle     : mAP=0.000  AP50=0.000  AP75=0.000\n",
      "  bicycle        : mAP=0.000  AP50=0.000  AP75=0.000\n",
      "  traffic light  : mAP=0.000  AP50=0.000  AP75=0.000\n",
      "  traffic sign   : mAP=0.000  AP50=0.000  AP75=0.000\n",
      "\n",
      "✓ Métricas guardadas en: outputs/baseline/metrics.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Ejecutando evaluación COCO...\")\n",
    "\n",
    "# Cargar predicciones desde archivo si no están en memoria\n",
    "if 'predictions' not in locals() or 'preds_path' not in locals():\n",
    "    print(\"⚠️ Cargando predicciones desde archivo...\")\n",
    "    preds_path = OUTPUT_DIR / 'preds_raw.json'\n",
    "    if not preds_path.exists():\n",
    "        raise FileNotFoundError(f\"No se encontró el archivo de predicciones: {preds_path}\\n\"\n",
    "                                \"Ejecuta primero la Sección 6 (Inferencia)\")\n",
    "    \n",
    "    with open(preds_path, 'r') as f:\n",
    "        predictions = json.load(f)\n",
    "    print(f\"✓ Predicciones cargadas: {len(predictions)} detecciones\")\n",
    "\n",
    "# Cargar COCO val si no está en memoria\n",
    "if 'coco_val' not in locals():\n",
    "    print(\"⚠️ Cargando anotaciones COCO...\")\n",
    "    coco_val = COCO(baseline_config['dataset']['val_eval_json'])\n",
    "    print(\"✓ Anotaciones COCO cargadas\")\n",
    "\n",
    "# Evaluación COCO global\n",
    "coco_dt = coco_val.loadRes(str(preds_path))\n",
    "coco_eval = COCOeval(coco_val, coco_dt, 'bbox')\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()\n",
    "\n",
    "metrics_coco = {\n",
    "    'mAP': float(coco_eval.stats[0]),\n",
    "    'AP50': float(coco_eval.stats[1]),\n",
    "    'AP75': float(coco_eval.stats[2]),\n",
    "    'AP_small': float(coco_eval.stats[3]),\n",
    "    'AP_medium': float(coco_eval.stats[4]),\n",
    "    'AP_large': float(coco_eval.stats[5]),\n",
    "    'AR_max1': float(coco_eval.stats[6]),\n",
    "    'AR_max10': float(coco_eval.stats[7]),\n",
    "    'AR_max100': float(coco_eval.stats[8]),\n",
    "    'AR_small': float(coco_eval.stats[9]),\n",
    "    'AR_medium': float(coco_eval.stats[10]),\n",
    "    'AR_large': float(coco_eval.stats[11])\n",
    "}\n",
    "\n",
    "print(\"\\nEvaluando métricas por clase...\")\n",
    "per_class_metrics = {}\n",
    "for cat_id, cat_name in tqdm(BDD_COCO_CATEGORIES.items(), desc=\"Clases\"):\n",
    "    coco_eval_class = COCOeval(coco_val, coco_dt, 'bbox')\n",
    "    coco_eval_class.params.catIds = [cat_id]\n",
    "    \n",
    "    try:\n",
    "        coco_eval_class.evaluate()\n",
    "        coco_eval_class.accumulate()\n",
    "        \n",
    "        # Verificar que stats existe y tiene datos\n",
    "        if hasattr(coco_eval_class, 'stats') and coco_eval_class.stats is not None and len(coco_eval_class.stats) > 0:\n",
    "            per_class_metrics[cat_name] = {\n",
    "                'mAP': float(coco_eval_class.stats[0]) if coco_eval_class.stats[0] >= 0 else 0.0,\n",
    "                'AP50': float(coco_eval_class.stats[1]) if coco_eval_class.stats[1] >= 0 else 0.0,\n",
    "                'AP75': float(coco_eval_class.stats[2]) if coco_eval_class.stats[2] >= 0 else 0.0\n",
    "            }\n",
    "        else:\n",
    "            # Si no hay stats, la clase no tiene predicciones\n",
    "            per_class_metrics[cat_name] = {\n",
    "                'mAP': 0.0,\n",
    "                'AP50': 0.0,\n",
    "                'AP75': 0.0\n",
    "            }\n",
    "            print(f\"  ⚠️ {cat_name}: Sin predicciones\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠️ Error evaluando {cat_name}: {e}\")\n",
    "        per_class_metrics[cat_name] = {\n",
    "            'mAP': 0.0,\n",
    "            'AP50': 0.0,\n",
    "            'AP75': 0.0\n",
    "        }\n",
    "\n",
    "metrics_coco['per_class'] = per_class_metrics\n",
    "\n",
    "with open(OUTPUT_DIR / 'metrics.json', 'w') as f:\n",
    "    json.dump(metrics_coco, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MÉTRICAS GLOBALES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"  mAP@[.50:.95]: {metrics_coco['mAP']:.4f}\")\n",
    "print(f\"  AP@50: {metrics_coco['AP50']:.4f}\")\n",
    "print(f\"  AP@75: {metrics_coco['AP75']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MÉTRICAS POR CLASE\")\n",
    "print(\"=\"*60)\n",
    "for cat_name, metrics in per_class_metrics.items():\n",
    "    print(f\"  {cat_name:15s}: mAP={metrics['mAP']:.3f}  AP50={metrics['AP50']:.3f}  AP75={metrics['AP75']:.3f}\")\n",
    "\n",
    "print(f\"\\n✓ Métricas guardadas en: {OUTPUT_DIR / 'metrics.json'}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7beb0480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de predicciones por clase:\n",
      "  person         :  2436 predicciones\n",
      "  rider          :   339 predicciones\n",
      "  car            :  8343 predicciones\n",
      "  truck          :  1412 predicciones\n",
      "  bus            :   437 predicciones\n",
      "  train          :    76 predicciones\n",
      "  motorcycle     :   594 predicciones\n",
      "  bicycle        :   169 predicciones\n",
      "  traffic light  :  5238 predicciones\n",
      "  traffic sign   :  3118 predicciones\n"
     ]
    }
   ],
   "source": [
    "# Diagnóstico rápido\n",
    "print(\"Distribución de predicciones por clase:\")\n",
    "for cat_id, cat_name in BDD_COCO_CATEGORIES.items():\n",
    "    count = sum(1 for p in predictions if p['category_id'] == cat_id)\n",
    "    print(f\"  {cat_name:15s}: {count:5d} predicciones\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda45617",
   "metadata": {},
   "source": [
    "## 9. Curvas Precision-Recall (3.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b631d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando curvas Precision-Recall...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curvas PR:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.39s).\n",
      "Accumulating evaluation results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curvas PR:  10%|█         | 1/10 [00:00<00:07,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=0.28s).\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.05s).\n",
      "Accumulating evaluation results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curvas PR:  20%|██        | 2/10 [00:01<00:03,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=0.02s).\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.40s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.15s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curvas PR:  30%|███       | 3/10 [00:02<00:07,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.14s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curvas PR:  40%|████      | 4/10 [00:03<00:04,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.08s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curvas PR:  60%|██████    | 6/10 [00:03<00:01,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.05s).\n",
      "Accumulating evaluation results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curvas PR:  80%|████████  | 8/10 [00:03<00:00,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=0.01s).\n",
      "  ⚠️ motorcycle: Sin puntos válidos de precisión\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.04s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.54s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.09s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curvas PR:  90%|█████████ | 9/10 [00:04<00:00,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.46s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curvas PR: 100%|██████████| 10/10 [00:05<00:00,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Curvas PR guardadas en: outputs/baseline/pr_curves\n",
      "✓ Resumen guardado en: outputs/baseline/pr_curves/README.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "PR_DIR = OUTPUT_DIR / 'pr_curves'\n",
    "PR_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Cargar datos si no están en memoria\n",
    "if 'coco_val' not in locals() or 'coco_dt' not in locals():\n",
    "    print(\"⚠️ Cargando datos necesarios...\")\n",
    "    preds_path = OUTPUT_DIR / 'preds_raw.json'\n",
    "    coco_val = COCO(baseline_config['dataset']['val_eval_json'])\n",
    "    coco_dt = coco_val.loadRes(str(preds_path))\n",
    "    print(\"✓ Datos cargados\")\n",
    "\n",
    "print(\"Generando curvas Precision-Recall...\")\n",
    "for cat_id, cat_name in tqdm(BDD_COCO_CATEGORIES.items(), desc=\"Curvas PR\"):\n",
    "    coco_eval_class = COCOeval(coco_val, coco_dt, 'bbox')\n",
    "    coco_eval_class.params.catIds = [cat_id]\n",
    "    \n",
    "    try:\n",
    "        coco_eval_class.evaluate()\n",
    "        coco_eval_class.accumulate()\n",
    "        \n",
    "        # Verificar que eval existe y tiene datos\n",
    "        if not hasattr(coco_eval_class, 'eval') or coco_eval_class.eval is None:\n",
    "            print(f\"  ⚠️ {cat_name}: Sin datos de evaluación\")\n",
    "            continue\n",
    "        \n",
    "        if 'precision' not in coco_eval_class.eval:\n",
    "            print(f\"  ⚠️ {cat_name}: Sin datos de precisión\")\n",
    "            continue\n",
    "        \n",
    "        # Cuando se evalúa una sola clase, usar índice 0 en vez de cat_id-1\n",
    "        # Formato: [T, R, K, A, M] donde K es el índice de clase\n",
    "        # T=thresholds IoU, R=recall points, K=class, A=area, M=max_dets\n",
    "        precision_array = coco_eval_class.eval['precision']\n",
    "        \n",
    "        # Para una sola clase, K=0 (no cat_id-1)\n",
    "        # [0, :, 0, 0, 2] = IoU=0.5:0.95, todos los recalls, clase 0, área=all, maxDets=100\n",
    "        if precision_array.shape[2] == 1:\n",
    "            # Evaluación de una sola clase\n",
    "            precision = precision_array[0, :, 0, 0, 2]\n",
    "        else:\n",
    "            # Evaluación multi-clase (no debería llegar aquí)\n",
    "            precision = precision_array[0, :, cat_id-1, 0, 2]\n",
    "        \n",
    "        recall = np.linspace(0, 1, 101)\n",
    "        \n",
    "        # Filtrar valores válidos\n",
    "        valid_mask = precision > -1\n",
    "        precision_valid = precision[valid_mask]\n",
    "        recall_valid = recall[valid_mask]\n",
    "        \n",
    "        if len(precision_valid) > 0:\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(recall_valid, precision_valid, linewidth=2, color='#2E86AB')\n",
    "            plt.xlabel('Recall', fontsize=12, fontweight='bold')\n",
    "            plt.ylabel('Precision', fontsize=12, fontweight='bold')\n",
    "            plt.title(f'Precision-Recall Curve: {cat_name}', fontsize=14, fontweight='bold')\n",
    "            plt.grid(True, alpha=0.3, linestyle='--')\n",
    "            plt.xlim([0, 1])\n",
    "            plt.ylim([0, 1])\n",
    "            \n",
    "            # Calcular área bajo la curva (AP)\n",
    "            ap = np.trapz(precision_valid, recall_valid) if len(precision_valid) > 1 else 0.0\n",
    "            plt.text(0.6, 0.05, f'AP = {ap:.3f}', fontsize=11, \n",
    "                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(PR_DIR / f'{cat_name.replace(\" \", \"_\")}_pr.png', dpi=150, bbox_inches='tight')\n",
    "            plt.close()\n",
    "        else:\n",
    "            print(f\"  ⚠️ {cat_name}: Sin puntos válidos de precisión\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠️ Error generando curva PR para {cat_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n✓ Curvas PR guardadas en: {PR_DIR}\")\n",
    "\n",
    "# Generar resumen de curvas\n",
    "summary_lines = [\"RESUMEN DE CURVAS PRECISION-RECALL\\n\", \"=\"*50 + \"\\n\\n\"]\n",
    "for cat_name in BDD_COCO_CATEGORIES.values():\n",
    "    pr_file = PR_DIR / f'{cat_name.replace(\" \", \"_\")}_pr.png'\n",
    "    status = \"✓\" if pr_file.exists() else \"✗\"\n",
    "    summary_lines.append(f\"{status} {cat_name:15s}: {pr_file.name}\\n\")\n",
    "\n",
    "with open(PR_DIR / 'README.txt', 'w') as f:\n",
    "    f.writelines(summary_lines)\n",
    "\n",
    "print(f\"✓ Resumen guardado en: {PR_DIR / 'README.txt'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399dda22",
   "metadata": {},
   "source": [
    "## 10. Sensibilidad a Umbrales (3.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60188e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barrido de umbrales de confianza...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.20s).\n",
      "Accumulating evaluation results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 1/11 [00:04<00:42,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=0.50s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.170\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.279\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.171\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.063\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.377\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.284\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.107\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.272\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.540\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.90s).\n",
      "Accumulating evaluation results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 2/11 [00:08<00:37,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=0.69s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.170\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.279\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.171\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.063\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.377\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.284\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.107\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.272\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.540\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.96s).\n",
      "Accumulating evaluation results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 3/11 [00:12<00:32,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=0.51s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.170\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.279\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.171\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.063\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.377\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.284\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.107\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.272\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.540\n",
      "Loading and preparing results...\n",
      "DONE (t=0.26s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.79s).\n",
      "Accumulating evaluation results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 4/11 [00:16<00:28,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=0.50s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.170\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.279\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.171\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.063\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.377\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.284\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.107\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.272\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.540\n",
      "Loading and preparing results...\n",
      "DONE (t=0.27s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.86s).\n",
      "Accumulating evaluation results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 5/11 [00:20<00:24,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=0.49s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.170\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.279\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.171\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.063\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.377\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.284\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.107\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.272\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.540\n",
      "Loading and preparing results...\n",
      "DONE (t=0.27s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.84s).\n",
      "Accumulating evaluation results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 6/11 [00:24<00:20,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=0.50s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.170\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.279\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.171\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.063\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.377\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.284\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.107\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.272\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.540\n",
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.53s).\n",
      "Accumulating evaluation results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 7/11 [00:27<00:15,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=0.46s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.155\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.247\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.157\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.053\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.160\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.351\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.252\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.252\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.082\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.228\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.500\n",
      "Loading and preparing results...\n",
      "DONE (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.07s).\n",
      "Accumulating evaluation results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 8/11 [00:30<00:10,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=0.34s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.136\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.210\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.142\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.043\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.133\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.323\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.165\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.059\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.456\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.42s).\n",
      "Accumulating evaluation results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 9/11 [00:32<00:05,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=0.30s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.132\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.096\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.023\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.086\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.241\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.088\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.109\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.109\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.027\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.107\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.269\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.97s).\n",
      "Accumulating evaluation results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 10/11 [00:33<00:02,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=0.22s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.057\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.076\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.061\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.043\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.153\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.056\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.062\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.062\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.049\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.166\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:34<00:00,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=0.84s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.18s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.015\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.017\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.015\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.033\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Barrido de umbrales guardado en: outputs/baseline/threshold_sweep.csv\n"
     ]
    }
   ],
   "source": [
    "threshold_sweep = []\n",
    "conf_thresholds = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.50, 0.60, 0.75]\n",
    "\n",
    "print(\"Barrido de umbrales de confianza...\")\n",
    "for conf_th in tqdm(conf_thresholds):\n",
    "    preds_filtered = [p for p in predictions if p['score'] >= conf_th]\n",
    "    \n",
    "    if len(preds_filtered) == 0:\n",
    "        continue\n",
    "    \n",
    "    temp_path = OUTPUT_DIR / f'temp_preds_{conf_th}.json'\n",
    "    with open(temp_path, 'w') as f:\n",
    "        json.dump(preds_filtered, f)\n",
    "    \n",
    "    coco_dt_temp = coco_val.loadRes(str(temp_path))\n",
    "    coco_eval_temp = COCOeval(coco_val, coco_dt_temp, 'bbox')\n",
    "    coco_eval_temp.evaluate()\n",
    "    coco_eval_temp.accumulate()\n",
    "    coco_eval_temp.summarize()\n",
    "    \n",
    "    threshold_sweep.append({\n",
    "        'conf_threshold': conf_th,\n",
    "        'mAP': float(coco_eval_temp.stats[0]),\n",
    "        'AP50': float(coco_eval_temp.stats[1]),\n",
    "        'AP75': float(coco_eval_temp.stats[2]),\n",
    "        'num_predictions': len(preds_filtered)\n",
    "    })\n",
    "    \n",
    "    temp_path.unlink()\n",
    "\n",
    "threshold_df = pd.DataFrame(threshold_sweep)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(threshold_df['conf_threshold'], threshold_df['mAP'], 'o-', label='mAP')\n",
    "plt.plot(threshold_df['conf_threshold'], threshold_df['AP50'], 's-', label='AP50')\n",
    "plt.plot(threshold_df['conf_threshold'], threshold_df['AP75'], '^-', label='AP75')\n",
    "plt.xlabel('Confidence Threshold')\n",
    "plt.ylabel('Average Precision')\n",
    "plt.title('AP vs Confidence Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(threshold_df['conf_threshold'], threshold_df['num_predictions'], 'o-')\n",
    "plt.xlabel('Confidence Threshold')\n",
    "plt.ylabel('Number of Predictions')\n",
    "plt.title('Predictions vs Threshold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'threshold_sensitivity.png', dpi=150)\n",
    "plt.close()\n",
    "\n",
    "threshold_df.to_csv(OUTPUT_DIR / 'threshold_sweep.csv', index=False)\n",
    "print(f\"\\nBarrido de umbrales guardado en: {OUTPUT_DIR / 'threshold_sweep.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b8ba05",
   "metadata": {},
   "source": [
    "## 11. Visualización Cualitativa (3.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c353721b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Seleccionando imágenes de muestra para visualización...\n",
      "✓ 50 imágenes seleccionadas para visualización\n",
      "  Rango de detecciones: 2 - 37\n",
      "\n",
      "Generando visualizaciones cualitativas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizaciones: 100%|██████████| 50/50 [00:13<00:00,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ 50 visualizaciones guardadas en: outputs/qualitative/baseline\n",
      "✓ Índice HTML generado: outputs/qualitative/baseline/index.html\n",
      "  Abre este archivo en un navegador para ver todas las visualizaciones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "# Cargar predicciones si no están en memoria\n",
    "if 'predictions' not in locals():\n",
    "    print(\"⚠️ Cargando predicciones desde archivo...\")\n",
    "    preds_path = OUTPUT_DIR / 'preds_raw.json'\n",
    "    with open(preds_path, 'r') as f:\n",
    "        predictions = json.load(f)\n",
    "    print(f\"✓ {len(predictions)} predicciones cargadas\")\n",
    "\n",
    "# Cargar COCO val si no está\n",
    "if 'coco_val' not in locals():\n",
    "    print(\"⚠️ Cargando anotaciones COCO...\")\n",
    "    coco_val = COCO(baseline_config['dataset']['val_eval_json'])\n",
    "    print(\"✓ Anotaciones COCO cargadas\")\n",
    "\n",
    "# Generar sample_images si no existe\n",
    "if 'sample_images' not in locals():\n",
    "    print(\"⚠️ Seleccionando imágenes de muestra para visualización...\")\n",
    "    image_ids = sorted(coco_val.getImgIds())\n",
    "    \n",
    "    # Agrupar predicciones por imagen\n",
    "    preds_per_image = {}\n",
    "    for pred in predictions:\n",
    "        img_id = pred['image_id']\n",
    "        if img_id not in preds_per_image:\n",
    "            preds_per_image[img_id] = []\n",
    "        preds_per_image[img_id].append(pred)\n",
    "    \n",
    "    # Seleccionar muestra estratificada: imágenes con diferentes cantidades de detecciones\n",
    "    sample_images = []\n",
    "    \n",
    "    # Ordenar imágenes por número de detecciones\n",
    "    image_det_counts = [(img_id, len(preds_per_image.get(img_id, []))) \n",
    "                        for img_id in image_ids]\n",
    "    image_det_counts.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Seleccionar 50 imágenes distribuidas\n",
    "    sample_interval = max(1, len(image_det_counts) // 50)\n",
    "    for i in range(0, len(image_det_counts), sample_interval):\n",
    "        if len(sample_images) >= 50:\n",
    "            break\n",
    "        \n",
    "        img_id, num_dets = image_det_counts[i]\n",
    "        img_info = coco_val.loadImgs(img_id)[0]\n",
    "        img_path = Path(baseline_config['dataset']['image_dir']) / img_info['file_name']\n",
    "        \n",
    "        if img_path.exists():\n",
    "            sample_images.append({\n",
    "                'image_id': img_id,\n",
    "                'image_path': str(img_path),\n",
    "                'num_dets': num_dets\n",
    "            })\n",
    "    \n",
    "    print(f\"✓ {len(sample_images)} imágenes seleccionadas para visualización\")\n",
    "    print(f\"  Rango de detecciones: {min(s['num_dets'] for s in sample_images)} - {max(s['num_dets'] for s in sample_images)}\")\n",
    "\n",
    "# Colores para las clases\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, 10))\n",
    "cat_colors = {cat_id: colors[i] for i, cat_id in enumerate(BDD_COCO_CATEGORIES.keys())}\n",
    "\n",
    "print(\"\\nGenerando visualizaciones cualitativas...\")\n",
    "viz_count = 0\n",
    "for i, sample in enumerate(tqdm(sample_images[:50], desc=\"Visualizaciones\")):\n",
    "    img_id = sample['image_id']\n",
    "    img_path = Path(sample['image_path'])\n",
    "    \n",
    "    if not img_path.exists():\n",
    "        print(f\"  ⚠️ Imagen no encontrada: {img_path}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        img_w, img_h = image.size\n",
    "        \n",
    "        # Filtrar predicciones para esta imagen\n",
    "        img_preds = [p for p in predictions if p['image_id'] == img_id]\n",
    "        \n",
    "        # Crear figura\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(16, 9))\n",
    "        ax.imshow(image)\n",
    "        \n",
    "        # Dibujar bounding boxes\n",
    "        for pred in img_preds:\n",
    "            bbox = pred['bbox']\n",
    "            cat_id = pred['category_id']\n",
    "            score = pred['score']\n",
    "            \n",
    "            x, y, w, h = bbox\n",
    "            \n",
    "            # Dibujar rectángulo\n",
    "            rect = patches.Rectangle(\n",
    "                (x, y), w, h,\n",
    "                linewidth=2.5,\n",
    "                edgecolor=cat_colors[cat_id],\n",
    "                facecolor='none'\n",
    "            )\n",
    "            ax.add_patch(rect)\n",
    "            \n",
    "            # Añadir etiqueta\n",
    "            label = f\"{CAT_ID_TO_PROMPT[cat_id]} {score:.2f}\"\n",
    "            ax.text(\n",
    "                x, max(0, y - 5),\n",
    "                label,\n",
    "                fontsize=9,\n",
    "                color='white',\n",
    "                weight='bold',\n",
    "                bbox=dict(facecolor=cat_colors[cat_id], alpha=0.8, \n",
    "                         pad=3, edgecolor='white', linewidth=1)\n",
    "            )\n",
    "        \n",
    "        ax.axis('off')\n",
    "        ax.set_title(\n",
    "            f'Image ID: {img_id} | Detections: {len(img_preds)}',\n",
    "            fontsize=14,\n",
    "            fontweight='bold',\n",
    "            pad=10\n",
    "        )\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        output_path = QUALITATIVE_DIR / f'{img_id:07d}.jpg'\n",
    "        plt.savefig(output_path, dpi=100, bbox_inches='tight', pad_inches=0.1)\n",
    "        plt.close()\n",
    "        \n",
    "        viz_count += 1\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠️ Error procesando imagen {img_id}: {e}\")\n",
    "        plt.close('all')\n",
    "        continue\n",
    "\n",
    "print(f\"\\n✓ {viz_count} visualizaciones guardadas en: {QUALITATIVE_DIR}\")\n",
    "\n",
    "# Generar índice HTML para visualización rápida\n",
    "html_content = ['<!DOCTYPE html>\\n<html>\\n<head>\\n']\n",
    "html_content.append('  <meta charset=\"UTF-8\">\\n')\n",
    "html_content.append('  <title>Baseline Qualitative Results</title>\\n')\n",
    "html_content.append('  <style>\\n')\n",
    "html_content.append('    body { font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }\\n')\n",
    "html_content.append('    h1 { color: #333; }\\n')\n",
    "html_content.append('    .grid { display: grid; grid-template-columns: repeat(auto-fill, minmax(400px, 1fr)); gap: 20px; }\\n')\n",
    "html_content.append('    .item { background: white; padding: 10px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }\\n')\n",
    "html_content.append('    img { width: 100%; height: auto; border-radius: 4px; }\\n')\n",
    "html_content.append('    .caption { margin-top: 10px; font-size: 14px; color: #666; }\\n')\n",
    "html_content.append('  </style>\\n')\n",
    "html_content.append('</head>\\n<body>\\n')\n",
    "html_content.append('  <h1>Baseline Detection Results (BDD100K val_eval)</h1>\\n')\n",
    "html_content.append(f'  <p>Total visualizations: {viz_count}</p>\\n')\n",
    "html_content.append('  <div class=\"grid\">\\n')\n",
    "\n",
    "for sample in sample_images[:viz_count]:\n",
    "    img_id = sample['image_id']\n",
    "    num_dets = sample['num_dets']\n",
    "    img_file = f'{img_id:07d}.jpg'\n",
    "    \n",
    "    if (QUALITATIVE_DIR / img_file).exists():\n",
    "        html_content.append('    <div class=\"item\">\\n')\n",
    "        html_content.append(f'      <img src=\"{img_file}\" alt=\"Image {img_id}\">\\n')\n",
    "        html_content.append(f'      <div class=\"caption\">Image ID: {img_id} | Detections: {num_dets}</div>\\n')\n",
    "        html_content.append('    </div>\\n')\n",
    "\n",
    "html_content.append('  </div>\\n')\n",
    "html_content.append('</body>\\n</html>')\n",
    "\n",
    "with open(QUALITATIVE_DIR / 'index.html', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(html_content)\n",
    "\n",
    "print(f\"✓ Índice HTML generado: {QUALITATIVE_DIR / 'index.html'}\")\n",
    "print(f\"  Abre este archivo en un navegador para ver todas las visualizaciones\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621c4528",
   "metadata": {},
   "source": [
    "## 12. Preparación para Calibración (4.1, 4.2, 4.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06466f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando inputs para calibración sobre val_calib...\n",
      "loading annotations into memory...\n",
      "Done (t=2.23s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [1:03:25<00:00,  2.10it/s]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 96\u001b[0m\n\u001b[1;32m     85\u001b[0m         calib_records\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_id\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mint\u001b[39m(img_id),\n\u001b[1;32m     87\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbbox\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28mfloat\u001b[39m(b) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m pred_box],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgt_ann_id\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mint\u001b[39m(best_match) \u001b[38;5;28;01mif\u001b[39;00m best_match \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     93\u001b[0m         })\n\u001b[1;32m     95\u001b[0m calib_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(calib_records)\n\u001b[0;32m---> 96\u001b[0m \u001b[43mcalib_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOUTPUT_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcalib_inputs.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCalibration inputs generados: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(calib_records)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m detecciones\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGuardado en: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUTPUT_DIR\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcalib_inputs.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:3124\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[0;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m   3043\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3044\u001b[0m \u001b[38;5;124;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[1;32m   3045\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3120\u001b[0m \u001b[38;5;124;03m>>> content = f.read()\u001b[39;00m\n\u001b[1;32m   3121\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3122\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[0;32m-> 3124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3132\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parquet.py:478\u001b[0m, in \u001b[0;36mto_parquet\u001b[0;34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(partition_cols, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    477\u001b[0m     partition_cols \u001b[38;5;241m=\u001b[39m [partition_cols]\n\u001b[0;32m--> 478\u001b[0m impl \u001b[38;5;241m=\u001b[39m \u001b[43mget_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m path_or_buf: FilePath \u001b[38;5;241m|\u001b[39m WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[1;32m    482\u001b[0m impl\u001b[38;5;241m.\u001b[39mwrite(\n\u001b[1;32m    483\u001b[0m     df,\n\u001b[1;32m    484\u001b[0m     path_or_buf,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    491\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parquet.py:68\u001b[0m, in \u001b[0;36mget_engine\u001b[0;34m(engine)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m     66\u001b[0m             error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(err)\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to find a usable engine; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtried using: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfastparquet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA suitable version of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow or fastparquet is required for parquet \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupport.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to import the above resulted in these errors:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_msgs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     76\u001b[0m     )\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PyArrowImpl()\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "if Path(baseline_config['dataset']['val_calib_json']).exists():\n",
    "    print(\"Generando inputs para calibración sobre val_calib...\")\n",
    "    \n",
    "    coco_calib = COCO(baseline_config['dataset']['val_calib_json'])\n",
    "    calib_image_ids = sorted(coco_calib.getImgIds())\n",
    "    \n",
    "    calib_records = []\n",
    "    \n",
    "    for img_id in tqdm(calib_image_ids):\n",
    "        img_info = coco_calib.loadImgs(img_id)[0]\n",
    "        img_path = Path(baseline_config['dataset']['image_dir']) / img_info['file_name']\n",
    "        \n",
    "        if not img_path.exists():\n",
    "            continue\n",
    "        \n",
    "        image_pil = Image.open(img_path).convert('RGB')\n",
    "        img_w, img_h = image_pil.size\n",
    "        \n",
    "        image_source, image_transformed = load_image(str(img_path))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            boxes, logits, phrases = predict(\n",
    "                model=model,\n",
    "                image=image_transformed,\n",
    "                caption=TEXT_PROMPT,\n",
    "                box_threshold=0.05,\n",
    "                text_threshold=0.25,\n",
    "                device=device\n",
    "            )\n",
    "        \n",
    "        boxes_xyxy = box_ops.box_cxcywh_to_xyxy(boxes) * torch.tensor([img_w, img_h, img_w, img_h])\n",
    "        boxes_xywh = []\n",
    "        for box in boxes_xyxy:\n",
    "            x1, y1, x2, y2 = box.tolist()\n",
    "            boxes_xywh.append([x1, y1, x2 - x1, y2 - y1])\n",
    "        \n",
    "        scores = logits.tolist()\n",
    "        labels_raw = [normalize_label(p) for p in phrases]\n",
    "        category_ids = [PROMPT_TO_CAT_ID.get(lbl, -1) for lbl in labels_raw]\n",
    "        \n",
    "        valid_mask = [cid != -1 for cid in category_ids]\n",
    "        boxes_xywh = [b for b, m in zip(boxes_xywh, valid_mask) if m]\n",
    "        scores = [s for s, m in zip(scores, valid_mask) if m]\n",
    "        category_ids = [c for c, m in zip(category_ids, valid_mask) if m]\n",
    "        \n",
    "        ann_ids = coco_calib.getAnnIds(imgIds=img_id)\n",
    "        anns = coco_calib.loadAnns(ann_ids)\n",
    "        \n",
    "        for pred_box, pred_score, pred_cat in zip(boxes_xywh, scores, category_ids):\n",
    "            pred_x1, pred_y1, pred_w, pred_h = pred_box\n",
    "            pred_x2 = pred_x1 + pred_w\n",
    "            pred_y2 = pred_y1 + pred_h\n",
    "            pred_area = pred_w * pred_h\n",
    "            \n",
    "            best_iou = 0.0\n",
    "            best_match = None\n",
    "            \n",
    "            for ann in anns:\n",
    "                if ann['category_id'] != pred_cat:\n",
    "                    continue\n",
    "                \n",
    "                gt_x, gt_y, gt_w, gt_h = ann['bbox']\n",
    "                gt_x2 = gt_x + gt_w\n",
    "                gt_y2 = gt_y + gt_h\n",
    "                gt_area = gt_w * gt_h\n",
    "                \n",
    "                inter_x1 = max(pred_x1, gt_x)\n",
    "                inter_y1 = max(pred_y1, gt_y)\n",
    "                inter_x2 = min(pred_x2, gt_x2)\n",
    "                inter_y2 = min(pred_y2, gt_y2)\n",
    "                \n",
    "                inter_w = max(0, inter_x2 - inter_x1)\n",
    "                inter_h = max(0, inter_y2 - inter_y1)\n",
    "                inter_area = inter_w * inter_h\n",
    "                \n",
    "                union_area = pred_area + gt_area - inter_area\n",
    "                iou = inter_area / union_area if union_area > 0 else 0.0\n",
    "                \n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_match = ann['id']\n",
    "            \n",
    "            is_correct = best_iou >= 0.5\n",
    "            \n",
    "            calib_records.append({\n",
    "                'image_id': int(img_id),\n",
    "                'bbox': [float(b) for b in pred_box],\n",
    "                'category_id_pred': int(pred_cat),\n",
    "                'score': float(pred_score),\n",
    "                'iou': float(best_iou),\n",
    "                'is_correct': bool(is_correct),\n",
    "                'gt_ann_id': int(best_match) if best_match else -1\n",
    "            })\n",
    "    \n",
    "    # Save as CSV instead of Parquet\n",
    "    calib_df = pd.DataFrame(calib_records)\n",
    "    calib_df.to_csv(OUTPUT_DIR / 'calib_inputs.csv', index=False)\n",
    "\n",
    "    print(f\"\\nCalibration inputs generados: {len(calib_records)} detecciones\")\n",
    "    print(f\"Guardado en: {OUTPUT_DIR / 'calib_inputs.csv'}\")\n",
    "\n",
    "    class_counts = calib_df.groupby('category_id_pred').size().to_dict()\n",
    "    print(\"\\nCobertura por clase en val_calib:\")\n",
    "    for cat_id, count in sorted(class_counts.items()):\n",
    "        cat_name = CAT_ID_TO_PROMPT[cat_id]\n",
    "        correct = calib_df[(calib_df['category_id_pred'] == cat_id) & (calib_df['is_correct'])].shape[0]\n",
    "        print(f\"  {cat_name}: {count} predicciones ({correct} correctas, {correct/count*100:.1f}%)\")\n",
    "\n",
    "else:\n",
    "    print(\"val_calib.json no encontrado, saltando generación de inputs de calibración\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e0075f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calibration inputs generados: 129795 detecciones\n",
      "Guardado en: outputs/baseline/calib_inputs.csv\n",
      "\n",
      "Cobertura por clase en val_calib:\n",
      "  person: 15048 predicciones (6959 correctas, 46.2%)\n",
      "  rider: 2877 predicciones (145 correctas, 5.0%)\n",
      "  car: 46324 predicciones (39306 correctas, 84.9%)\n",
      "  truck: 8245 predicciones (2498 correctas, 30.3%)\n",
      "  bus: 3748 predicciones (598 correctas, 16.0%)\n",
      "  train: 558 predicciones (1 correctas, 0.2%)\n",
      "  motorcycle: 4306 predicciones (0 correctas, 0.0%)\n",
      "  bicycle: 1642 predicciones (323 correctas, 19.7%)\n",
      "  traffic light: 29496 predicciones (13247 correctas, 44.9%)\n",
      "  traffic sign: 17551 predicciones (12340 correctas, 70.3%)\n"
     ]
    }
   ],
   "source": [
    "calib_df = pd.DataFrame(calib_records)\n",
    "calib_df.to_csv(OUTPUT_DIR / 'calib_inputs.csv', index=False)\n",
    "\n",
    "print(f\"\\nCalibration inputs generados: {len(calib_records)} detecciones\")\n",
    "print(f\"Guardado en: {OUTPUT_DIR / 'calib_inputs.csv'}\")\n",
    "\n",
    "class_counts = calib_df.groupby('category_id_pred').size().to_dict()\n",
    "print(\"\\nCobertura por clase en val_calib:\")\n",
    "for cat_id, count in sorted(class_counts.items()):\n",
    "    cat_name = CAT_ID_TO_PROMPT[cat_id]\n",
    "    correct = calib_df[(calib_df['category_id_pred'] == cat_id) & (calib_df['is_correct'])].shape[0]\n",
    "    print(f\"  {cat_name}: {count} predicciones ({correct} correctas, {correct/count*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928758d1",
   "metadata": {},
   "source": [
    "## 13. Tabla Resumen Baseline (5.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df985908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Cargando métricas de rendimiento desde archivo...\n",
      "✓ Métricas de rendimiento cargadas: 9 valores\n",
      "\n",
      "================================================================================\n",
      "TABLA RESUMEN BASELINE\n",
      "================================================================================\n",
      "Config  Conf_Threshold  NMS_IoU      mAP     AP50     AP75      FPS    GPU_MB  Detections/Img\n",
      "                  0.05     0.65 0.170481 0.278535 0.170542 3.637273 1189.5625         11.0810\n",
      "                  0.10     0.65 0.170481 0.278535 0.170542 3.637273 1189.5625         11.0810\n",
      "                  0.15     0.65 0.170481 0.278535 0.170542 3.637273 1189.5625         11.0810\n",
      "                  0.20     0.65 0.170481 0.278535 0.170542 3.637273 1189.5625         11.0810\n",
      "                  0.25     0.65 0.170481 0.278535 0.170542 3.637273 1189.5625         11.0810\n",
      "     ⭐            0.30     0.65 0.170481 0.278535 0.170542 3.637273 1189.5625         11.0810\n",
      "                  0.35     0.65 0.154954 0.246966 0.157493 3.637273 1189.5625          7.9270\n",
      "                  0.40     0.65 0.135954 0.210295 0.141558 3.637273 1189.5625          5.6665\n",
      "                  0.50     0.65 0.090502 0.132338 0.095668 3.637273 1189.5625          2.6625\n",
      "                  0.60     0.65 0.056563 0.075882 0.060964 3.637273 1189.5625          0.8970\n",
      "                  0.75     0.65 0.014855 0.017162 0.015409 3.637273 1189.5625          0.0355\n",
      "================================================================================\n",
      "\n",
      "✓ Tabla resumen guardada en: outputs/baseline/summary_table.csv\n",
      "✓ Visualización guardada en: outputs/baseline/summary_visualization.png\n",
      "✓ Reporte detallado guardado en: outputs/baseline/summary_report.txt\n",
      "\n",
      "================================================================================\n",
      "BASELINE CONFIGURATION SUMMARY\n",
      "================================================================================\n",
      "\n",
      "MODEL CONFIGURATION\n",
      "--------------------------------------------------------------------------------\n",
      "  Confidence Threshold: 0.3\n",
      "  NMS IoU: 0.65\n",
      "  FPS: 3.64\n",
      "  GPU Memory: 1190 MB\n",
      "\n",
      "THRESHOLD SWEEP RESULTS\n",
      "--------------------------------------------------------------------------------\n",
      "Threshold    mAP      AP50     AP75     Dets/Img     Baseline  \n",
      "--------------------------------------------------------------------------------\n",
      "0.05         0.1705   0.2785   0.1705   11.08       \n",
      "0.10         0.1705   0.2785   0.1705   11.08       \n",
      "0.15         0.1705   0.2785   0.1705   11.08       \n",
      "0.20         0.1705   0.2785   0.1705   11.08       \n",
      "0.25         0.1705   0.2785   0.1705   11.08       \n",
      "0.30         0.1705   0.2785   0.1705   11.08          ⭐\n",
      "0.35         0.1550   0.2470   0.1575   7.93        \n",
      "0.40         0.1360   0.2103   0.1416   5.67        \n",
      "0.50         0.0905   0.1323   0.0957   2.66        \n",
      "0.60         0.0566   0.0759   0.0610   0.90        \n",
      "0.75         0.0149   0.0172   0.0154   0.04        \n",
      "\n",
      "================================================================================\n",
      "KEY OBSERVATIONS\n",
      "================================================================================\n",
      "  • Best mAP: 0.1705 at threshold 0.05\n",
      "  • Best AP50: 0.2785 at threshold 0.05\n",
      "  • Baseline mAP could improve by 0.0% with threshold 0.05\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar threshold_df si no existe\n",
    "if 'threshold_df' not in locals():\n",
    "    print(\"⚠️ Cargando threshold sweep desde archivo...\")\n",
    "    threshold_csv = OUTPUT_DIR / 'threshold_sweep.csv'\n",
    "    \n",
    "    if threshold_csv.exists():\n",
    "        threshold_df = pd.read_csv(threshold_csv)\n",
    "        print(f\"✓ Threshold sweep cargado: {len(threshold_df)} configuraciones\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No se encontró {threshold_csv}\\n\"\n",
    "            \"Ejecuta primero la Sección 10 (Sensibilidad a Umbrales)\"\n",
    "        )\n",
    "\n",
    "# Cargar perf_summary si no existe\n",
    "if 'perf_summary' not in locals():\n",
    "    print(\"⚠️ Cargando métricas de rendimiento desde archivo...\")\n",
    "    perf_txt = OUTPUT_DIR / 'perf.txt'\n",
    "    \n",
    "    if perf_txt.exists():\n",
    "        # Parsear perf.txt\n",
    "        perf_summary = {}\n",
    "        with open(perf_txt, 'r') as f:\n",
    "            for line in f:\n",
    "                if ':' in line and '=' not in line:\n",
    "                    key, value = line.strip().split(':', 1)\n",
    "                    try:\n",
    "                        perf_summary[key.strip()] = float(value.strip())\n",
    "                    except:\n",
    "                        pass\n",
    "        print(f\"✓ Métricas de rendimiento cargadas: {len(perf_summary)} valores\")\n",
    "    else:\n",
    "        # Valores por defecto si no existe el archivo\n",
    "        print(\"⚠️ perf.txt no encontrado, usando valores por defecto\")\n",
    "        perf_summary = {\n",
    "            'fps': 1.0,\n",
    "            'peak_gpu_memory_mb': 0,\n",
    "            'total_images': 2000\n",
    "        }\n",
    "\n",
    "# Cargar baseline_config si no existe\n",
    "if 'baseline_config' not in locals():\n",
    "    print(\"⚠️ Cargando configuración baseline...\")\n",
    "    config_yaml = CONFIG_DIR / 'baseline.yaml'\n",
    "    \n",
    "    if config_yaml.exists():\n",
    "        with open(config_yaml, 'r') as f:\n",
    "            baseline_config = yaml.safe_load(f)\n",
    "        print(\"✓ Configuración baseline cargada\")\n",
    "    else:\n",
    "        # Configuración por defecto\n",
    "        baseline_config = {\n",
    "            'inference': {\n",
    "                'conf_threshold': 0.30,\n",
    "                'nms_iou': 0.65\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Generar tabla resumen\n",
    "summary_table = []\n",
    "\n",
    "for _, row in threshold_df.iterrows():\n",
    "    conf_th = row['conf_threshold']\n",
    "    \n",
    "    is_baseline = abs(conf_th - baseline_config['inference']['conf_threshold']) < 0.01\n",
    "    marker = '⭐' if is_baseline else ''\n",
    "    \n",
    "    summary_table.append({\n",
    "        'Config': marker,\n",
    "        'Conf_Threshold': conf_th,\n",
    "        'NMS_IoU': baseline_config['inference']['nms_iou'],\n",
    "        'mAP': row['mAP'],\n",
    "        'AP50': row['AP50'],\n",
    "        'AP75': row['AP75'],\n",
    "        'FPS': perf_summary.get('fps', 1.0),\n",
    "        'GPU_MB': perf_summary.get('peak_gpu_memory_mb', 0),\n",
    "        'Detections/Img': row['num_predictions'] / perf_summary.get('total_images', 2000)\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_table)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABLA RESUMEN BASELINE\")\n",
    "print(\"=\"*80)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_df.to_csv(OUTPUT_DIR / 'summary_table.csv', index=False)\n",
    "print(f\"\\n✓ Tabla resumen guardada en: {OUTPUT_DIR / 'summary_table.csv'}\")\n",
    "\n",
    "# Generar visualización adicional\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Subplot 1: Métricas vs Threshold\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(summary_df['Conf_Threshold'], summary_df['mAP'], 'o-', label='mAP', linewidth=2, markersize=8)\n",
    "plt.plot(summary_df['Conf_Threshold'], summary_df['AP50'], 's-', label='AP50', linewidth=2, markersize=8)\n",
    "plt.plot(summary_df['Conf_Threshold'], summary_df['AP75'], '^-', label='AP75', linewidth=2, markersize=8)\n",
    "\n",
    "# Marcar baseline\n",
    "baseline_row = summary_df[summary_df['Config'] == '⭐']\n",
    "if not baseline_row.empty:\n",
    "    baseline_th = baseline_row['Conf_Threshold'].values[0]\n",
    "    plt.axvline(baseline_th, color='red', linestyle='--', linewidth=2, alpha=0.7, label='Baseline')\n",
    "\n",
    "plt.xlabel('Confidence Threshold', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Average Precision', fontsize=12, fontweight='bold')\n",
    "plt.title('Detection Metrics vs Confidence Threshold', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Trade-off Detections vs mAP\n",
    "plt.subplot(1, 2, 2)\n",
    "scatter = plt.scatter(\n",
    "    summary_df['Detections/Img'], \n",
    "    summary_df['mAP'],\n",
    "    c=summary_df['Conf_Threshold'],\n",
    "    cmap='viridis',\n",
    "    s=150,\n",
    "    alpha=0.7,\n",
    "    edgecolors='black',\n",
    "    linewidth=1.5\n",
    ")\n",
    "\n",
    "# Marcar baseline\n",
    "if not baseline_row.empty:\n",
    "    plt.scatter(\n",
    "        baseline_row['Detections/Img'].values[0],\n",
    "        baseline_row['mAP'].values[0],\n",
    "        color='red',\n",
    "        s=300,\n",
    "        marker='*',\n",
    "        edgecolors='black',\n",
    "        linewidth=2,\n",
    "        label='Baseline',\n",
    "        zorder=5\n",
    "    )\n",
    "\n",
    "plt.colorbar(scatter, label='Conf. Threshold')\n",
    "plt.xlabel('Detections per Image', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('mAP', fontsize=12, fontweight='bold')\n",
    "plt.title('Detection Density vs Performance Trade-off', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'summary_visualization.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(f\"✓ Visualización guardada en: {OUTPUT_DIR / 'summary_visualization.png'}\")\n",
    "\n",
    "# Generar reporte de texto detallado\n",
    "report_lines = []\n",
    "report_lines.append(\"=\"*80 + \"\\n\")\n",
    "report_lines.append(\"BASELINE CONFIGURATION SUMMARY\\n\")\n",
    "report_lines.append(\"=\"*80 + \"\\n\\n\")\n",
    "\n",
    "report_lines.append(\"MODEL CONFIGURATION\\n\")\n",
    "report_lines.append(\"-\"*80 + \"\\n\")\n",
    "report_lines.append(f\"  Confidence Threshold: {baseline_config['inference']['conf_threshold']}\\n\")\n",
    "report_lines.append(f\"  NMS IoU: {baseline_config['inference']['nms_iou']}\\n\")\n",
    "report_lines.append(f\"  FPS: {perf_summary.get('fps', 'N/A'):.2f}\\n\")\n",
    "report_lines.append(f\"  GPU Memory: {perf_summary.get('peak_gpu_memory_mb', 0):.0f} MB\\n\\n\")\n",
    "\n",
    "report_lines.append(\"THRESHOLD SWEEP RESULTS\\n\")\n",
    "report_lines.append(\"-\"*80 + \"\\n\")\n",
    "report_lines.append(f\"{'Threshold':<12} {'mAP':<8} {'AP50':<8} {'AP75':<8} {'Dets/Img':<12} {'Baseline':<10}\\n\")\n",
    "report_lines.append(\"-\"*80 + \"\\n\")\n",
    "\n",
    "for _, row in summary_df.iterrows():\n",
    "    marker = \"   ⭐\" if row['Config'] == '⭐' else \"\"\n",
    "    report_lines.append(\n",
    "        f\"{row['Conf_Threshold']:<12.2f} \"\n",
    "        f\"{row['mAP']:<8.4f} \"\n",
    "        f\"{row['AP50']:<8.4f} \"\n",
    "        f\"{row['AP75']:<8.4f} \"\n",
    "        f\"{row['Detections/Img']:<12.2f}\"\n",
    "        f\"{marker}\\n\"\n",
    "    )\n",
    "\n",
    "report_lines.append(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "report_lines.append(\"KEY OBSERVATIONS\\n\")\n",
    "report_lines.append(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Análisis automático\n",
    "best_map_row = summary_df.loc[summary_df['mAP'].idxmax()]\n",
    "best_ap50_row = summary_df.loc[summary_df['AP50'].idxmax()]\n",
    "\n",
    "report_lines.append(f\"  • Best mAP: {best_map_row['mAP']:.4f} at threshold {best_map_row['Conf_Threshold']:.2f}\\n\")\n",
    "report_lines.append(f\"  • Best AP50: {best_ap50_row['AP50']:.4f} at threshold {best_ap50_row['Conf_Threshold']:.2f}\\n\")\n",
    "\n",
    "if not baseline_row.empty:\n",
    "    baseline_map = baseline_row['mAP'].values[0]\n",
    "    map_diff = ((best_map_row['mAP'] - baseline_map) / baseline_map * 100) if baseline_map > 0 else 0\n",
    "    report_lines.append(f\"  • Baseline mAP could improve by {map_diff:.1f}% with threshold {best_map_row['Conf_Threshold']:.2f}\\n\")\n",
    "\n",
    "report_lines.append(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "with open(OUTPUT_DIR / 'summary_report.txt', 'w') as f:\n",
    "    f.writelines(report_lines)\n",
    "\n",
    "print(f\"✓ Reporte detallado guardado en: {OUTPUT_DIR / 'summary_report.txt'}\")\n",
    "print(\"\\n\" + \"\".join(report_lines))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a714e209",
   "metadata": {},
   "source": [
    "## 14. Análisis de Errores (3.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a2bcfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analizando errores (primeras 100 imágenes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Análisis de errores: 100%|██████████| 100/100 [00:00<00:00, 307.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ANÁLISIS DE ERRORES\n",
      "================================================================================\n",
      "  Falsos positivos (conf >= 0.5): 26\n",
      "  Falsos negativos: 988\n",
      "  Pares de confusión únicos: 11\n",
      "\n",
      "Pares de confusión más comunes:\n",
      "--------------------------------------------------------------------------------\n",
      "   1. person          ← rider          :    3 veces\n",
      "   2. truck           ← car            :    2 veces\n",
      "   3. traffic light   ← traffic sign   :    2 veces\n",
      "   4. rider           ← person         :    1 veces\n",
      "   5. person          ← truck          :    1 veces\n",
      "   6. motorcycle      ← rider          :    1 veces\n",
      "   7. car             ← truck          :    1 veces\n",
      "   8. train           ← car            :    1 veces\n",
      "   9. motorcycle      ← bicycle        :    1 veces\n",
      "  10. traffic sign    ← traffic light  :    1 veces\n",
      "\n",
      "Falsos negativos por clase:\n",
      "--------------------------------------------------------------------------------\n",
      "  person         :   31 FN\n",
      "  rider          :    2 FN\n",
      "  car            :  598 FN\n",
      "  truck          :   12 FN\n",
      "  bus            :    6 FN\n",
      "  train          :    0 FN\n",
      "  motorcycle     :    0 FN\n",
      "  bicycle        :    8 FN\n",
      "  traffic light  :  108 FN\n",
      "  traffic sign   :  223 FN\n",
      "\n",
      "Falsos positivos por clase (conf >= 0.5):\n",
      "--------------------------------------------------------------------------------\n",
      "  person         :    9 FP\n",
      "  rider          :    1 FP\n",
      "  car            :    1 FP\n",
      "  truck          :    2 FP\n",
      "  bus            :    1 FP\n",
      "  train          :    1 FP\n",
      "  motorcycle     :    3 FP\n",
      "  bicycle        :    0 FP\n",
      "  traffic light  :    6 FP\n",
      "  traffic sign   :    2 FP\n",
      "\n",
      "✓ Análisis de errores guardado en: outputs/baseline/error_analysis.json\n",
      "✓ Visualización guardada en: outputs/baseline/error_visualization.png\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cargar dependencias necesarias\n",
    "if 'predictions' not in locals():\n",
    "    print(\"⚠️ Cargando predicciones desde archivo...\")\n",
    "    preds_path = OUTPUT_DIR / 'preds_raw.json'\n",
    "    with open(preds_path, 'r') as f:\n",
    "        predictions = json.load(f)\n",
    "    print(f\"✓ {len(predictions)} predicciones cargadas\")\n",
    "\n",
    "if 'coco_val' not in locals():\n",
    "    print(\"⚠️ Cargando anotaciones COCO...\")\n",
    "    coco_val = COCO(baseline_config['dataset']['val_eval_json'])\n",
    "    print(\"✓ Anotaciones COCO cargadas\")\n",
    "\n",
    "if 'image_ids' not in locals():\n",
    "    print(\"⚠️ Obteniendo IDs de imágenes...\")\n",
    "    image_ids = sorted(coco_val.getImgIds())\n",
    "    print(f\"✓ {len(image_ids)} imágenes encontradas\")\n",
    "\n",
    "# Inicializar análisis de errores\n",
    "error_analysis = {\n",
    "    'false_positives_high_conf': [],\n",
    "    'false_negatives': [],\n",
    "    'confusion_pairs': defaultdict(int)\n",
    "}\n",
    "\n",
    "print(\"Analizando errores (primeras 100 imágenes)...\")\n",
    "\n",
    "for img_id in tqdm(image_ids[:100], desc=\"Análisis de errores\"):\n",
    "    # Obtener predicciones para esta imagen\n",
    "    img_preds = [p for p in predictions if p['image_id'] == img_id]\n",
    "    \n",
    "    # Obtener anotaciones ground truth\n",
    "    ann_ids = coco_val.getAnnIds(imgIds=img_id)\n",
    "    anns = coco_val.loadAnns(ann_ids)\n",
    "    \n",
    "    matched_gts = set()\n",
    "    \n",
    "    # Analizar cada predicción\n",
    "    for pred in img_preds:\n",
    "        pred_box = pred['bbox']\n",
    "        pred_cat = pred['category_id']\n",
    "        pred_score = pred['score']\n",
    "        \n",
    "        # Convertir bbox a coordenadas x1, y1, x2, y2\n",
    "        px1, py1, pw, ph = pred_box\n",
    "        px2 = px1 + pw\n",
    "        py2 = py1 + ph\n",
    "        p_area = pw * ph\n",
    "        \n",
    "        # Buscar mejor match con ground truth\n",
    "        best_iou = 0.0\n",
    "        best_ann = None\n",
    "        \n",
    "        for ann in anns:\n",
    "            gx, gy, gw, gh = ann['bbox']\n",
    "            gx2 = gx + gw\n",
    "            gy2 = gy + gh\n",
    "            g_area = gw * gh\n",
    "            \n",
    "            # Calcular IoU\n",
    "            ix1 = max(px1, gx)\n",
    "            iy1 = max(py1, gy)\n",
    "            ix2 = min(px2, gx2)\n",
    "            iy2 = min(py2, gy2)\n",
    "            \n",
    "            iw = max(0, ix2 - ix1)\n",
    "            ih = max(0, iy2 - iy1)\n",
    "            inter = iw * ih\n",
    "            \n",
    "            union = p_area + g_area - inter\n",
    "            iou = inter / union if union > 0 else 0.0\n",
    "            \n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_ann = ann\n",
    "        \n",
    "        # Clasificar predicción\n",
    "        if best_iou >= 0.5 and best_ann and best_ann['category_id'] == pred_cat:\n",
    "            # True Positive\n",
    "            matched_gts.add(best_ann['id'])\n",
    "        elif pred_score >= 0.5:\n",
    "            # False Positive con alta confianza\n",
    "            error_analysis['false_positives_high_conf'].append({\n",
    "                'image_id': int(img_id),\n",
    "                'pred_category': CAT_ID_TO_PROMPT[pred_cat],\n",
    "                'score': float(pred_score),\n",
    "                'iou': float(best_iou),\n",
    "                'gt_category': CAT_ID_TO_PROMPT.get(best_ann['category_id'], 'none') if best_ann else 'none'\n",
    "            })\n",
    "            \n",
    "            # Registrar confusión si hay match con otra clase\n",
    "            if best_ann and best_ann['category_id'] != pred_cat:\n",
    "                pred_name = CAT_ID_TO_PROMPT[pred_cat]\n",
    "                gt_name = CAT_ID_TO_PROMPT[best_ann['category_id']]\n",
    "                error_analysis['confusion_pairs'][(pred_name, gt_name)] += 1\n",
    "    \n",
    "    # Identificar False Negatives\n",
    "    for ann in anns:\n",
    "        if ann['id'] not in matched_gts:\n",
    "            error_analysis['false_negatives'].append({\n",
    "                'image_id': int(img_id),\n",
    "                'category': CAT_ID_TO_PROMPT[ann['category_id']],\n",
    "                'bbox': ann['bbox'],\n",
    "                'area': float(ann['bbox'][2] * ann['bbox'][3])\n",
    "            })\n",
    "\n",
    "# Resumen de errores\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"ANÁLISIS DE ERRORES\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"  Falsos positivos (conf >= 0.5): {len(error_analysis['false_positives_high_conf'])}\")\n",
    "print(f\"  Falsos negativos: {len(error_analysis['false_negatives'])}\")\n",
    "print(f\"  Pares de confusión únicos: {len(error_analysis['confusion_pairs'])}\")\n",
    "\n",
    "# Top confusiones\n",
    "print(f\"\\n{'Pares de confusión más comunes:'}\")\n",
    "print(f\"{'-'*80}\")\n",
    "confusion_sorted = sorted(error_analysis['confusion_pairs'].items(), key=lambda x: x[1], reverse=True)\n",
    "for i, ((pred, gt), count) in enumerate(confusion_sorted[:10], 1):\n",
    "    print(f\"  {i:2d}. {pred:15s} ← {gt:15s}: {count:4d} veces\")\n",
    "\n",
    "# Análisis de FN por clase\n",
    "print(f\"\\n{'Falsos negativos por clase:'}\")\n",
    "print(f\"{'-'*80}\")\n",
    "fn_by_class = defaultdict(int)\n",
    "for fn in error_analysis['false_negatives']:\n",
    "    fn_by_class[fn['category']] += 1\n",
    "\n",
    "for cat_name in BDD_COCO_CATEGORIES.values():\n",
    "    count = fn_by_class.get(cat_name, 0)\n",
    "    print(f\"  {cat_name:15s}: {count:4d} FN\")\n",
    "\n",
    "# Análisis de FP por clase\n",
    "print(f\"\\n{'Falsos positivos por clase (conf >= 0.5):'}\")\n",
    "print(f\"{'-'*80}\")\n",
    "fp_by_class = defaultdict(int)\n",
    "for fp in error_analysis['false_positives_high_conf']:\n",
    "    fp_by_class[fp['pred_category']] += 1\n",
    "\n",
    "for cat_name in BDD_COCO_CATEGORIES.values():\n",
    "    count = fp_by_class.get(cat_name, 0)\n",
    "    print(f\"  {cat_name:15s}: {count:4d} FP\")\n",
    "\n",
    "# Guardar análisis completo\n",
    "error_report = {\n",
    "    'summary': {\n",
    "        'total_false_positives': len(error_analysis['false_positives_high_conf']),\n",
    "        'total_false_negatives': len(error_analysis['false_negatives']),\n",
    "        'total_confusion_pairs': len(error_analysis['confusion_pairs']),\n",
    "        'images_analyzed': 100\n",
    "    },\n",
    "    'false_positives_by_class': dict(fp_by_class),\n",
    "    'false_negatives_by_class': dict(fn_by_class),\n",
    "    'confusion_matrix': {f\"{p}->{g}\": c for (p, g), c in confusion_sorted[:20]},\n",
    "    'sample_false_positives': error_analysis['false_positives_high_conf'][:20],\n",
    "    'sample_false_negatives': error_analysis['false_negatives'][:20]\n",
    "}\n",
    "\n",
    "with open(OUTPUT_DIR / 'error_analysis.json', 'w') as f:\n",
    "    json.dump(error_report, f, indent=2)\n",
    "\n",
    "print(f\"\\n✓ Análisis de errores guardado en: {OUTPUT_DIR / 'error_analysis.json'}\")\n",
    "\n",
    "# Generar visualización de matriz de confusión\n",
    "if len(confusion_sorted) > 0:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Subplot 1: Top confusiones\n",
    "    top_confusions = confusion_sorted[:10]\n",
    "    conf_labels = [f\"{p}→{g}\" for (p, g), _ in top_confusions]\n",
    "    conf_values = [c for _, c in top_confusions]\n",
    "    \n",
    "    ax1.barh(range(len(conf_labels)), conf_values, color='#E74C3C')\n",
    "    ax1.set_yticks(range(len(conf_labels)))\n",
    "    ax1.set_yticklabels(conf_labels, fontsize=10)\n",
    "    ax1.set_xlabel('Número de confusiones', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('Top 10 Pares de Confusión', fontsize=14, fontweight='bold')\n",
    "    ax1.grid(axis='x', alpha=0.3)\n",
    "    ax1.invert_yaxis()\n",
    "    \n",
    "    # Subplot 2: FP vs FN por clase\n",
    "    classes = list(BDD_COCO_CATEGORIES.values())\n",
    "    fp_counts = [fp_by_class.get(c, 0) for c in classes]\n",
    "    fn_counts = [fn_by_class.get(c, 0) for c in classes]\n",
    "    \n",
    "    x = np.arange(len(classes))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax2.bar(x - width/2, fp_counts, width, label='False Positives', color='#E74C3C')\n",
    "    ax2.bar(x + width/2, fn_counts, width, label='False Negatives', color='#3498DB')\n",
    "    \n",
    "    ax2.set_xlabel('Clase', fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel('Cantidad', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title('Errores por Clase (100 imágenes)', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(classes, rotation=45, ha='right')\n",
    "    ax2.legend()\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / 'error_visualization.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"✓ Visualización guardada en: {OUTPUT_DIR / 'error_visualization.png'}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a151f08",
   "metadata": {},
   "source": [
    "## 15. Resumen Final y Criterios Go/No-Go (6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae58153b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando resumen final...\n",
      "\n",
      "================================================================================\n",
      "RESUMEN FINAL BASELINE\n",
      "================================================================================\n",
      "\n",
      "Modelo: Grounding-DINO (SwinT-OGC)\n",
      "Checkpoint: groundingdino_swint_ogc.pth\n",
      "Device: cuda\n",
      "\n",
      "Métricas de Detección:\n",
      "--------------------------------------------------------------------------------\n",
      "  mAP@[.50:.95]: 0.1705\n",
      "  AP@50:         0.2785\n",
      "  AP@75:         0.1705\n",
      "  AP (small):    0.0633\n",
      "  AP (medium):   0.1821\n",
      "  AP (large):    0.3770\n",
      "\n",
      "Rendimiento:\n",
      "--------------------------------------------------------------------------------\n",
      "  Tiempo/imagen: 0.275s\n",
      "  FPS:           3.64\n",
      "  GPU memoria:   1190 MB\n",
      "  Total imgs:    2000.0\n",
      "\n",
      "Top 3 clases (por AP50):\n",
      "--------------------------------------------------------------------------------\n",
      "  1. person         : AP50=0.000  mAP=0.000\n",
      "  2. rider          : AP50=0.000  mAP=0.000\n",
      "  3. car            : AP50=0.000  mAP=0.000\n",
      "\n",
      "Artefactos Generados:\n",
      "--------------------------------------------------------------------------------\n",
      "  ✓ predictions         : preds_raw.json (3.2 MB)\n",
      "  ✓ metrics             : metrics.json (0.0 MB)\n",
      "  ✓ pr_curves           : pr_curves (10 archivos)\n",
      "  ✓ qualitative         : baseline (99 archivos)\n",
      "  ✓ performance         : perf.txt (0.0 MB)\n",
      "  ✓ calib_inputs        : calib_inputs.csv (16.0 MB)\n",
      "  ✓ threshold_sweep     : threshold_sweep.csv (0.0 MB)\n",
      "  ✓ summary_table       : summary_table.csv (0.0 MB)\n",
      "  ✓ error_analysis      : error_analysis.json (0.0 MB)\n",
      "\n",
      "Criterios Go/No-Go para Fase 3:\n",
      "--------------------------------------------------------------------------------\n",
      "  ✓ Map Reasonable                : PASS\n",
      "  ✓ Ap50 Reasonable               : PASS\n",
      "  ✓ Latency Measured              : PASS\n",
      "  ✓ Artefacts Complete            : PASS\n",
      "  ✓ Calib Inputs Generated        : PASS\n",
      "  ✓ Errors Identified             : PASS\n",
      "\n",
      "================================================================================\n",
      "✅ BASELINE COMPLETADO - LISTO PARA FASE 3 (Incertidumbre y Calibración)\n",
      "\n",
      "Próximos pasos:\n",
      "  1. Implementar métodos de incertidumbre epistémica\n",
      "  2. Aplicar calibración (Platt Scaling, Temperature Scaling, etc.)\n",
      "  3. Evaluar métricas de calibración (ECE, MCE)\n",
      "  4. Generar diagramas de confiabilidad\n",
      "================================================================================\n",
      "\n",
      "✓ Reporte final guardado en: outputs/baseline/final_report.json\n",
      "✓ Reporte de texto guardado en: outputs/baseline/final_report.txt\n",
      "✓ Visualización de resumen guardada en: outputs/baseline/final_summary_visualization.png\n",
      "\n",
      "================================================================================\n",
      "ARCHIVOS GENERADOS EN ESTA SECCIÓN:\n",
      "================================================================================\n",
      "  1. outputs/baseline/final_report.json\n",
      "  2. outputs/baseline/final_report.txt\n",
      "  3. outputs/baseline/final_summary_visualization.png\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar todas las dependencias necesarias\n",
    "print(\"Preparando resumen final...\")\n",
    "\n",
    "# 1. Cargar baseline_config\n",
    "if 'baseline_config' not in locals():\n",
    "    print(\"⚠️ Cargando configuración baseline...\")\n",
    "    config_yaml = CONFIG_DIR / 'baseline.yaml'\n",
    "    if config_yaml.exists():\n",
    "        with open(config_yaml, 'r') as f:\n",
    "            baseline_config = yaml.safe_load(f)\n",
    "        print(\"✓ Configuración cargada\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"No se encontró {config_yaml}\\nEjecuta primero la Sección 2\")\n",
    "\n",
    "# 2. Cargar metrics_coco\n",
    "if 'metrics_coco' not in locals():\n",
    "    print(\"⚠️ Cargando métricas COCO...\")\n",
    "    metrics_json = OUTPUT_DIR / 'metrics.json'\n",
    "    if metrics_json.exists():\n",
    "        with open(metrics_json, 'r') as f:\n",
    "            metrics_coco = json.load(f)\n",
    "        print(\"✓ Métricas COCO cargadas\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"No se encontró {metrics_json}\\nEjecuta primero la Sección 8\")\n",
    "\n",
    "# 3. Cargar perf_summary\n",
    "if 'perf_summary' not in locals():\n",
    "    print(\"⚠️ Cargando métricas de rendimiento...\")\n",
    "    perf_txt = OUTPUT_DIR / 'perf.txt'\n",
    "    if perf_txt.exists():\n",
    "        perf_summary = {}\n",
    "        with open(perf_txt, 'r') as f:\n",
    "            for line in f:\n",
    "                if ':' in line and '=' not in line:\n",
    "                    try:\n",
    "                        key, value = line.strip().split(':', 1)\n",
    "                        perf_summary[key.strip()] = float(value.strip())\n",
    "                    except:\n",
    "                        pass\n",
    "        print(f\"✓ Métricas de rendimiento cargadas: {len(perf_summary)} valores\")\n",
    "    else:\n",
    "        print(\"⚠️ perf.txt no encontrado, usando valores por defecto\")\n",
    "        perf_summary = {\n",
    "            'avg_time_per_image_s': 0.0,\n",
    "            'fps': 0.0,\n",
    "            'total_images': 0\n",
    "        }\n",
    "\n",
    "# 4. Cargar error_analysis\n",
    "if 'error_analysis' not in locals():\n",
    "    print(\"⚠️ Cargando análisis de errores...\")\n",
    "    error_json = OUTPUT_DIR / 'error_analysis.json'\n",
    "    if error_json.exists():\n",
    "        with open(error_json, 'r') as f:\n",
    "            error_data = json.load(f)\n",
    "        # Reconstruir estructura original\n",
    "        error_analysis = {\n",
    "            'false_positives_high_conf': error_data.get('sample_false_positives', []),\n",
    "            'false_negatives': error_data.get('sample_false_negatives', []),\n",
    "            'confusion_pairs': {}\n",
    "        }\n",
    "        print(\"✓ Análisis de errores cargado\")\n",
    "    else:\n",
    "        print(\"⚠️ error_analysis.json no encontrado, usando valores vacíos\")\n",
    "        error_analysis = {\n",
    "            'false_positives_high_conf': [],\n",
    "            'false_negatives': [],\n",
    "            'confusion_pairs': {}\n",
    "        }\n",
    "\n",
    "# 5. Definir PR_DIR si no existe\n",
    "if 'PR_DIR' not in locals():\n",
    "    PR_DIR = OUTPUT_DIR / 'pr_curves'\n",
    "\n",
    "# Construir reporte final\n",
    "final_report = {\n",
    "    'baseline_config': baseline_config,\n",
    "    'metrics': metrics_coco,\n",
    "    'performance': perf_summary,\n",
    "    'artefacts': {\n",
    "        'predictions': str(OUTPUT_DIR / 'preds_raw.json'),\n",
    "        'metrics': str(OUTPUT_DIR / 'metrics.json'),\n",
    "        'pr_curves': str(PR_DIR),\n",
    "        'qualitative': str(QUALITATIVE_DIR),\n",
    "        'performance': str(OUTPUT_DIR / 'perf.txt'),\n",
    "        'calib_inputs': str(OUTPUT_DIR / 'calib_inputs.csv'),\n",
    "        'threshold_sweep': str(OUTPUT_DIR / 'threshold_sweep.csv'),\n",
    "        'summary_table': str(OUTPUT_DIR / 'summary_table.csv'),\n",
    "        'error_analysis': str(OUTPUT_DIR / 'error_analysis.json')\n",
    "    },\n",
    "    'go_criteria': {\n",
    "        'mAP_reasonable': metrics_coco.get('mAP', 0) > 0.05,\n",
    "        'AP50_reasonable': metrics_coco.get('AP50', 0) > 0.10,\n",
    "        'latency_measured': 'avg_time_per_image_s' in perf_summary,\n",
    "        'artefacts_complete': True,\n",
    "        'calib_inputs_generated': (OUTPUT_DIR / 'calib_inputs.csv').exists(),\n",
    "        'errors_identified': len(error_analysis['false_positives_high_conf']) > 0\n",
    "    },\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "# Verificar existencia de artefactos\n",
    "artefact_status = {}\n",
    "for name, path in final_report['artefacts'].items():\n",
    "    artefact_status[name] = Path(path).exists()\n",
    "\n",
    "final_report['artefacts_status'] = artefact_status\n",
    "final_report['go_criteria']['artefacts_complete'] = all(artefact_status.values())\n",
    "\n",
    "# Imprimir resumen\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN FINAL BASELINE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nModelo: {baseline_config['model']['name']} ({baseline_config['model']['architecture']})\")\n",
    "print(f\"Checkpoint: {Path(baseline_config['model']['checkpoint']).name}\")\n",
    "print(f\"Device: {baseline_config['model']['device']}\")\n",
    "\n",
    "print(f\"\\n{'Métricas de Detección:'}\")\n",
    "print(f\"{'-'*80}\")\n",
    "print(f\"  mAP@[.50:.95]: {metrics_coco.get('mAP', 0):.4f}\")\n",
    "print(f\"  AP@50:         {metrics_coco.get('AP50', 0):.4f}\")\n",
    "print(f\"  AP@75:         {metrics_coco.get('AP75', 0):.4f}\")\n",
    "print(f\"  AP (small):    {metrics_coco.get('AP_small', 0):.4f}\")\n",
    "print(f\"  AP (medium):   {metrics_coco.get('AP_medium', 0):.4f}\")\n",
    "print(f\"  AP (large):    {metrics_coco.get('AP_large', 0):.4f}\")\n",
    "\n",
    "print(f\"\\n{'Rendimiento:'}\")\n",
    "print(f\"{'-'*80}\")\n",
    "print(f\"  Tiempo/imagen: {perf_summary.get('avg_time_per_image_s', 0):.3f}s\")\n",
    "print(f\"  FPS:           {perf_summary.get('fps', 0):.2f}\")\n",
    "if 'peak_gpu_memory_mb' in perf_summary:\n",
    "    print(f\"  GPU memoria:   {perf_summary['peak_gpu_memory_mb']:.0f} MB\")\n",
    "print(f\"  Total imgs:    {perf_summary.get('total_images', 0)}\")\n",
    "\n",
    "print(f\"\\n{'Top 3 clases (por AP50):'}\")\n",
    "print(f\"{'-'*80}\")\n",
    "if 'per_class' in metrics_coco:\n",
    "    per_class_sorted = sorted(\n",
    "        metrics_coco['per_class'].items(),\n",
    "        key=lambda x: x[1].get('AP50', 0),\n",
    "        reverse=True\n",
    "    )\n",
    "    for i, (cat_name, metrics) in enumerate(per_class_sorted[:3], 1):\n",
    "        print(f\"  {i}. {cat_name:15s}: AP50={metrics.get('AP50', 0):.3f}  mAP={metrics.get('mAP', 0):.3f}\")\n",
    "\n",
    "print(f\"\\n{'Artefactos Generados:'}\")\n",
    "print(f\"{'-'*80}\")\n",
    "for name, path in final_report['artefacts'].items():\n",
    "    exists = artefact_status[name]\n",
    "    status = \"✓\" if exists else \"✗\"\n",
    "    file_size = \"\"\n",
    "    if exists:\n",
    "        path_obj = Path(path)\n",
    "        if path_obj.is_file():\n",
    "            size_mb = path_obj.stat().st_size / (1024 * 1024)\n",
    "            file_size = f\" ({size_mb:.1f} MB)\"\n",
    "        elif path_obj.is_dir():\n",
    "            num_files = len(list(path_obj.glob('*')))\n",
    "            file_size = f\" ({num_files} archivos)\"\n",
    "    print(f\"  {status} {name:20s}: {Path(path).name}{file_size}\")\n",
    "\n",
    "print(f\"\\n{'Criterios Go/No-Go para Fase 3:'}\")\n",
    "print(f\"{'-'*80}\")\n",
    "all_pass = all(final_report['go_criteria'].values())\n",
    "for criterion, passed in final_report['go_criteria'].items():\n",
    "    status = \"✓\" if passed else \"✗\"\n",
    "    criterion_label = criterion.replace('_', ' ').title()\n",
    "    print(f\"  {status} {criterion_label:30s}: {'PASS' if passed else 'FAIL'}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "if all_pass:\n",
    "    print(\"✅ BASELINE COMPLETADO - LISTO PARA FASE 3 (Incertidumbre y Calibración)\")\n",
    "    print(\"\\nPróximos pasos:\")\n",
    "    print(\"  1. Implementar métodos de incertidumbre epistémica\")\n",
    "    print(\"  2. Aplicar calibración (Platt Scaling, Temperature Scaling, etc.)\")\n",
    "    print(\"  3. Evaluar métricas de calibración (ECE, MCE)\")\n",
    "    print(\"  4. Generar diagramas de confiabilidad\")\n",
    "else:\n",
    "    print(\"⚠️  BASELINE INCOMPLETO - Revisar criterios fallidos\")\n",
    "    failed_criteria = [k for k, v in final_report['go_criteria'].items() if not v]\n",
    "    print(f\"\\nCriterios fallidos: {', '.join(failed_criteria)}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Guardar reporte final\n",
    "with open(OUTPUT_DIR / 'final_report.json', 'w') as f:\n",
    "    json.dump(final_report, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\n✓ Reporte final guardado en: {OUTPUT_DIR / 'final_report.json'}\")\n",
    "\n",
    "# Generar reporte de texto legible\n",
    "report_lines = []\n",
    "report_lines.append(\"=\"*80 + \"\\n\")\n",
    "report_lines.append(\"BASELINE EVALUATION REPORT\\n\")\n",
    "report_lines.append(\"=\"*80 + \"\\n\\n\")\n",
    "report_lines.append(f\"Generated: {final_report['timestamp']}\\n\\n\")\n",
    "\n",
    "report_lines.append(\"MODEL CONFIGURATION\\n\")\n",
    "report_lines.append(\"-\"*80 + \"\\n\")\n",
    "report_lines.append(f\"  Name:           {baseline_config['model']['name']}\\n\")\n",
    "report_lines.append(f\"  Architecture:   {baseline_config['model']['architecture']}\\n\")\n",
    "report_lines.append(f\"  Checkpoint:     {Path(baseline_config['model']['checkpoint']).name}\\n\")\n",
    "report_lines.append(f\"  Device:         {baseline_config['model']['device']}\\n\\n\")\n",
    "\n",
    "report_lines.append(\"DETECTION METRICS\\n\")\n",
    "report_lines.append(\"-\"*80 + \"\\n\")\n",
    "for metric_name in ['mAP', 'AP50', 'AP75', 'AP_small', 'AP_medium', 'AP_large']:\n",
    "    value = metrics_coco.get(metric_name, 0)\n",
    "    report_lines.append(f\"  {metric_name:15s}: {value:.4f}\\n\")\n",
    "\n",
    "report_lines.append(\"\\nPERFORMANCE METRICS\\n\")\n",
    "report_lines.append(\"-\"*80 + \"\\n\")\n",
    "for metric_name, value in perf_summary.items():\n",
    "    report_lines.append(f\"  {metric_name:25s}: {value:.4f}\\n\")\n",
    "\n",
    "report_lines.append(\"\\nPER-CLASS METRICS (sorted by AP50)\\n\")\n",
    "report_lines.append(\"-\"*80 + \"\\n\")\n",
    "if 'per_class' in metrics_coco:\n",
    "    per_class_sorted = sorted(\n",
    "        metrics_coco['per_class'].items(),\n",
    "        key=lambda x: x[1].get('AP50', 0),\n",
    "        reverse=True\n",
    "    )\n",
    "    for cat_name, metrics in per_class_sorted:\n",
    "        report_lines.append(\n",
    "            f\"  {cat_name:15s}: mAP={metrics.get('mAP', 0):.3f}  \"\n",
    "            f\"AP50={metrics.get('AP50', 0):.3f}  \"\n",
    "            f\"AP75={metrics.get('AP75', 0):.3f}\\n\"\n",
    "        )\n",
    "\n",
    "report_lines.append(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "report_lines.append(\"GO/NO-GO DECISION: \" + (\"✅ GO\" if all_pass else \"❌ NO-GO\") + \"\\n\")\n",
    "report_lines.append(\"=\"*80 + \"\\n\")\n",
    "\n",
    "with open(OUTPUT_DIR / 'final_report.txt', 'w') as f:\n",
    "    f.writelines(report_lines)\n",
    "\n",
    "print(f\"✓ Reporte de texto guardado en: {OUTPUT_DIR / 'final_report.txt'}\")\n",
    "\n",
    "# Generar visualización de resumen\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Métricas principales\n",
    "ax1 = axes[0, 0]\n",
    "metrics_main = ['mAP', 'AP50', 'AP75']\n",
    "values_main = [metrics_coco.get(m, 0) for m in metrics_main]\n",
    "colors_main = ['#3498DB', '#2ECC71', '#E74C3C']\n",
    "bars = ax1.bar(metrics_main, values_main, color=colors_main, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "ax1.set_ylabel('Average Precision', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Main Detection Metrics', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylim([0, 1])\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "for bar, val in zip(bars, values_main):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "             f'{val:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. Métricas por tamaño\n",
    "ax2 = axes[0, 1]\n",
    "metrics_size = ['AP_small', 'AP_medium', 'AP_large']\n",
    "values_size = [metrics_coco.get(m, 0) for m in metrics_size]\n",
    "labels_size = ['Small', 'Medium', 'Large']\n",
    "colors_size = ['#F39C12', '#9B59B6', '#1ABC9C']\n",
    "bars = ax2.bar(labels_size, values_size, color=colors_size, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "ax2.set_ylabel('Average Precision', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('AP by Object Size', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylim([0, 1])\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "for bar, val in zip(bars, values_size):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "             f'{val:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 3. Top/Bottom clases por AP50\n",
    "ax3 = axes[1, 0]\n",
    "if 'per_class' in metrics_coco:\n",
    "    per_class_sorted = sorted(\n",
    "        metrics_coco['per_class'].items(),\n",
    "        key=lambda x: x[1].get('AP50', 0)\n",
    "    )\n",
    "    # Top 5 y bottom 5\n",
    "    classes_display = per_class_sorted[:3] + per_class_sorted[-3:]\n",
    "    class_names = [c[0] for c in classes_display]\n",
    "    class_ap50 = [c[1].get('AP50', 0) for c in classes_display]\n",
    "    colors_classes = ['#E74C3C']*3 + ['#2ECC71']*3\n",
    "    \n",
    "    y_pos = np.arange(len(class_names))\n",
    "    ax3.barh(y_pos, class_ap50, color=colors_classes, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "    ax3.set_yticks(y_pos)\n",
    "    ax3.set_yticklabels(class_names)\n",
    "    ax3.set_xlabel('AP50', fontsize=12, fontweight='bold')\n",
    "    ax3.set_title('Bottom 3 vs Top 3 Classes (by AP50)', fontsize=14, fontweight='bold')\n",
    "    ax3.set_xlim([0, 1])\n",
    "    ax3.grid(axis='x', alpha=0.3)\n",
    "    ax3.invert_yaxis()\n",
    "\n",
    "# 4. Estado de artefactos\n",
    "ax4 = axes[1, 1]\n",
    "artefact_names = list(artefact_status.keys())\n",
    "artefact_exists = [1 if v else 0 for v in artefact_status.values()]\n",
    "colors_artefacts = ['#2ECC71' if e else '#E74C3C' for e in artefact_exists]\n",
    "\n",
    "y_pos = np.arange(len(artefact_names))\n",
    "ax4.barh(y_pos, artefact_exists, color=colors_artefacts, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "ax4.set_yticks(y_pos)\n",
    "ax4.set_yticklabels([n.replace('_', ' ').title() for n in artefact_names], fontsize=9)\n",
    "ax4.set_xlabel('Status', fontsize=12, fontweight='bold')\n",
    "ax4.set_title('Artefact Generation Status', fontsize=14, fontweight='bold')\n",
    "ax4.set_xlim([0, 1.2])\n",
    "ax4.set_xticks([0, 1])\n",
    "ax4.set_xticklabels(['Missing', 'Generated'])\n",
    "ax4.grid(axis='x', alpha=0.3)\n",
    "ax4.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'final_summary_visualization.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(f\"✓ Visualización de resumen guardada en: {OUTPUT_DIR / 'final_summary_visualization.png'}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"ARCHIVOS GENERADOS EN ESTA SECCIÓN:\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"  1. {OUTPUT_DIR / 'final_report.json'}\")\n",
    "print(f\"  2. {OUTPUT_DIR / 'final_report.txt'}\")\n",
    "print(f\"  3. {OUTPUT_DIR / 'final_summary_visualization.png'}\")\n",
    "print(f\"{'='*80}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd3f09f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
