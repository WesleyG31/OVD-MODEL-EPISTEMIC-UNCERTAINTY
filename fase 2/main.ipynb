{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "041e1452",
   "metadata": {},
   "source": [
    "# Baseline OVD - BDD100K Detection Pipeline\n",
    "\n",
    "Pipeline completo para establecer el baseline de detección con Grounding-DINO en BDD100K.\n",
    "\n",
    "**Fases:**\n",
    "1. Configuración del modelo y dataset\n",
    "2. Inferencia sobre val_eval\n",
    "3. Evaluación de métricas\n",
    "4. Preparación para calibración\n",
    "5. Generación de artefactos\n",
    "\n",
    "**Hardware requerido:** GPU con CUDA (mínimo 8GB VRAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41b56ec",
   "metadata": {},
   "source": [
    "## 1. Imports y Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62eb21cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from seaborn) (2.2.6)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from seaborn) (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f367695a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.9.0-cp312-cp312-win_amd64.whl.metadata (30 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.24.0-cp312-cp312-win_amd64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from torch) (4.15.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from torchvision) (12.0.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Using cached torch-2.9.0-cp312-cp312-win_amd64.whl (109.3 MB)\n",
      "Using cached torchvision-0.24.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, torch, torchvision\n",
      "\n",
      "   ---------------------------------------- 0/4 [mpmath]\n",
      "   ---------------------------------------- 0/4 [mpmath]\n",
      "   ---------------------------------------- 0/4 [mpmath]\n",
      "   ---------------------------------------- 0/4 [mpmath]\n",
      "   ---------------------------------------- 0/4 [mpmath]\n",
      "   ---------------------------------------- 0/4 [mpmath]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ---------------------------------------- 4/4 [torchvision]\n",
      "\n",
      "Successfully installed mpmath-1.3.0 sympy-1.14.0 torch-2.9.0 torchvision-0.24.0\n",
      "Requirement already satisfied: pycocotools in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (2.0.10)\n",
      "Requirement already satisfied: numpy in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pycocotools) (2.2.6)\n",
      "Requirement already satisfied: pycocotools in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (2.0.10)\n",
      "Requirement already satisfied: numpy in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pycocotools) (2.2.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (3.10.7)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Requirement already satisfied: pandas in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (3.10.7)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Requirement already satisfied: Pillow in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (12.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (6.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: Pillow in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (12.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (6.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "#!pip install torch torchvision\n",
    "#!pip install pycocotools\n",
    "#!pip install pandas matplotlib seaborn\n",
    "#!pip install Pillow tqdm pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecdd564",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All required packages are installed.\")\n",
    "#pip install ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cf281a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.3.3 tzdata-2025.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeb31b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import yaml\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a8de9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundingDINO en: /opt/conda/lib/python3.10/site-packages/groundingdino-0.1.0-py3.10-linux-x86_64.egg/groundingdino\n"
     ]
    }
   ],
   "source": [
    "import groundingdino, os\n",
    "print(\"GroundingDINO en:\", os.path.dirname(groundingdino.__file__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac8dd91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /opt/conda/lib/python310.zip\n",
      "1 /opt/conda/lib/python3.10\n",
      "2 /opt/conda/lib/python3.10/lib-dynload\n",
      "3 \n",
      "4 /opt/conda/lib/python3.10/site-packages\n",
      "5 /opt/conda/lib/python3.10/site-packages/groundingdino-0.1.0-py3.10-linux-x86_64.egg\n",
      "6 /opt/program/GroundingDINO\n"
     ]
    }
   ],
   "source": [
    "for i, p in enumerate(sys.path):\n",
    "    print(i, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f8e663f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "#sys.path.append('../installing_dino/GroundingDINO')\n",
    "from groundingdino.util.inference import load_model, load_image, predict\n",
    "from groundingdino.util import box_ops\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f22fbfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "PyTorch: 2.3.1+cu121\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "CUDA version: 12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43576c1a",
   "metadata": {},
   "source": [
    "## 2. Configuración Baseline (1.1, 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9752ae9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración baseline:\n",
      "dataset:\n",
      "  image_dir: ../data/bdd100k/bdd100k/bdd100k/images/100k/val\n",
      "  val_calib_json: ../data/bdd100k_coco/val_calib.json\n",
      "  val_eval_json: ../data/bdd100k_coco/val_eval.json\n",
      "inference:\n",
      "  batch_size: 1\n",
      "  conf_threshold: 0.3\n",
      "  max_detections: 300\n",
      "  nms_iou: 0.65\n",
      "model:\n",
      "  architecture: SwinT-OGC\n",
      "  checkpoint: /opt/program/GroundingDINO/weights/groundingdino_swint_ogc.pth\n",
      "  config: /opt/program/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\n",
      "  device: cuda\n",
      "  input_size:\n",
      "  - 800\n",
      "  - 1333\n",
      "  name: Grounding-DINO\n",
      "prompts_file: ../data/prompts/bdd100k.txt\n",
      "seed: 42\n",
      "timestamp: '2025-11-10T22:15:34.737010'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path('../data')\n",
    "OUTPUT_DIR = Path('./outputs/baseline')\n",
    "QUALITATIVE_DIR = Path('./outputs/qualitative/baseline')\n",
    "CONFIG_DIR = Path('./configs')\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "QUALITATIVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CONFIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "baseline_config = {\n",
    "    'model': {\n",
    "        'name': 'Grounding-DINO',\n",
    "        'checkpoint': '/opt/program/GroundingDINO/weights/groundingdino_swint_ogc.pth',\n",
    "        'config': '/opt/program/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py',\n",
    "        'architecture': 'SwinT-OGC',\n",
    "        'input_size': [800, 1333],\n",
    "        'device': str(device)\n",
    "    },\n",
    "    'dataset': {\n",
    "        'image_dir': str(BASE_DIR / 'bdd100k/bdd100k/bdd100k/images/100k/val'),\n",
    "        'val_eval_json': str(BASE_DIR / 'bdd100k_coco/val_eval.json'),\n",
    "        'val_calib_json': str(BASE_DIR / 'bdd100k_coco/val_calib.json')\n",
    "    },\n",
    "    'inference': {\n",
    "        'conf_threshold': 0.30,\n",
    "        'nms_iou': 0.65,\n",
    "        'batch_size': 1,\n",
    "        'max_detections': 300\n",
    "    },\n",
    "    'prompts_file': str(BASE_DIR / 'prompts/bdd100k.txt'),\n",
    "    'seed': 42,\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "with open(CONFIG_DIR / 'baseline.yaml', 'w') as f:\n",
    "    yaml.dump(baseline_config, f, default_flow_style=False)\n",
    "\n",
    "print(\"Configuración baseline:\")\n",
    "print(yaml.dump(baseline_config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8381fa37",
   "metadata": {},
   "source": [
    "## 3. Definición del Vocabulario (1.3, 1.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d813d7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases BDD100K COCO: 10\n",
      "Text prompt para Grounding-DINO:\n",
      "person. rider. car. truck. bus. train. motorcycle. bicycle. traffic light. traffic sign.\n",
      "\n",
      "Mapeo guardado en: ../data/prompts/bdd100k.txt\n"
     ]
    }
   ],
   "source": [
    "BDD_COCO_CATEGORIES = {\n",
    "    1: 'person',\n",
    "    2: 'rider',\n",
    "    3: 'car',\n",
    "    4: 'truck',\n",
    "    5: 'bus',\n",
    "    6: 'train',\n",
    "    7: 'motorcycle',\n",
    "    8: 'bicycle',\n",
    "    9: 'traffic light',\n",
    "    10: 'traffic sign'\n",
    "}\n",
    "\n",
    "PROMPTS = [\n",
    "    'person',\n",
    "    'rider',\n",
    "    'car',\n",
    "    'truck',\n",
    "    'bus',\n",
    "    'train',\n",
    "    'motorcycle',\n",
    "    'bicycle',\n",
    "    'traffic light',\n",
    "    'traffic sign'\n",
    "]\n",
    "\n",
    "PROMPT_SYNONYMS = {\n",
    "    'bike': 'bicycle',\n",
    "    'motorbike': 'motorcycle',\n",
    "    'motor': 'motorcycle',\n",
    "    'stop sign': 'traffic sign',\n",
    "    'red light': 'traffic light',\n",
    "    'signal': 'traffic light',\n",
    "    'pedestrian': 'person',\n",
    "    'vehicle': 'car',\n",
    "    'bicyclist': 'rider'\n",
    "}\n",
    "\n",
    "CAT_ID_TO_PROMPT = {cat_id: name for cat_id, name in BDD_COCO_CATEGORIES.items()}\n",
    "PROMPT_TO_CAT_ID = {name: cat_id for cat_id, name in BDD_COCO_CATEGORIES.items()}\n",
    "PROMPT_IDX_TO_CAT_ID = {i: i+1 for i in range(len(PROMPTS))}\n",
    "\n",
    "PROMPTS_DIR = BASE_DIR / 'prompts'\n",
    "PROMPTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(PROMPTS_DIR / 'bdd100k.txt', 'w') as f:\n",
    "    for prompt in PROMPTS:\n",
    "        f.write(f\"{prompt}\\n\")\n",
    "\n",
    "TEXT_PROMPT = '. '.join(PROMPTS) + '.'\n",
    "\n",
    "print(f\"Clases BDD100K COCO: {len(BDD_COCO_CATEGORIES)}\")\n",
    "print(f\"Text prompt para Grounding-DINO:\\n{TEXT_PROMPT}\")\n",
    "print(f\"\\nMapeo guardado en: {PROMPTS_DIR / 'bdd100k.txt'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8026fd3d",
   "metadata": {},
   "source": [
    "## 4. Carga del Modelo Grounding-DINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "858b6e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando Grounding-DINO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado exitosamente\n"
     ]
    }
   ],
   "source": [
    "print(\"Cargando Grounding-DINO...\")\n",
    "model = load_model(baseline_config['model']['config'],baseline_config['model']['checkpoint'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(\"Modelo cargado exitosamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8aa772fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primer parámetro (transformer.level_embed) en: cuda:0\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Primer parámetro ({name}) en:\", param.device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf331b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ El modelo está en GPU (CUDA)\n"
     ]
    }
   ],
   "source": [
    "if next(model.parameters()).is_cuda:\n",
    "    print(\"✅ El modelo está en GPU (CUDA)\")\n",
    "else:\n",
    "    print(\"⚠️ El modelo está en CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78bc72d",
   "metadata": {},
   "source": [
    "## 5. Funciones de Post-procesamiento (2.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c474d06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funciones de post-procesamiento definidas\n"
     ]
    }
   ],
   "source": [
    "def normalize_label(label):\n",
    "    label_lower = label.lower().strip()\n",
    "    if label_lower in PROMPT_SYNONYMS:\n",
    "        return PROMPT_SYNONYMS[label_lower]\n",
    "    for canonical in PROMPTS:\n",
    "        if canonical in label_lower:\n",
    "            return canonical\n",
    "    return label_lower\n",
    "\n",
    "def cxcywh_to_xywh(bbox):\n",
    "    cx, cy, w, h = bbox\n",
    "    x = cx - w / 2\n",
    "    y = cy - h / 2\n",
    "    return [x, y, w, h]\n",
    "\n",
    "def clip_bbox(bbox, img_w, img_h):\n",
    "    x, y, w, h = bbox\n",
    "    x = max(0, min(x, img_w))\n",
    "    y = max(0, min(y, img_h))\n",
    "    w = max(0, min(w, img_w - x))\n",
    "    h = max(0, min(h, img_h - y))\n",
    "    return [x, y, w, h]\n",
    "\n",
    "def apply_nms(boxes, scores, labels, iou_threshold=0.65):\n",
    "    if len(boxes) == 0:\n",
    "        return boxes, scores, labels\n",
    "    \n",
    "    keep_indices = []\n",
    "    boxes_tensor = torch.tensor(boxes)\n",
    "    scores_tensor = torch.tensor(scores)\n",
    "    labels_tensor = torch.tensor(labels)\n",
    "    \n",
    "    for label_id in torch.unique(labels_tensor):\n",
    "        mask = labels_tensor == label_id\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        \n",
    "        class_boxes = boxes_tensor[mask]\n",
    "        class_scores = scores_tensor[mask]\n",
    "        class_indices = torch.where(mask)[0]\n",
    "        \n",
    "        x1 = class_boxes[:, 0]\n",
    "        y1 = class_boxes[:, 1]\n",
    "        x2 = class_boxes[:, 0] + class_boxes[:, 2]\n",
    "        y2 = class_boxes[:, 1] + class_boxes[:, 3]\n",
    "        areas = class_boxes[:, 2] * class_boxes[:, 3]\n",
    "        \n",
    "        order = class_scores.argsort(descending=True)\n",
    "        \n",
    "        keep = []\n",
    "        while order.numel() > 0:\n",
    "            if order.numel() == 1:\n",
    "                keep.append(order.item())\n",
    "                break\n",
    "            \n",
    "            i = order[0].item()\n",
    "            keep.append(i)\n",
    "            \n",
    "            xx1 = torch.maximum(x1[i], x1[order[1:]])\n",
    "            yy1 = torch.maximum(y1[i], y1[order[1:]])\n",
    "            xx2 = torch.minimum(x2[i], x2[order[1:]])\n",
    "            yy2 = torch.minimum(y2[i], y2[order[1:]])\n",
    "            \n",
    "            w = torch.maximum(torch.tensor(0.0), xx2 - xx1)\n",
    "            h = torch.maximum(torch.tensor(0.0), yy2 - yy1)\n",
    "            inter = w * h\n",
    "            \n",
    "            iou = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "            \n",
    "            mask_keep = iou <= iou_threshold\n",
    "            order = order[1:][mask_keep]\n",
    "        \n",
    "        keep_indices.extend(class_indices[keep].tolist())\n",
    "    \n",
    "    keep_indices = sorted(keep_indices)\n",
    "    return (\n",
    "        [boxes[i] for i in keep_indices],\n",
    "        [scores[i] for i in keep_indices],\n",
    "        [labels[i] for i in keep_indices]\n",
    "    )\n",
    "\n",
    "print(\"Funciones de post-procesamiento definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e247a626",
   "metadata": {},
   "source": [
    "## 6. Inferencia sobre val_eval (2.1, 2.3, 2.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6569e391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "Iniciando inferencia sobre 2000 imágenes de val_eval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "100%|██████████| 2000/2000 [12:05<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inferencia completada!\n",
      "Total predicciones: 22162\n",
      "Predicciones guardadas en: outputs/baseline/preds_raw.json\n",
      "Tiempo promedio por imagen: 0.275s\n",
      "FPS: 3.64\n",
      "Detecciones promedio por imagen: 11.1\n"
     ]
    }
   ],
   "source": [
    "coco_val = COCO(baseline_config['dataset']['val_eval_json'])\n",
    "image_ids = sorted(coco_val.getImgIds())\n",
    "\n",
    "predictions = []\n",
    "perf_metrics = {\n",
    "    'times': [],\n",
    "    'num_detections': [],\n",
    "    'gpu_memory_mb': []\n",
    "}\n",
    "\n",
    "print(f\"Iniciando inferencia sobre {len(image_ids)} imágenes de val_eval...\")\n",
    "\n",
    "sample_images = []\n",
    "sample_interval = len(image_ids) // 50 if len(image_ids) > 50 else 1\n",
    "\n",
    "for idx, img_id in enumerate(tqdm(image_ids)):\n",
    "    img_info = coco_val.loadImgs(img_id)[0]\n",
    "    img_path = Path(baseline_config['dataset']['image_dir']) / img_info['file_name']\n",
    "    \n",
    "    if not img_path.exists():\n",
    "        continue\n",
    "    \n",
    "    image_pil = Image.open(img_path).convert('RGB')\n",
    "    img_w, img_h = image_pil.size\n",
    "    \n",
    "    image_source, image_transformed = load_image(str(img_path))\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        boxes, logits, phrases = predict(\n",
    "            model=model,\n",
    "            image=image_transformed,\n",
    "            caption=TEXT_PROMPT,\n",
    "            box_threshold=baseline_config['inference']['conf_threshold'],\n",
    "            text_threshold=0.25,\n",
    "            device=device\n",
    "        )\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    elapsed = time.time() - start_time\n",
    "    perf_metrics['times'].append(elapsed)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        perf_metrics['gpu_memory_mb'].append(torch.cuda.max_memory_allocated() / 1024 / 1024)\n",
    "    \n",
    "    boxes_xyxy = box_ops.box_cxcywh_to_xyxy(boxes) * torch.tensor([img_w, img_h, img_w, img_h])\n",
    "    boxes_xywh = []\n",
    "    for box in boxes_xyxy:\n",
    "        x1, y1, x2, y2 = box.tolist()\n",
    "        boxes_xywh.append([x1, y1, x2 - x1, y2 - y1])\n",
    "    \n",
    "    scores = logits.tolist()\n",
    "    labels_raw = [normalize_label(p) for p in phrases]\n",
    "    category_ids = [PROMPT_TO_CAT_ID.get(lbl, -1) for lbl in labels_raw]\n",
    "    \n",
    "    valid_mask = [cid != -1 for cid in category_ids]\n",
    "    boxes_xywh = [b for b, m in zip(boxes_xywh, valid_mask) if m]\n",
    "    scores = [s for s, m in zip(scores, valid_mask) if m]\n",
    "    category_ids = [c for c, m in zip(category_ids, valid_mask) if m]\n",
    "    \n",
    "    if len(boxes_xywh) > 0:\n",
    "        boxes_xywh, scores, category_ids = apply_nms(\n",
    "            boxes_xywh, scores, category_ids, \n",
    "            iou_threshold=baseline_config['inference']['nms_iou']\n",
    "        )\n",
    "    \n",
    "    if len(boxes_xywh) > baseline_config['inference']['max_detections']:\n",
    "        sorted_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)\n",
    "        sorted_indices = sorted_indices[:baseline_config['inference']['max_detections']]\n",
    "        boxes_xywh = [boxes_xywh[i] for i in sorted_indices]\n",
    "        scores = [scores[i] for i in sorted_indices]\n",
    "        category_ids = [category_ids[i] for i in sorted_indices]\n",
    "    \n",
    "    for box, score, cat_id in zip(boxes_xywh, scores, category_ids):\n",
    "        box_clipped = clip_bbox(box, img_w, img_h)\n",
    "        predictions.append({\n",
    "            'image_id': int(img_id),\n",
    "            'category_id': int(cat_id),\n",
    "            'bbox': [float(b) for b in box_clipped],\n",
    "            'score': float(score)\n",
    "        })\n",
    "    \n",
    "    perf_metrics['num_detections'].append(len(boxes_xywh))\n",
    "    \n",
    "    if idx % sample_interval == 0 and len(sample_images) < 50:\n",
    "        sample_images.append({\n",
    "            'image_id': img_id,\n",
    "            'image_path': str(img_path),\n",
    "            'num_dets': len(boxes_xywh)\n",
    "        })\n",
    "\n",
    "preds_path = OUTPUT_DIR / 'preds_raw.json'\n",
    "with open(preds_path, 'w') as f:\n",
    "    json.dump(predictions, f)\n",
    "\n",
    "print(f\"\\nInferencia completada!\")\n",
    "print(f\"Total predicciones: {len(predictions)}\")\n",
    "print(f\"Predicciones guardadas en: {preds_path}\")\n",
    "print(f\"Tiempo promedio por imagen: {np.mean(perf_metrics['times']):.3f}s\")\n",
    "print(f\"FPS: {1.0 / np.mean(perf_metrics['times']):.2f}\")\n",
    "print(f\"Detecciones promedio por imagen: {np.mean(perf_metrics['num_detections']):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2748a226",
   "metadata": {},
   "source": [
    "## 7. Guardado de Métricas de Rendimiento (2.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bbd5ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Métricas de rendimiento guardadas en: outputs/baseline/perf.txt\n"
     ]
    }
   ],
   "source": [
    "perf_summary = {\n",
    "    'avg_time_per_image_s': float(np.mean(perf_metrics['times'])),\n",
    "    'std_time_per_image_s': float(np.std(perf_metrics['times'])),\n",
    "    'fps': float(1.0 / np.mean(perf_metrics['times'])),\n",
    "    'avg_detections_per_image': float(np.mean(perf_metrics['num_detections'])),\n",
    "    'std_detections_per_image': float(np.std(perf_metrics['num_detections'])),\n",
    "    'total_predictions': len(predictions),\n",
    "    'total_images': len(image_ids)\n",
    "}\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    perf_summary['avg_gpu_memory_mb'] = float(np.mean(perf_metrics['gpu_memory_mb']))\n",
    "    perf_summary['peak_gpu_memory_mb'] = float(np.max(perf_metrics['gpu_memory_mb']))\n",
    "\n",
    "with open(OUTPUT_DIR / 'perf.txt', 'w') as f:\n",
    "    f.write(\"=\" * 60 + \"\\n\")\n",
    "    f.write(\"BASELINE PERFORMANCE METRICS\\n\")\n",
    "    f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "    for key, value in perf_summary.items():\n",
    "        f.write(f\"{key}: {value}\\n\")\n",
    "    f.write(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "\n",
    "print(\"\\nMétricas de rendimiento guardadas en:\", OUTPUT_DIR / 'perf.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b353ee",
   "metadata": {},
   "source": [
    "## 8. Evaluación COCO (3.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbcbd3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecutando evaluación COCO...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.34s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.52s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.170\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.279\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.171\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.063\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.377\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.284\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.107\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.272\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.540\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.30s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.06s).\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 32\u001b[0m\n\u001b[1;32m     28\u001b[0m     coco_eval_class\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[1;32m     29\u001b[0m     coco_eval_class\u001b[38;5;241m.\u001b[39maccumulate()\n\u001b[1;32m     31\u001b[0m     per_class_metrics[cat_name] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m---> 32\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmAP\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(coco_eval_class\u001b[38;5;241m.\u001b[39mstats[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcoco_eval_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstats\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAP50\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(coco_eval_class\u001b[38;5;241m.\u001b[39mstats[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m coco_eval_class\u001b[38;5;241m.\u001b[39mstats[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAP75\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(coco_eval_class\u001b[38;5;241m.\u001b[39mstats[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m coco_eval_class\u001b[38;5;241m.\u001b[39mstats[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     35\u001b[0m     }\n\u001b[1;32m     37\u001b[0m metrics_coco[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mper_class\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m per_class_metrics\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(OUTPUT_DIR \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(\"Ejecutando evaluación COCO...\")\n",
    "\n",
    "coco_dt = coco_val.loadRes(str(preds_path))\n",
    "coco_eval = COCOeval(coco_val, coco_dt, 'bbox')\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()\n",
    "\n",
    "metrics_coco = {\n",
    "    'mAP': float(coco_eval.stats[0]),\n",
    "    'AP50': float(coco_eval.stats[1]),\n",
    "    'AP75': float(coco_eval.stats[2]),\n",
    "    'AP_small': float(coco_eval.stats[3]),\n",
    "    'AP_medium': float(coco_eval.stats[4]),\n",
    "    'AP_large': float(coco_eval.stats[5]),\n",
    "    'AR_max1': float(coco_eval.stats[6]),\n",
    "    'AR_max10': float(coco_eval.stats[7]),\n",
    "    'AR_max100': float(coco_eval.stats[8]),\n",
    "    'AR_small': float(coco_eval.stats[9]),\n",
    "    'AR_medium': float(coco_eval.stats[10]),\n",
    "    'AR_large': float(coco_eval.stats[11])\n",
    "}\n",
    "\n",
    "per_class_metrics = {}\n",
    "for cat_id, cat_name in BDD_COCO_CATEGORIES.items():\n",
    "    coco_eval_class = COCOeval(coco_val, coco_dt, 'bbox')\n",
    "    coco_eval_class.params.catIds = [cat_id]\n",
    "    coco_eval_class.evaluate()\n",
    "    coco_eval_class.accumulate()\n",
    "    \n",
    "    per_class_metrics[cat_name] = {\n",
    "        'mAP': float(coco_eval_class.stats[0]) if coco_eval_class.stats[0] >= 0 else 0.0,\n",
    "        'AP50': float(coco_eval_class.stats[1]) if coco_eval_class.stats[1] >= 0 else 0.0,\n",
    "        'AP75': float(coco_eval_class.stats[2]) if coco_eval_class.stats[2] >= 0 else 0.0\n",
    "    }\n",
    "\n",
    "metrics_coco['per_class'] = per_class_metrics\n",
    "\n",
    "with open(OUTPUT_DIR / 'metrics.json', 'w') as f:\n",
    "    json.dump(metrics_coco, f, indent=2)\n",
    "\n",
    "print(\"\\nMétricas principales:\")\n",
    "print(f\"  mAP@[.50:.95]: {metrics_coco['mAP']:.4f}\")\n",
    "print(f\"  AP@50: {metrics_coco['AP50']:.4f}\")\n",
    "print(f\"  AP@75: {metrics_coco['AP75']:.4f}\")\n",
    "print(f\"\\nMétricas guardadas en: {OUTPUT_DIR / 'metrics.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda45617",
   "metadata": {},
   "source": [
    "## 9. Curvas Precision-Recall (3.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b631d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "PR_DIR = OUTPUT_DIR / 'pr_curves'\n",
    "PR_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "for cat_id, cat_name in BDD_COCO_CATEGORIES.items():\n",
    "    coco_eval_class = COCOeval(coco_val, coco_dt, 'bbox')\n",
    "    coco_eval_class.params.catIds = [cat_id]\n",
    "    coco_eval_class.evaluate()\n",
    "    coco_eval_class.accumulate()\n",
    "    \n",
    "    precision = coco_eval_class.eval['precision'][0, :, cat_id-1, 0, 2]\n",
    "    recall = np.linspace(0, 1, 101)\n",
    "    \n",
    "    valid_mask = precision > -1\n",
    "    precision_valid = precision[valid_mask]\n",
    "    recall_valid = recall[valid_mask]\n",
    "    \n",
    "    if len(precision_valid) > 0:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(recall_valid, precision_valid, linewidth=2)\n",
    "        plt.xlabel('Recall', fontsize=12)\n",
    "        plt.ylabel('Precision', fontsize=12)\n",
    "        plt.title(f'Precision-Recall: {cat_name}', fontsize=14)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.xlim([0, 1])\n",
    "        plt.ylim([0, 1])\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(PR_DIR / f'{cat_name}_pr.png', dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "print(f\"Curvas PR guardadas en: {PR_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399dda22",
   "metadata": {},
   "source": [
    "## 10. Sensibilidad a Umbrales (3.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60188e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_sweep = []\n",
    "conf_thresholds = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.50, 0.60, 0.75]\n",
    "\n",
    "print(\"Barrido de umbrales de confianza...\")\n",
    "for conf_th in tqdm(conf_thresholds):\n",
    "    preds_filtered = [p for p in predictions if p['score'] >= conf_th]\n",
    "    \n",
    "    if len(preds_filtered) == 0:\n",
    "        continue\n",
    "    \n",
    "    temp_path = OUTPUT_DIR / f'temp_preds_{conf_th}.json'\n",
    "    with open(temp_path, 'w') as f:\n",
    "        json.dump(preds_filtered, f)\n",
    "    \n",
    "    coco_dt_temp = coco_val.loadRes(str(temp_path))\n",
    "    coco_eval_temp = COCOeval(coco_val, coco_dt_temp, 'bbox')\n",
    "    coco_eval_temp.evaluate()\n",
    "    coco_eval_temp.accumulate()\n",
    "    coco_eval_temp.summarize()\n",
    "    \n",
    "    threshold_sweep.append({\n",
    "        'conf_threshold': conf_th,\n",
    "        'mAP': float(coco_eval_temp.stats[0]),\n",
    "        'AP50': float(coco_eval_temp.stats[1]),\n",
    "        'AP75': float(coco_eval_temp.stats[2]),\n",
    "        'num_predictions': len(preds_filtered)\n",
    "    })\n",
    "    \n",
    "    temp_path.unlink()\n",
    "\n",
    "threshold_df = pd.DataFrame(threshold_sweep)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(threshold_df['conf_threshold'], threshold_df['mAP'], 'o-', label='mAP')\n",
    "plt.plot(threshold_df['conf_threshold'], threshold_df['AP50'], 's-', label='AP50')\n",
    "plt.plot(threshold_df['conf_threshold'], threshold_df['AP75'], '^-', label='AP75')\n",
    "plt.xlabel('Confidence Threshold')\n",
    "plt.ylabel('Average Precision')\n",
    "plt.title('AP vs Confidence Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(threshold_df['conf_threshold'], threshold_df['num_predictions'], 'o-')\n",
    "plt.xlabel('Confidence Threshold')\n",
    "plt.ylabel('Number of Predictions')\n",
    "plt.title('Predictions vs Threshold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'threshold_sensitivity.png', dpi=150)\n",
    "plt.close()\n",
    "\n",
    "threshold_df.to_csv(OUTPUT_DIR / 'threshold_sweep.csv', index=False)\n",
    "print(f\"\\nBarrido de umbrales guardado en: {OUTPUT_DIR / 'threshold_sweep.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b8ba05",
   "metadata": {},
   "source": [
    "## 11. Visualización Cualitativa (3.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c353721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, 10))\n",
    "cat_colors = {cat_id: colors[i] for i, cat_id in enumerate(BDD_COCO_CATEGORIES.keys())}\n",
    "\n",
    "print(\"Generando visualizaciones cualitativas...\")\n",
    "for i, sample in enumerate(tqdm(sample_images[:50])):\n",
    "    img_id = sample['image_id']\n",
    "    img_path = Path(sample['image_path'])\n",
    "    \n",
    "    if not img_path.exists():\n",
    "        continue\n",
    "    \n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    img_w, img_h = image.size\n",
    "    \n",
    "    img_preds = [p for p in predictions if p['image_id'] == img_id]\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(16, 9))\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    for pred in img_preds:\n",
    "        bbox = pred['bbox']\n",
    "        cat_id = pred['category_id']\n",
    "        score = pred['score']\n",
    "        \n",
    "        x, y, w, h = bbox\n",
    "        rect = patches.Rectangle(\n",
    "            (x, y), w, h,\n",
    "            linewidth=2,\n",
    "            edgecolor=cat_colors[cat_id],\n",
    "            facecolor='none'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        label = f\"{CAT_ID_TO_PROMPT[cat_id]} {score:.2f}\"\n",
    "        ax.text(\n",
    "            x, y - 5,\n",
    "            label,\n",
    "            fontsize=8,\n",
    "            color='white',\n",
    "            bbox=dict(facecolor=cat_colors[cat_id], alpha=0.7, pad=2)\n",
    "        )\n",
    "    \n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'Image ID: {img_id} | Detections: {len(img_preds)}', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(QUALITATIVE_DIR / f'{img_id:07d}.jpg', dpi=100, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "print(f\"Visualizaciones guardadas en: {QUALITATIVE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621c4528",
   "metadata": {},
   "source": [
    "## 12. Preparación para Calibración (4.1, 4.2, 4.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06466f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 29/8000 [02:42<12:15:45,  5.54s/it]"
     ]
    }
   ],
   "source": [
    "if Path(baseline_config['dataset']['val_calib_json']).exists():\n",
    "    print(\"Generando inputs para calibración sobre val_calib...\")\n",
    "    \n",
    "    coco_calib = COCO(baseline_config['dataset']['val_calib_json'])\n",
    "    calib_image_ids = sorted(coco_calib.getImgIds())\n",
    "    \n",
    "    calib_records = []\n",
    "    \n",
    "    for img_id in tqdm(calib_image_ids):\n",
    "        img_info = coco_calib.loadImgs(img_id)[0]\n",
    "        img_path = Path(baseline_config['dataset']['image_dir']) / img_info['file_name']\n",
    "        \n",
    "        if not img_path.exists():\n",
    "            continue\n",
    "        \n",
    "        image_pil = Image.open(img_path).convert('RGB')\n",
    "        img_w, img_h = image_pil.size\n",
    "        \n",
    "        image_source, image_transformed = load_image(str(img_path))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            boxes, logits, phrases = predict(\n",
    "                model=model,\n",
    "                image=image_transformed,\n",
    "                caption=TEXT_PROMPT,\n",
    "                box_threshold=0.05,\n",
    "                text_threshold=0.25,\n",
    "                device=device\n",
    "            )\n",
    "        \n",
    "        boxes_xyxy = box_ops.box_cxcywh_to_xyxy(boxes) * torch.tensor([img_w, img_h, img_w, img_h])\n",
    "        boxes_xywh = []\n",
    "        for box in boxes_xyxy:\n",
    "            x1, y1, x2, y2 = box.tolist()\n",
    "            boxes_xywh.append([x1, y1, x2 - x1, y2 - y1])\n",
    "        \n",
    "        scores = logits.tolist()\n",
    "        labels_raw = [normalize_label(p) for p in phrases]\n",
    "        category_ids = [PROMPT_TO_CAT_ID.get(lbl, -1) for lbl in labels_raw]\n",
    "        \n",
    "        valid_mask = [cid != -1 for cid in category_ids]\n",
    "        boxes_xywh = [b for b, m in zip(boxes_xywh, valid_mask) if m]\n",
    "        scores = [s for s, m in zip(scores, valid_mask) if m]\n",
    "        category_ids = [c for c, m in zip(category_ids, valid_mask) if m]\n",
    "        \n",
    "        ann_ids = coco_calib.getAnnIds(imgIds=img_id)\n",
    "        anns = coco_calib.loadAnns(ann_ids)\n",
    "        \n",
    "        for pred_box, pred_score, pred_cat in zip(boxes_xywh, scores, category_ids):\n",
    "            pred_x1, pred_y1, pred_w, pred_h = pred_box\n",
    "            pred_x2 = pred_x1 + pred_w\n",
    "            pred_y2 = pred_y1 + pred_h\n",
    "            pred_area = pred_w * pred_h\n",
    "            \n",
    "            best_iou = 0.0\n",
    "            best_match = None\n",
    "            \n",
    "            for ann in anns:\n",
    "                if ann['category_id'] != pred_cat:\n",
    "                    continue\n",
    "                \n",
    "                gt_x, gt_y, gt_w, gt_h = ann['bbox']\n",
    "                gt_x2 = gt_x + gt_w\n",
    "                gt_y2 = gt_y + gt_h\n",
    "                gt_area = gt_w * gt_h\n",
    "                \n",
    "                inter_x1 = max(pred_x1, gt_x)\n",
    "                inter_y1 = max(pred_y1, gt_y)\n",
    "                inter_x2 = min(pred_x2, gt_x2)\n",
    "                inter_y2 = min(pred_y2, gt_y2)\n",
    "                \n",
    "                inter_w = max(0, inter_x2 - inter_x1)\n",
    "                inter_h = max(0, inter_y2 - inter_y1)\n",
    "                inter_area = inter_w * inter_h\n",
    "                \n",
    "                union_area = pred_area + gt_area - inter_area\n",
    "                iou = inter_area / union_area if union_area > 0 else 0.0\n",
    "                \n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_match = ann['id']\n",
    "            \n",
    "            is_correct = best_iou >= 0.5\n",
    "            \n",
    "            calib_records.append({\n",
    "                'image_id': int(img_id),\n",
    "                'bbox': [float(b) for b in pred_box],\n",
    "                'category_id_pred': int(pred_cat),\n",
    "                'score': float(pred_score),\n",
    "                'iou': float(best_iou),\n",
    "                'is_correct': bool(is_correct),\n",
    "                'gt_ann_id': int(best_match) if best_match else -1\n",
    "            })\n",
    "    \n",
    "    calib_df = pd.DataFrame(calib_records)\n",
    "    calib_df.to_parquet(OUTPUT_DIR / 'calib_inputs.parquet', index=False)\n",
    "    \n",
    "    print(f\"\\nCalibration inputs generados: {len(calib_records)} detecciones\")\n",
    "    print(f\"Guardado en: {OUTPUT_DIR / 'calib_inputs.parquet'}\")\n",
    "    \n",
    "    class_counts = calib_df.groupby('category_id_pred').size().to_dict()\n",
    "    print(\"\\nCobertura por clase en val_calib:\")\n",
    "    for cat_id, count in sorted(class_counts.items()):\n",
    "        cat_name = CAT_ID_TO_PROMPT[cat_id]\n",
    "        correct = calib_df[(calib_df['category_id_pred'] == cat_id) & (calib_df['is_correct'])].shape[0]\n",
    "        print(f\"  {cat_name}: {count} predicciones ({correct} correctas, {correct/count*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"val_calib.json no encontrado, saltando generación de inputs de calibración\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928758d1",
   "metadata": {},
   "source": [
    "## 13. Tabla Resumen Baseline (5.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df985908",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table = []\n",
    "\n",
    "for _, row in threshold_df.iterrows():\n",
    "    conf_th = row['conf_threshold']\n",
    "    \n",
    "    is_baseline = conf_th == baseline_config['inference']['conf_threshold']\n",
    "    marker = '⭐' if is_baseline else ''\n",
    "    \n",
    "    summary_table.append({\n",
    "        'Config': marker,\n",
    "        'Conf_Threshold': conf_th,\n",
    "        'NMS_IoU': baseline_config['inference']['nms_iou'],\n",
    "        'mAP': row['mAP'],\n",
    "        'AP50': row['AP50'],\n",
    "        'AP75': row['AP75'],\n",
    "        'FPS': perf_summary['fps'],\n",
    "        'GPU_MB': perf_summary.get('peak_gpu_memory_mb', 0),\n",
    "        'Detections/Img': row['num_predictions'] / perf_summary['total_images']\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_table)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABLA RESUMEN BASELINE\")\n",
    "print(\"=\"*80)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_df.to_csv(OUTPUT_DIR / 'summary_table.csv', index=False)\n",
    "print(f\"\\nTabla resumen guardada en: {OUTPUT_DIR / 'summary_table.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a714e209",
   "metadata": {},
   "source": [
    "## 14. Análisis de Errores (3.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2bcfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_analysis = {\n",
    "    'false_positives_high_conf': [],\n",
    "    'false_negatives': [],\n",
    "    'confusion_pairs': defaultdict(int)\n",
    "}\n",
    "\n",
    "print(\"Analizando errores...\")\n",
    "\n",
    "for img_id in tqdm(image_ids[:100]):\n",
    "    img_preds = [p for p in predictions if p['image_id'] == img_id]\n",
    "    \n",
    "    ann_ids = coco_val.getAnnIds(imgIds=img_id)\n",
    "    anns = coco_val.loadAnns(ann_ids)\n",
    "    \n",
    "    matched_gts = set()\n",
    "    \n",
    "    for pred in img_preds:\n",
    "        pred_box = pred['bbox']\n",
    "        pred_cat = pred['category_id']\n",
    "        pred_score = pred['score']\n",
    "        \n",
    "        px1, py1, pw, ph = pred_box\n",
    "        px2 = px1 + pw\n",
    "        py2 = py1 + ph\n",
    "        p_area = pw * ph\n",
    "        \n",
    "        best_iou = 0.0\n",
    "        best_ann = None\n",
    "        \n",
    "        for ann in anns:\n",
    "            gx, gy, gw, gh = ann['bbox']\n",
    "            gx2 = gx + gw\n",
    "            gy2 = gy + gh\n",
    "            g_area = gw * gh\n",
    "            \n",
    "            ix1 = max(px1, gx)\n",
    "            iy1 = max(py1, gy)\n",
    "            ix2 = min(px2, gx2)\n",
    "            iy2 = min(py2, gy2)\n",
    "            \n",
    "            iw = max(0, ix2 - ix1)\n",
    "            ih = max(0, iy2 - iy1)\n",
    "            inter = iw * ih\n",
    "            \n",
    "            union = p_area + g_area - inter\n",
    "            iou = inter / union if union > 0 else 0.0\n",
    "            \n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_ann = ann\n",
    "        \n",
    "        if best_iou >= 0.5 and best_ann['category_id'] == pred_cat:\n",
    "            matched_gts.add(best_ann['id'])\n",
    "        elif pred_score >= 0.5:\n",
    "            error_analysis['false_positives_high_conf'].append({\n",
    "                'image_id': img_id,\n",
    "                'pred_category': CAT_ID_TO_PROMPT[pred_cat],\n",
    "                'score': pred_score,\n",
    "                'iou': best_iou,\n",
    "                'gt_category': CAT_ID_TO_PROMPT.get(best_ann['category_id'], 'none') if best_ann else 'none'\n",
    "            })\n",
    "            \n",
    "            if best_ann and best_ann['category_id'] != pred_cat:\n",
    "                pred_name = CAT_ID_TO_PROMPT[pred_cat]\n",
    "                gt_name = CAT_ID_TO_PROMPT[best_ann['category_id']]\n",
    "                error_analysis['confusion_pairs'][(pred_name, gt_name)] += 1\n",
    "    \n",
    "    for ann in anns:\n",
    "        if ann['id'] not in matched_gts:\n",
    "            error_analysis['false_negatives'].append({\n",
    "                'image_id': img_id,\n",
    "                'category': CAT_ID_TO_PROMPT[ann['category_id']],\n",
    "                'bbox': ann['bbox']\n",
    "            })\n",
    "\n",
    "print(f\"\\nFalsos positivos (conf >= 0.5): {len(error_analysis['false_positives_high_conf'])}\")\n",
    "print(f\"Falsos negativos (en 100 imágenes): {len(error_analysis['false_negatives'])}\")\n",
    "\n",
    "print(\"\\nPares de confusión más comunes:\")\n",
    "confusion_sorted = sorted(error_analysis['confusion_pairs'].items(), key=lambda x: x[1], reverse=True)\n",
    "for (pred, gt), count in confusion_sorted[:10]:\n",
    "    print(f\"  {pred} ← {gt}: {count} veces\")\n",
    "\n",
    "with open(OUTPUT_DIR / 'error_analysis.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'false_positives_high_conf': error_analysis['false_positives_high_conf'][:20],\n",
    "        'false_negatives': error_analysis['false_negatives'][:20],\n",
    "        'confusion_pairs': {f\"{p}->{g}\": c for (p,g), c in confusion_sorted[:10]}\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"\\nAnálisis de errores guardado en: {OUTPUT_DIR / 'error_analysis.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a151f08",
   "metadata": {},
   "source": [
    "## 15. Resumen Final y Criterios Go/No-Go (6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae58153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_report = {\n",
    "    'baseline_config': baseline_config,\n",
    "    'metrics': metrics_coco,\n",
    "    'performance': perf_summary,\n",
    "    'artefacts': {\n",
    "        'predictions': str(OUTPUT_DIR / 'preds_raw.json'),\n",
    "        'metrics': str(OUTPUT_DIR / 'metrics.json'),\n",
    "        'pr_curves': str(PR_DIR),\n",
    "        'qualitative': str(QUALITATIVE_DIR),\n",
    "        'performance': str(OUTPUT_DIR / 'perf.txt'),\n",
    "        'calib_inputs': str(OUTPUT_DIR / 'calib_inputs.parquet'),\n",
    "        'threshold_sweep': str(OUTPUT_DIR / 'threshold_sweep.csv'),\n",
    "        'summary_table': str(OUTPUT_DIR / 'summary_table.csv'),\n",
    "        'error_analysis': str(OUTPUT_DIR / 'error_analysis.json')\n",
    "    },\n",
    "    'go_criteria': {\n",
    "        'mAP_reasonable': metrics_coco['mAP'] > 0.05,\n",
    "        'AP50_reasonable': metrics_coco['AP50'] > 0.10,\n",
    "        'latency_measured': True,\n",
    "        'artefacts_complete': True,\n",
    "        'calib_inputs_generated': Path(OUTPUT_DIR / 'calib_inputs.parquet').exists(),\n",
    "        'errors_identified': len(error_analysis['false_positives_high_conf']) > 0\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN FINAL BASELINE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nModelo: {baseline_config['model']['name']} ({baseline_config['model']['architecture']})\")\n",
    "print(f\"Checkpoint: {baseline_config['model']['checkpoint']}\")\n",
    "print(f\"Device: {baseline_config['model']['device']}\")\n",
    "\n",
    "print(f\"\\nMétricas de Detección:\")\n",
    "print(f\"  mAP@[.50:.95]: {metrics_coco['mAP']:.4f}\")\n",
    "print(f\"  AP@50: {metrics_coco['AP50']:.4f}\")\n",
    "print(f\"  AP@75: {metrics_coco['AP75']:.4f}\")\n",
    "\n",
    "print(f\"\\nRendimiento:\")\n",
    "print(f\"  Tiempo/imagen: {perf_summary['avg_time_per_image_s']:.3f}s\")\n",
    "print(f\"  FPS: {perf_summary['fps']:.2f}\")\n",
    "if 'peak_gpu_memory_mb' in perf_summary:\n",
    "    print(f\"  GPU memoria pico: {perf_summary['peak_gpu_memory_mb']:.0f} MB\")\n",
    "\n",
    "print(f\"\\nArtefactos Generados:\")\n",
    "for name, path in final_report['artefacts'].items():\n",
    "    exists = Path(path).exists()\n",
    "    status = \"✓\" if exists else \"✗\"\n",
    "    print(f\"  {status} {name}: {path}\")\n",
    "\n",
    "print(f\"\\nCriterios Go/No-Go para Fase 3:\")\n",
    "all_pass = all(final_report['go_criteria'].values())\n",
    "for criterion, passed in final_report['go_criteria'].items():\n",
    "    status = \"✓\" if passed else \"✗\"\n",
    "    print(f\"  {status} {criterion}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "if all_pass:\n",
    "    print(\"✅ BASELINE COMPLETADO - LISTO PARA FASE 3 (Incertidumbre y Calibración)\")\n",
    "else:\n",
    "    print(\"⚠️  BASELINE INCOMPLETO - Revisar criterios fallidos\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "with open(OUTPUT_DIR / 'final_report.json', 'w') as f:\n",
    "    json.dump(final_report, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\nReporte final guardado en: {OUTPUT_DIR / 'final_report.json'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
