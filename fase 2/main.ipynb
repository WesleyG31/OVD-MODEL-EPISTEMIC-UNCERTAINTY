{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "041e1452",
   "metadata": {},
   "source": [
    "# Baseline OVD - BDD100K Detection Pipeline\n",
    "\n",
    "Pipeline completo para establecer el baseline de detección con Grounding-DINO en BDD100K.\n",
    "\n",
    "**Fases:**\n",
    "1. Configuración del modelo y dataset\n",
    "2. Inferencia sobre val_eval\n",
    "3. Evaluación de métricas\n",
    "4. Preparación para calibración\n",
    "5. Generación de artefactos\n",
    "\n",
    "**Hardware requerido:** GPU con CUDA (mínimo 8GB VRAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41b56ec",
   "metadata": {},
   "source": [
    "## 1. Imports y Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62eb21cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from seaborn) (2.2.6)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from seaborn) (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sp1vevw\\.conda\\envs\\dino\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f367695a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.9.0-cp312-cp312-win_amd64.whl.metadata (30 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.24.0-cp312-cp312-win_amd64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from torch) (4.15.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from torchvision) (12.0.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Using cached torch-2.9.0-cp312-cp312-win_amd64.whl (109.3 MB)\n",
      "Using cached torchvision-0.24.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, torch, torchvision\n",
      "\n",
      "   ---------------------------------------- 0/4 [mpmath]\n",
      "   ---------------------------------------- 0/4 [mpmath]\n",
      "   ---------------------------------------- 0/4 [mpmath]\n",
      "   ---------------------------------------- 0/4 [mpmath]\n",
      "   ---------------------------------------- 0/4 [mpmath]\n",
      "   ---------------------------------------- 0/4 [mpmath]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchvision]\n",
      "   ---------------------------------------- 4/4 [torchvision]\n",
      "\n",
      "Successfully installed mpmath-1.3.0 sympy-1.14.0 torch-2.9.0 torchvision-0.24.0\n",
      "Requirement already satisfied: pycocotools in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (2.0.10)\n",
      "Requirement already satisfied: numpy in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pycocotools) (2.2.6)\n",
      "Requirement already satisfied: pycocotools in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (2.0.10)\n",
      "Requirement already satisfied: numpy in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pycocotools) (2.2.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (3.10.7)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Requirement already satisfied: pandas in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (3.10.7)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Requirement already satisfied: Pillow in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (12.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (6.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: Pillow in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (12.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (6.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\sp1vevw\\.conda\\envs\\dataset_huggingface\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "#!pip install torch torchvision\n",
    "#!pip install pycocotools\n",
    "#!pip install pandas matplotlib seaborn\n",
    "#!pip install Pillow tqdm pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f8e663f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "huggingface-hub>=0.34.0,<1.0 is required for a normal functioning of this module, but found huggingface-hub==1.0.1.\nTry: `pip install transformers -U` or `pip install -e '.[dev]'` if you're working with git main",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m     17\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../installing_dino/GroundingDINO\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgroundingdino\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_model, load_image, predict\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgroundingdino\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m box_ops\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpycocotools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcoco\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m COCO\n",
      "File \u001b[1;32mc:\\Users\\SP1VEVW\\.conda\\envs\\dino\\lib\\site-packages\\groundingdino\\util\\inference.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbisect\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgroundingdino\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mT\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgroundingdino\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_model\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgroundingdino\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clean_state_dict\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgroundingdino\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mslconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SLConfig\n",
      "File \u001b[1;32mc:\\Users\\SP1VEVW\\.conda\\envs\\dino\\lib\\site-packages\\groundingdino\\models\\__init__.py:8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Grounding DINO\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# url: https://github.com/IDEA-Research/GroundingDINO\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mGroundingDINO\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_groundingdino\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbuild_model\u001b[39m(args):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# we use register to maintain models from catdet6 on.\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MODULE_BUILD_FUNCS\n",
      "File \u001b[1;32mc:\\Users\\SP1VEVW\\.conda\\envs\\dino\\lib\\site-packages\\groundingdino\\models\\GroundingDINO\\__init__.py:15\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Grounding DINO\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# url: https://github.com/IDEA-Research/GroundingDINO\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroundingdino\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_groundingdino\n",
      "File \u001b[1;32mc:\\Users\\SP1VEVW\\.conda\\envs\\dino\\lib\\site-packages\\groundingdino\\models\\GroundingDINO\\groundingdino.py:24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mboxes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nms\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, BertModel, BertTokenizer, RobertaModel, RobertaTokenizerFast\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgroundingdino\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m box_ops, get_tokenlizer\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgroundingdino\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     NestedTensor,\n\u001b[0;32m     29\u001b[0m     accuracy,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     nested_tensor_from_tensor_list,\n\u001b[0;32m     35\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\SP1VEVW\\.conda\\envs\\dino\\lib\\site-packages\\transformers\\__init__.py:27\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     29\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[0;32m     30\u001b[0m     _LazyModule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m     is_pretty_midi_available,\n\u001b[0;32m     37\u001b[0m )\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Note: the following symbols are deliberately exported with `as`\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# so that mypy, pylint or other static linters can recognize them,\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# given that they are not exported using `__all__` in this file.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SP1VEVW\\.conda\\envs\\dino\\lib\\site-packages\\transformers\\dependency_versions_check.py:57\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[0;32m     55\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# not required, check version only if installed\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     \u001b[43mrequire_version_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpkg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeps\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, check dependency_versions_table.py\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\SP1VEVW\\.conda\\envs\\dino\\lib\\site-packages\\transformers\\utils\\versions.py:117\u001b[0m, in \u001b[0;36mrequire_version_core\u001b[1;34m(requirement)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"require_version wrapper which emits a core-specific hint on failure\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m hint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry: `pip install transformers -U` or `pip install -e \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.[dev]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` if you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre working with git main\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequire_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequirement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhint\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SP1VEVW\\.conda\\envs\\dino\\lib\\site-packages\\transformers\\utils\\versions.py:111\u001b[0m, in \u001b[0;36mrequire_version\u001b[1;34m(requirement, hint)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m want_ver \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m op, want_ver \u001b[38;5;129;01min\u001b[39;00m wanted\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 111\u001b[0m         \u001b[43m_compare_versions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgot_ver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwant_ver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequirement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpkg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhint\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SP1VEVW\\.conda\\envs\\dino\\lib\\site-packages\\transformers\\utils\\versions.py:44\u001b[0m, in \u001b[0;36m_compare_versions\u001b[1;34m(op, got_ver, want_ver, requirement, pkg, hint)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to compare versions for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequirement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: need=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwant_ver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m found=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgot_ver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is unusual. Consider\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m reinstalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     42\u001b[0m     )\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops[op](version\u001b[38;5;241m.\u001b[39mparse(got_ver), version\u001b[38;5;241m.\u001b[39mparse(want_ver)):\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequirement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is required for a normal functioning of this module, but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m==\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgot_ver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     46\u001b[0m     )\n",
      "\u001b[1;31mImportError\u001b[0m: huggingface-hub>=0.34.0,<1.0 is required for a normal functioning of this module, but found huggingface-hub==1.0.1.\nTry: `pip install transformers -U` or `pip install -e '.[dev]'` if you're working with git main"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import yaml\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.append('../installing_dino/GroundingDINO')\n",
    "from groundingdino.util.inference import load_model, load_image, predict\n",
    "from groundingdino.util import box_ops\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43576c1a",
   "metadata": {},
   "source": [
    "## 2. Configuración Baseline (1.1, 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9752ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path('../data')\n",
    "OUTPUT_DIR = Path('./outputs/baseline')\n",
    "QUALITATIVE_DIR = Path('./outputs/qualitative/baseline')\n",
    "CONFIG_DIR = Path('./configs')\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "QUALITATIVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CONFIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "baseline_config = {\n",
    "    'model': {\n",
    "        'name': 'Grounding-DINO',\n",
    "        'checkpoint': '../installing_dino/GroundingDINO/weights/groundingdino_swint_ogc.pth',\n",
    "        'config': '../installing_dino/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py',\n",
    "        'architecture': 'SwinT-OGC',\n",
    "        'input_size': [800, 1333],\n",
    "        'device': str(device)\n",
    "    },\n",
    "    'dataset': {\n",
    "        'image_dir': str(BASE_DIR / 'bdd100k/bdd100k/bdd100k/images/100k/val'),\n",
    "        'val_eval_json': str(BASE_DIR / 'bdd100k_coco/val_eval.json'),\n",
    "        'val_calib_json': str(BASE_DIR / 'bdd100k_coco/val_calib.json')\n",
    "    },\n",
    "    'inference': {\n",
    "        'conf_threshold': 0.30,\n",
    "        'nms_iou': 0.65,\n",
    "        'batch_size': 1,\n",
    "        'max_detections': 300\n",
    "    },\n",
    "    'prompts_file': str(BASE_DIR / 'prompts/bdd100k.txt'),\n",
    "    'seed': 42,\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "with open(CONFIG_DIR / 'baseline.yaml', 'w') as f:\n",
    "    yaml.dump(baseline_config, f, default_flow_style=False)\n",
    "\n",
    "print(\"Configuración baseline:\")\n",
    "print(yaml.dump(baseline_config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8381fa37",
   "metadata": {},
   "source": [
    "## 3. Definición del Vocabulario (1.3, 1.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d813d7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BDD_COCO_CATEGORIES = {\n",
    "    1: 'person',\n",
    "    2: 'rider',\n",
    "    3: 'car',\n",
    "    4: 'truck',\n",
    "    5: 'bus',\n",
    "    6: 'train',\n",
    "    7: 'motorcycle',\n",
    "    8: 'bicycle',\n",
    "    9: 'traffic light',\n",
    "    10: 'traffic sign'\n",
    "}\n",
    "\n",
    "PROMPTS = [\n",
    "    'person',\n",
    "    'rider',\n",
    "    'car',\n",
    "    'truck',\n",
    "    'bus',\n",
    "    'train',\n",
    "    'motorcycle',\n",
    "    'bicycle',\n",
    "    'traffic light',\n",
    "    'traffic sign'\n",
    "]\n",
    "\n",
    "PROMPT_SYNONYMS = {\n",
    "    'bike': 'bicycle',\n",
    "    'motorbike': 'motorcycle',\n",
    "    'motor': 'motorcycle',\n",
    "    'stop sign': 'traffic sign',\n",
    "    'red light': 'traffic light',\n",
    "    'signal': 'traffic light',\n",
    "    'pedestrian': 'person',\n",
    "    'vehicle': 'car',\n",
    "    'bicyclist': 'rider'\n",
    "}\n",
    "\n",
    "CAT_ID_TO_PROMPT = {cat_id: name for cat_id, name in BDD_COCO_CATEGORIES.items()}\n",
    "PROMPT_TO_CAT_ID = {name: cat_id for cat_id, name in BDD_COCO_CATEGORIES.items()}\n",
    "PROMPT_IDX_TO_CAT_ID = {i: i+1 for i in range(len(PROMPTS))}\n",
    "\n",
    "PROMPTS_DIR = BASE_DIR / 'prompts'\n",
    "PROMPTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(PROMPTS_DIR / 'bdd100k.txt', 'w') as f:\n",
    "    for prompt in PROMPTS:\n",
    "        f.write(f\"{prompt}\\n\")\n",
    "\n",
    "TEXT_PROMPT = '. '.join(PROMPTS) + '.'\n",
    "\n",
    "print(f\"Clases BDD100K COCO: {len(BDD_COCO_CATEGORIES)}\")\n",
    "print(f\"Text prompt para Grounding-DINO:\\n{TEXT_PROMPT}\")\n",
    "print(f\"\\nMapeo guardado en: {PROMPTS_DIR / 'bdd100k.txt'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8026fd3d",
   "metadata": {},
   "source": [
    "## 4. Carga del Modelo Grounding-DINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858b6e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cargando Grounding-DINO...\")\n",
    "model = load_model(\n",
    "    model_config_path=baseline_config['model']['config'],\n",
    "    model_checkpoint_path=baseline_config['model']['checkpoint'],\n",
    "    device=device\n",
    ")\n",
    "model.eval()\n",
    "print(\"Modelo cargado exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78bc72d",
   "metadata": {},
   "source": [
    "## 5. Funciones de Post-procesamiento (2.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c474d06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_label(label):\n",
    "    label_lower = label.lower().strip()\n",
    "    if label_lower in PROMPT_SYNONYMS:\n",
    "        return PROMPT_SYNONYMS[label_lower]\n",
    "    for canonical in PROMPTS:\n",
    "        if canonical in label_lower:\n",
    "            return canonical\n",
    "    return label_lower\n",
    "\n",
    "def cxcywh_to_xywh(bbox):\n",
    "    cx, cy, w, h = bbox\n",
    "    x = cx - w / 2\n",
    "    y = cy - h / 2\n",
    "    return [x, y, w, h]\n",
    "\n",
    "def clip_bbox(bbox, img_w, img_h):\n",
    "    x, y, w, h = bbox\n",
    "    x = max(0, min(x, img_w))\n",
    "    y = max(0, min(y, img_h))\n",
    "    w = max(0, min(w, img_w - x))\n",
    "    h = max(0, min(h, img_h - y))\n",
    "    return [x, y, w, h]\n",
    "\n",
    "def apply_nms(boxes, scores, labels, iou_threshold=0.65):\n",
    "    if len(boxes) == 0:\n",
    "        return boxes, scores, labels\n",
    "    \n",
    "    keep_indices = []\n",
    "    boxes_tensor = torch.tensor(boxes)\n",
    "    scores_tensor = torch.tensor(scores)\n",
    "    labels_tensor = torch.tensor(labels)\n",
    "    \n",
    "    for label_id in torch.unique(labels_tensor):\n",
    "        mask = labels_tensor == label_id\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        \n",
    "        class_boxes = boxes_tensor[mask]\n",
    "        class_scores = scores_tensor[mask]\n",
    "        class_indices = torch.where(mask)[0]\n",
    "        \n",
    "        x1 = class_boxes[:, 0]\n",
    "        y1 = class_boxes[:, 1]\n",
    "        x2 = class_boxes[:, 0] + class_boxes[:, 2]\n",
    "        y2 = class_boxes[:, 1] + class_boxes[:, 3]\n",
    "        areas = class_boxes[:, 2] * class_boxes[:, 3]\n",
    "        \n",
    "        order = class_scores.argsort(descending=True)\n",
    "        \n",
    "        keep = []\n",
    "        while order.numel() > 0:\n",
    "            if order.numel() == 1:\n",
    "                keep.append(order.item())\n",
    "                break\n",
    "            \n",
    "            i = order[0].item()\n",
    "            keep.append(i)\n",
    "            \n",
    "            xx1 = torch.maximum(x1[i], x1[order[1:]])\n",
    "            yy1 = torch.maximum(y1[i], y1[order[1:]])\n",
    "            xx2 = torch.minimum(x2[i], x2[order[1:]])\n",
    "            yy2 = torch.minimum(y2[i], y2[order[1:]])\n",
    "            \n",
    "            w = torch.maximum(torch.tensor(0.0), xx2 - xx1)\n",
    "            h = torch.maximum(torch.tensor(0.0), yy2 - yy1)\n",
    "            inter = w * h\n",
    "            \n",
    "            iou = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "            \n",
    "            mask_keep = iou <= iou_threshold\n",
    "            order = order[1:][mask_keep]\n",
    "        \n",
    "        keep_indices.extend(class_indices[keep].tolist())\n",
    "    \n",
    "    keep_indices = sorted(keep_indices)\n",
    "    return (\n",
    "        [boxes[i] for i in keep_indices],\n",
    "        [scores[i] for i in keep_indices],\n",
    "        [labels[i] for i in keep_indices]\n",
    "    )\n",
    "\n",
    "print(\"Funciones de post-procesamiento definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e247a626",
   "metadata": {},
   "source": [
    "## 6. Inferencia sobre val_eval (2.1, 2.3, 2.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6569e391",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_val = COCO(baseline_config['dataset']['val_eval_json'])\n",
    "image_ids = sorted(coco_val.getImgIds())\n",
    "\n",
    "predictions = []\n",
    "perf_metrics = {\n",
    "    'times': [],\n",
    "    'num_detections': [],\n",
    "    'gpu_memory_mb': []\n",
    "}\n",
    "\n",
    "print(f\"Iniciando inferencia sobre {len(image_ids)} imágenes de val_eval...\")\n",
    "\n",
    "sample_images = []\n",
    "sample_interval = len(image_ids) // 50 if len(image_ids) > 50 else 1\n",
    "\n",
    "for idx, img_id in enumerate(tqdm(image_ids)):\n",
    "    img_info = coco_val.loadImgs(img_id)[0]\n",
    "    img_path = Path(baseline_config['dataset']['image_dir']) / img_info['file_name']\n",
    "    \n",
    "    if not img_path.exists():\n",
    "        continue\n",
    "    \n",
    "    image_pil = Image.open(img_path).convert('RGB')\n",
    "    img_w, img_h = image_pil.size\n",
    "    \n",
    "    image_source, image_transformed = load_image(str(img_path))\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        boxes, logits, phrases = predict(\n",
    "            model=model,\n",
    "            image=image_transformed,\n",
    "            caption=TEXT_PROMPT,\n",
    "            box_threshold=baseline_config['inference']['conf_threshold'],\n",
    "            text_threshold=0.25,\n",
    "            device=device\n",
    "        )\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    elapsed = time.time() - start_time\n",
    "    perf_metrics['times'].append(elapsed)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        perf_metrics['gpu_memory_mb'].append(torch.cuda.max_memory_allocated() / 1024 / 1024)\n",
    "    \n",
    "    boxes_xyxy = box_ops.box_cxcywh_to_xyxy(boxes) * torch.tensor([img_w, img_h, img_w, img_h])\n",
    "    boxes_xywh = []\n",
    "    for box in boxes_xyxy:\n",
    "        x1, y1, x2, y2 = box.tolist()\n",
    "        boxes_xywh.append([x1, y1, x2 - x1, y2 - y1])\n",
    "    \n",
    "    scores = logits.tolist()\n",
    "    labels_raw = [normalize_label(p) for p in phrases]\n",
    "    category_ids = [PROMPT_TO_CAT_ID.get(lbl, -1) for lbl in labels_raw]\n",
    "    \n",
    "    valid_mask = [cid != -1 for cid in category_ids]\n",
    "    boxes_xywh = [b for b, m in zip(boxes_xywh, valid_mask) if m]\n",
    "    scores = [s for s, m in zip(scores, valid_mask) if m]\n",
    "    category_ids = [c for c, m in zip(category_ids, valid_mask) if m]\n",
    "    \n",
    "    if len(boxes_xywh) > 0:\n",
    "        boxes_xywh, scores, category_ids = apply_nms(\n",
    "            boxes_xywh, scores, category_ids, \n",
    "            iou_threshold=baseline_config['inference']['nms_iou']\n",
    "        )\n",
    "    \n",
    "    if len(boxes_xywh) > baseline_config['inference']['max_detections']:\n",
    "        sorted_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)\n",
    "        sorted_indices = sorted_indices[:baseline_config['inference']['max_detections']]\n",
    "        boxes_xywh = [boxes_xywh[i] for i in sorted_indices]\n",
    "        scores = [scores[i] for i in sorted_indices]\n",
    "        category_ids = [category_ids[i] for i in sorted_indices]\n",
    "    \n",
    "    for box, score, cat_id in zip(boxes_xywh, scores, category_ids):\n",
    "        box_clipped = clip_bbox(box, img_w, img_h)\n",
    "        predictions.append({\n",
    "            'image_id': int(img_id),\n",
    "            'category_id': int(cat_id),\n",
    "            'bbox': [float(b) for b in box_clipped],\n",
    "            'score': float(score)\n",
    "        })\n",
    "    \n",
    "    perf_metrics['num_detections'].append(len(boxes_xywh))\n",
    "    \n",
    "    if idx % sample_interval == 0 and len(sample_images) < 50:\n",
    "        sample_images.append({\n",
    "            'image_id': img_id,\n",
    "            'image_path': str(img_path),\n",
    "            'num_dets': len(boxes_xywh)\n",
    "        })\n",
    "\n",
    "preds_path = OUTPUT_DIR / 'preds_raw.json'\n",
    "with open(preds_path, 'w') as f:\n",
    "    json.dump(predictions, f)\n",
    "\n",
    "print(f\"\\nInferencia completada!\")\n",
    "print(f\"Total predicciones: {len(predictions)}\")\n",
    "print(f\"Predicciones guardadas en: {preds_path}\")\n",
    "print(f\"Tiempo promedio por imagen: {np.mean(perf_metrics['times']):.3f}s\")\n",
    "print(f\"FPS: {1.0 / np.mean(perf_metrics['times']):.2f}\")\n",
    "print(f\"Detecciones promedio por imagen: {np.mean(perf_metrics['num_detections']):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2748a226",
   "metadata": {},
   "source": [
    "## 7. Guardado de Métricas de Rendimiento (2.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbd5ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_summary = {\n",
    "    'avg_time_per_image_s': float(np.mean(perf_metrics['times'])),\n",
    "    'std_time_per_image_s': float(np.std(perf_metrics['times'])),\n",
    "    'fps': float(1.0 / np.mean(perf_metrics['times'])),\n",
    "    'avg_detections_per_image': float(np.mean(perf_metrics['num_detections'])),\n",
    "    'std_detections_per_image': float(np.std(perf_metrics['num_detections'])),\n",
    "    'total_predictions': len(predictions),\n",
    "    'total_images': len(image_ids)\n",
    "}\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    perf_summary['avg_gpu_memory_mb'] = float(np.mean(perf_metrics['gpu_memory_mb']))\n",
    "    perf_summary['peak_gpu_memory_mb'] = float(np.max(perf_metrics['gpu_memory_mb']))\n",
    "\n",
    "with open(OUTPUT_DIR / 'perf.txt', 'w') as f:\n",
    "    f.write(\"=\" * 60 + \"\\n\")\n",
    "    f.write(\"BASELINE PERFORMANCE METRICS\\n\")\n",
    "    f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "    for key, value in perf_summary.items():\n",
    "        f.write(f\"{key}: {value}\\n\")\n",
    "    f.write(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "\n",
    "print(\"\\nMétricas de rendimiento guardadas en:\", OUTPUT_DIR / 'perf.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b353ee",
   "metadata": {},
   "source": [
    "## 8. Evaluación COCO (3.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcbd3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ejecutando evaluación COCO...\")\n",
    "\n",
    "coco_dt = coco_val.loadRes(str(preds_path))\n",
    "coco_eval = COCOeval(coco_val, coco_dt, 'bbox')\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()\n",
    "\n",
    "metrics_coco = {\n",
    "    'mAP': float(coco_eval.stats[0]),\n",
    "    'AP50': float(coco_eval.stats[1]),\n",
    "    'AP75': float(coco_eval.stats[2]),\n",
    "    'AP_small': float(coco_eval.stats[3]),\n",
    "    'AP_medium': float(coco_eval.stats[4]),\n",
    "    'AP_large': float(coco_eval.stats[5]),\n",
    "    'AR_max1': float(coco_eval.stats[6]),\n",
    "    'AR_max10': float(coco_eval.stats[7]),\n",
    "    'AR_max100': float(coco_eval.stats[8]),\n",
    "    'AR_small': float(coco_eval.stats[9]),\n",
    "    'AR_medium': float(coco_eval.stats[10]),\n",
    "    'AR_large': float(coco_eval.stats[11])\n",
    "}\n",
    "\n",
    "per_class_metrics = {}\n",
    "for cat_id, cat_name in BDD_COCO_CATEGORIES.items():\n",
    "    coco_eval_class = COCOeval(coco_val, coco_dt, 'bbox')\n",
    "    coco_eval_class.params.catIds = [cat_id]\n",
    "    coco_eval_class.evaluate()\n",
    "    coco_eval_class.accumulate()\n",
    "    \n",
    "    per_class_metrics[cat_name] = {\n",
    "        'mAP': float(coco_eval_class.stats[0]) if coco_eval_class.stats[0] >= 0 else 0.0,\n",
    "        'AP50': float(coco_eval_class.stats[1]) if coco_eval_class.stats[1] >= 0 else 0.0,\n",
    "        'AP75': float(coco_eval_class.stats[2]) if coco_eval_class.stats[2] >= 0 else 0.0\n",
    "    }\n",
    "\n",
    "metrics_coco['per_class'] = per_class_metrics\n",
    "\n",
    "with open(OUTPUT_DIR / 'metrics.json', 'w') as f:\n",
    "    json.dump(metrics_coco, f, indent=2)\n",
    "\n",
    "print(\"\\nMétricas principales:\")\n",
    "print(f\"  mAP@[.50:.95]: {metrics_coco['mAP']:.4f}\")\n",
    "print(f\"  AP@50: {metrics_coco['AP50']:.4f}\")\n",
    "print(f\"  AP@75: {metrics_coco['AP75']:.4f}\")\n",
    "print(f\"\\nMétricas guardadas en: {OUTPUT_DIR / 'metrics.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda45617",
   "metadata": {},
   "source": [
    "## 9. Curvas Precision-Recall (3.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b631d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "PR_DIR = OUTPUT_DIR / 'pr_curves'\n",
    "PR_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "for cat_id, cat_name in BDD_COCO_CATEGORIES.items():\n",
    "    coco_eval_class = COCOeval(coco_val, coco_dt, 'bbox')\n",
    "    coco_eval_class.params.catIds = [cat_id]\n",
    "    coco_eval_class.evaluate()\n",
    "    coco_eval_class.accumulate()\n",
    "    \n",
    "    precision = coco_eval_class.eval['precision'][0, :, cat_id-1, 0, 2]\n",
    "    recall = np.linspace(0, 1, 101)\n",
    "    \n",
    "    valid_mask = precision > -1\n",
    "    precision_valid = precision[valid_mask]\n",
    "    recall_valid = recall[valid_mask]\n",
    "    \n",
    "    if len(precision_valid) > 0:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(recall_valid, precision_valid, linewidth=2)\n",
    "        plt.xlabel('Recall', fontsize=12)\n",
    "        plt.ylabel('Precision', fontsize=12)\n",
    "        plt.title(f'Precision-Recall: {cat_name}', fontsize=14)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.xlim([0, 1])\n",
    "        plt.ylim([0, 1])\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(PR_DIR / f'{cat_name}_pr.png', dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "print(f\"Curvas PR guardadas en: {PR_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399dda22",
   "metadata": {},
   "source": [
    "## 10. Sensibilidad a Umbrales (3.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60188e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_sweep = []\n",
    "conf_thresholds = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.50, 0.60, 0.75]\n",
    "\n",
    "print(\"Barrido de umbrales de confianza...\")\n",
    "for conf_th in tqdm(conf_thresholds):\n",
    "    preds_filtered = [p for p in predictions if p['score'] >= conf_th]\n",
    "    \n",
    "    if len(preds_filtered) == 0:\n",
    "        continue\n",
    "    \n",
    "    temp_path = OUTPUT_DIR / f'temp_preds_{conf_th}.json'\n",
    "    with open(temp_path, 'w') as f:\n",
    "        json.dump(preds_filtered, f)\n",
    "    \n",
    "    coco_dt_temp = coco_val.loadRes(str(temp_path))\n",
    "    coco_eval_temp = COCOeval(coco_val, coco_dt_temp, 'bbox')\n",
    "    coco_eval_temp.evaluate()\n",
    "    coco_eval_temp.accumulate()\n",
    "    coco_eval_temp.summarize()\n",
    "    \n",
    "    threshold_sweep.append({\n",
    "        'conf_threshold': conf_th,\n",
    "        'mAP': float(coco_eval_temp.stats[0]),\n",
    "        'AP50': float(coco_eval_temp.stats[1]),\n",
    "        'AP75': float(coco_eval_temp.stats[2]),\n",
    "        'num_predictions': len(preds_filtered)\n",
    "    })\n",
    "    \n",
    "    temp_path.unlink()\n",
    "\n",
    "threshold_df = pd.DataFrame(threshold_sweep)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(threshold_df['conf_threshold'], threshold_df['mAP'], 'o-', label='mAP')\n",
    "plt.plot(threshold_df['conf_threshold'], threshold_df['AP50'], 's-', label='AP50')\n",
    "plt.plot(threshold_df['conf_threshold'], threshold_df['AP75'], '^-', label='AP75')\n",
    "plt.xlabel('Confidence Threshold')\n",
    "plt.ylabel('Average Precision')\n",
    "plt.title('AP vs Confidence Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(threshold_df['conf_threshold'], threshold_df['num_predictions'], 'o-')\n",
    "plt.xlabel('Confidence Threshold')\n",
    "plt.ylabel('Number of Predictions')\n",
    "plt.title('Predictions vs Threshold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'threshold_sensitivity.png', dpi=150)\n",
    "plt.close()\n",
    "\n",
    "threshold_df.to_csv(OUTPUT_DIR / 'threshold_sweep.csv', index=False)\n",
    "print(f\"\\nBarrido de umbrales guardado en: {OUTPUT_DIR / 'threshold_sweep.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b8ba05",
   "metadata": {},
   "source": [
    "## 11. Visualización Cualitativa (3.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c353721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, 10))\n",
    "cat_colors = {cat_id: colors[i] for i, cat_id in enumerate(BDD_COCO_CATEGORIES.keys())}\n",
    "\n",
    "print(\"Generando visualizaciones cualitativas...\")\n",
    "for i, sample in enumerate(tqdm(sample_images[:50])):\n",
    "    img_id = sample['image_id']\n",
    "    img_path = Path(sample['image_path'])\n",
    "    \n",
    "    if not img_path.exists():\n",
    "        continue\n",
    "    \n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    img_w, img_h = image.size\n",
    "    \n",
    "    img_preds = [p for p in predictions if p['image_id'] == img_id]\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(16, 9))\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    for pred in img_preds:\n",
    "        bbox = pred['bbox']\n",
    "        cat_id = pred['category_id']\n",
    "        score = pred['score']\n",
    "        \n",
    "        x, y, w, h = bbox\n",
    "        rect = patches.Rectangle(\n",
    "            (x, y), w, h,\n",
    "            linewidth=2,\n",
    "            edgecolor=cat_colors[cat_id],\n",
    "            facecolor='none'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        label = f\"{CAT_ID_TO_PROMPT[cat_id]} {score:.2f}\"\n",
    "        ax.text(\n",
    "            x, y - 5,\n",
    "            label,\n",
    "            fontsize=8,\n",
    "            color='white',\n",
    "            bbox=dict(facecolor=cat_colors[cat_id], alpha=0.7, pad=2)\n",
    "        )\n",
    "    \n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'Image ID: {img_id} | Detections: {len(img_preds)}', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(QUALITATIVE_DIR / f'{img_id:07d}.jpg', dpi=100, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "print(f\"Visualizaciones guardadas en: {QUALITATIVE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621c4528",
   "metadata": {},
   "source": [
    "## 12. Preparación para Calibración (4.1, 4.2, 4.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06466f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 29/8000 [02:42<12:15:45,  5.54s/it]"
     ]
    }
   ],
   "source": [
    "if Path(baseline_config['dataset']['val_calib_json']).exists():\n",
    "    print(\"Generando inputs para calibración sobre val_calib...\")\n",
    "    \n",
    "    coco_calib = COCO(baseline_config['dataset']['val_calib_json'])\n",
    "    calib_image_ids = sorted(coco_calib.getImgIds())\n",
    "    \n",
    "    calib_records = []\n",
    "    \n",
    "    for img_id in tqdm(calib_image_ids):\n",
    "        img_info = coco_calib.loadImgs(img_id)[0]\n",
    "        img_path = Path(baseline_config['dataset']['image_dir']) / img_info['file_name']\n",
    "        \n",
    "        if not img_path.exists():\n",
    "            continue\n",
    "        \n",
    "        image_pil = Image.open(img_path).convert('RGB')\n",
    "        img_w, img_h = image_pil.size\n",
    "        \n",
    "        image_source, image_transformed = load_image(str(img_path))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            boxes, logits, phrases = predict(\n",
    "                model=model,\n",
    "                image=image_transformed,\n",
    "                caption=TEXT_PROMPT,\n",
    "                box_threshold=0.05,\n",
    "                text_threshold=0.25,\n",
    "                device=device\n",
    "            )\n",
    "        \n",
    "        boxes_xyxy = box_ops.box_cxcywh_to_xyxy(boxes) * torch.tensor([img_w, img_h, img_w, img_h])\n",
    "        boxes_xywh = []\n",
    "        for box in boxes_xyxy:\n",
    "            x1, y1, x2, y2 = box.tolist()\n",
    "            boxes_xywh.append([x1, y1, x2 - x1, y2 - y1])\n",
    "        \n",
    "        scores = logits.tolist()\n",
    "        labels_raw = [normalize_label(p) for p in phrases]\n",
    "        category_ids = [PROMPT_TO_CAT_ID.get(lbl, -1) for lbl in labels_raw]\n",
    "        \n",
    "        valid_mask = [cid != -1 for cid in category_ids]\n",
    "        boxes_xywh = [b for b, m in zip(boxes_xywh, valid_mask) if m]\n",
    "        scores = [s for s, m in zip(scores, valid_mask) if m]\n",
    "        category_ids = [c for c, m in zip(category_ids, valid_mask) if m]\n",
    "        \n",
    "        ann_ids = coco_calib.getAnnIds(imgIds=img_id)\n",
    "        anns = coco_calib.loadAnns(ann_ids)\n",
    "        \n",
    "        for pred_box, pred_score, pred_cat in zip(boxes_xywh, scores, category_ids):\n",
    "            pred_x1, pred_y1, pred_w, pred_h = pred_box\n",
    "            pred_x2 = pred_x1 + pred_w\n",
    "            pred_y2 = pred_y1 + pred_h\n",
    "            pred_area = pred_w * pred_h\n",
    "            \n",
    "            best_iou = 0.0\n",
    "            best_match = None\n",
    "            \n",
    "            for ann in anns:\n",
    "                if ann['category_id'] != pred_cat:\n",
    "                    continue\n",
    "                \n",
    "                gt_x, gt_y, gt_w, gt_h = ann['bbox']\n",
    "                gt_x2 = gt_x + gt_w\n",
    "                gt_y2 = gt_y + gt_h\n",
    "                gt_area = gt_w * gt_h\n",
    "                \n",
    "                inter_x1 = max(pred_x1, gt_x)\n",
    "                inter_y1 = max(pred_y1, gt_y)\n",
    "                inter_x2 = min(pred_x2, gt_x2)\n",
    "                inter_y2 = min(pred_y2, gt_y2)\n",
    "                \n",
    "                inter_w = max(0, inter_x2 - inter_x1)\n",
    "                inter_h = max(0, inter_y2 - inter_y1)\n",
    "                inter_area = inter_w * inter_h\n",
    "                \n",
    "                union_area = pred_area + gt_area - inter_area\n",
    "                iou = inter_area / union_area if union_area > 0 else 0.0\n",
    "                \n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_match = ann['id']\n",
    "            \n",
    "            is_correct = best_iou >= 0.5\n",
    "            \n",
    "            calib_records.append({\n",
    "                'image_id': int(img_id),\n",
    "                'bbox': [float(b) for b in pred_box],\n",
    "                'category_id_pred': int(pred_cat),\n",
    "                'score': float(pred_score),\n",
    "                'iou': float(best_iou),\n",
    "                'is_correct': bool(is_correct),\n",
    "                'gt_ann_id': int(best_match) if best_match else -1\n",
    "            })\n",
    "    \n",
    "    calib_df = pd.DataFrame(calib_records)\n",
    "    calib_df.to_parquet(OUTPUT_DIR / 'calib_inputs.parquet', index=False)\n",
    "    \n",
    "    print(f\"\\nCalibration inputs generados: {len(calib_records)} detecciones\")\n",
    "    print(f\"Guardado en: {OUTPUT_DIR / 'calib_inputs.parquet'}\")\n",
    "    \n",
    "    class_counts = calib_df.groupby('category_id_pred').size().to_dict()\n",
    "    print(\"\\nCobertura por clase en val_calib:\")\n",
    "    for cat_id, count in sorted(class_counts.items()):\n",
    "        cat_name = CAT_ID_TO_PROMPT[cat_id]\n",
    "        correct = calib_df[(calib_df['category_id_pred'] == cat_id) & (calib_df['is_correct'])].shape[0]\n",
    "        print(f\"  {cat_name}: {count} predicciones ({correct} correctas, {correct/count*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"val_calib.json no encontrado, saltando generación de inputs de calibración\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928758d1",
   "metadata": {},
   "source": [
    "## 13. Tabla Resumen Baseline (5.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df985908",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table = []\n",
    "\n",
    "for _, row in threshold_df.iterrows():\n",
    "    conf_th = row['conf_threshold']\n",
    "    \n",
    "    is_baseline = conf_th == baseline_config['inference']['conf_threshold']\n",
    "    marker = '⭐' if is_baseline else ''\n",
    "    \n",
    "    summary_table.append({\n",
    "        'Config': marker,\n",
    "        'Conf_Threshold': conf_th,\n",
    "        'NMS_IoU': baseline_config['inference']['nms_iou'],\n",
    "        'mAP': row['mAP'],\n",
    "        'AP50': row['AP50'],\n",
    "        'AP75': row['AP75'],\n",
    "        'FPS': perf_summary['fps'],\n",
    "        'GPU_MB': perf_summary.get('peak_gpu_memory_mb', 0),\n",
    "        'Detections/Img': row['num_predictions'] / perf_summary['total_images']\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_table)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABLA RESUMEN BASELINE\")\n",
    "print(\"=\"*80)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_df.to_csv(OUTPUT_DIR / 'summary_table.csv', index=False)\n",
    "print(f\"\\nTabla resumen guardada en: {OUTPUT_DIR / 'summary_table.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a714e209",
   "metadata": {},
   "source": [
    "## 14. Análisis de Errores (3.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2bcfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_analysis = {\n",
    "    'false_positives_high_conf': [],\n",
    "    'false_negatives': [],\n",
    "    'confusion_pairs': defaultdict(int)\n",
    "}\n",
    "\n",
    "print(\"Analizando errores...\")\n",
    "\n",
    "for img_id in tqdm(image_ids[:100]):\n",
    "    img_preds = [p for p in predictions if p['image_id'] == img_id]\n",
    "    \n",
    "    ann_ids = coco_val.getAnnIds(imgIds=img_id)\n",
    "    anns = coco_val.loadAnns(ann_ids)\n",
    "    \n",
    "    matched_gts = set()\n",
    "    \n",
    "    for pred in img_preds:\n",
    "        pred_box = pred['bbox']\n",
    "        pred_cat = pred['category_id']\n",
    "        pred_score = pred['score']\n",
    "        \n",
    "        px1, py1, pw, ph = pred_box\n",
    "        px2 = px1 + pw\n",
    "        py2 = py1 + ph\n",
    "        p_area = pw * ph\n",
    "        \n",
    "        best_iou = 0.0\n",
    "        best_ann = None\n",
    "        \n",
    "        for ann in anns:\n",
    "            gx, gy, gw, gh = ann['bbox']\n",
    "            gx2 = gx + gw\n",
    "            gy2 = gy + gh\n",
    "            g_area = gw * gh\n",
    "            \n",
    "            ix1 = max(px1, gx)\n",
    "            iy1 = max(py1, gy)\n",
    "            ix2 = min(px2, gx2)\n",
    "            iy2 = min(py2, gy2)\n",
    "            \n",
    "            iw = max(0, ix2 - ix1)\n",
    "            ih = max(0, iy2 - iy1)\n",
    "            inter = iw * ih\n",
    "            \n",
    "            union = p_area + g_area - inter\n",
    "            iou = inter / union if union > 0 else 0.0\n",
    "            \n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_ann = ann\n",
    "        \n",
    "        if best_iou >= 0.5 and best_ann['category_id'] == pred_cat:\n",
    "            matched_gts.add(best_ann['id'])\n",
    "        elif pred_score >= 0.5:\n",
    "            error_analysis['false_positives_high_conf'].append({\n",
    "                'image_id': img_id,\n",
    "                'pred_category': CAT_ID_TO_PROMPT[pred_cat],\n",
    "                'score': pred_score,\n",
    "                'iou': best_iou,\n",
    "                'gt_category': CAT_ID_TO_PROMPT.get(best_ann['category_id'], 'none') if best_ann else 'none'\n",
    "            })\n",
    "            \n",
    "            if best_ann and best_ann['category_id'] != pred_cat:\n",
    "                pred_name = CAT_ID_TO_PROMPT[pred_cat]\n",
    "                gt_name = CAT_ID_TO_PROMPT[best_ann['category_id']]\n",
    "                error_analysis['confusion_pairs'][(pred_name, gt_name)] += 1\n",
    "    \n",
    "    for ann in anns:\n",
    "        if ann['id'] not in matched_gts:\n",
    "            error_analysis['false_negatives'].append({\n",
    "                'image_id': img_id,\n",
    "                'category': CAT_ID_TO_PROMPT[ann['category_id']],\n",
    "                'bbox': ann['bbox']\n",
    "            })\n",
    "\n",
    "print(f\"\\nFalsos positivos (conf >= 0.5): {len(error_analysis['false_positives_high_conf'])}\")\n",
    "print(f\"Falsos negativos (en 100 imágenes): {len(error_analysis['false_negatives'])}\")\n",
    "\n",
    "print(\"\\nPares de confusión más comunes:\")\n",
    "confusion_sorted = sorted(error_analysis['confusion_pairs'].items(), key=lambda x: x[1], reverse=True)\n",
    "for (pred, gt), count in confusion_sorted[:10]:\n",
    "    print(f\"  {pred} ← {gt}: {count} veces\")\n",
    "\n",
    "with open(OUTPUT_DIR / 'error_analysis.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'false_positives_high_conf': error_analysis['false_positives_high_conf'][:20],\n",
    "        'false_negatives': error_analysis['false_negatives'][:20],\n",
    "        'confusion_pairs': {f\"{p}->{g}\": c for (p,g), c in confusion_sorted[:10]}\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"\\nAnálisis de errores guardado en: {OUTPUT_DIR / 'error_analysis.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a151f08",
   "metadata": {},
   "source": [
    "## 15. Resumen Final y Criterios Go/No-Go (6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae58153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_report = {\n",
    "    'baseline_config': baseline_config,\n",
    "    'metrics': metrics_coco,\n",
    "    'performance': perf_summary,\n",
    "    'artefacts': {\n",
    "        'predictions': str(OUTPUT_DIR / 'preds_raw.json'),\n",
    "        'metrics': str(OUTPUT_DIR / 'metrics.json'),\n",
    "        'pr_curves': str(PR_DIR),\n",
    "        'qualitative': str(QUALITATIVE_DIR),\n",
    "        'performance': str(OUTPUT_DIR / 'perf.txt'),\n",
    "        'calib_inputs': str(OUTPUT_DIR / 'calib_inputs.parquet'),\n",
    "        'threshold_sweep': str(OUTPUT_DIR / 'threshold_sweep.csv'),\n",
    "        'summary_table': str(OUTPUT_DIR / 'summary_table.csv'),\n",
    "        'error_analysis': str(OUTPUT_DIR / 'error_analysis.json')\n",
    "    },\n",
    "    'go_criteria': {\n",
    "        'mAP_reasonable': metrics_coco['mAP'] > 0.05,\n",
    "        'AP50_reasonable': metrics_coco['AP50'] > 0.10,\n",
    "        'latency_measured': True,\n",
    "        'artefacts_complete': True,\n",
    "        'calib_inputs_generated': Path(OUTPUT_DIR / 'calib_inputs.parquet').exists(),\n",
    "        'errors_identified': len(error_analysis['false_positives_high_conf']) > 0\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN FINAL BASELINE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nModelo: {baseline_config['model']['name']} ({baseline_config['model']['architecture']})\")\n",
    "print(f\"Checkpoint: {baseline_config['model']['checkpoint']}\")\n",
    "print(f\"Device: {baseline_config['model']['device']}\")\n",
    "\n",
    "print(f\"\\nMétricas de Detección:\")\n",
    "print(f\"  mAP@[.50:.95]: {metrics_coco['mAP']:.4f}\")\n",
    "print(f\"  AP@50: {metrics_coco['AP50']:.4f}\")\n",
    "print(f\"  AP@75: {metrics_coco['AP75']:.4f}\")\n",
    "\n",
    "print(f\"\\nRendimiento:\")\n",
    "print(f\"  Tiempo/imagen: {perf_summary['avg_time_per_image_s']:.3f}s\")\n",
    "print(f\"  FPS: {perf_summary['fps']:.2f}\")\n",
    "if 'peak_gpu_memory_mb' in perf_summary:\n",
    "    print(f\"  GPU memoria pico: {perf_summary['peak_gpu_memory_mb']:.0f} MB\")\n",
    "\n",
    "print(f\"\\nArtefactos Generados:\")\n",
    "for name, path in final_report['artefacts'].items():\n",
    "    exists = Path(path).exists()\n",
    "    status = \"✓\" if exists else \"✗\"\n",
    "    print(f\"  {status} {name}: {path}\")\n",
    "\n",
    "print(f\"\\nCriterios Go/No-Go para Fase 3:\")\n",
    "all_pass = all(final_report['go_criteria'].values())\n",
    "for criterion, passed in final_report['go_criteria'].items():\n",
    "    status = \"✓\" if passed else \"✗\"\n",
    "    print(f\"  {status} {criterion}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "if all_pass:\n",
    "    print(\"✅ BASELINE COMPLETADO - LISTO PARA FASE 3 (Incertidumbre y Calibración)\")\n",
    "else:\n",
    "    print(\"⚠️  BASELINE INCOMPLETO - Revisar criterios fallidos\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "with open(OUTPUT_DIR / 'final_report.json', 'w') as f:\n",
    "    json.dump(final_report, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\nReporte final guardado en: {OUTPUT_DIR / 'final_report.json'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
