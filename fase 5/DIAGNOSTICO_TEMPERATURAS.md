# üîç DIAGN√ìSTICO: Temperaturas Id√©nticas Entre M√©todos

## Problema Identificado

Los archivos de calibraci√≥n (`calib_baseline.csv`, `calib_mc_dropout.csv`, `calib_decoder_variance.csv`) son **id√©nticos**, lo que causa que las temperaturas calculadas sean las mismas (2.735) para los 3 m√©todos.

## Causa Ra√≠z

**NO HAY OVERLAP** entre las predicciones cacheadas de MC-Dropout y las im√°genes procesadas en val_calib:

- **MC-Dropout Parquet** (Fase 3): Tiene 100 im√°genes (IDs: 136-9857)
- **val_calib (primeras 500)**: Im√°genes con IDs diferentes (4-9961)
- **Overlap**: 0% (¬°ninguna imagen en com√∫n!)

Esto significa que:
1. Aunque el c√≥digo carga correctamente el Parquet con incertidumbre
2. **NINGUNA** de las 500 im√°genes procesadas tiene predicciones MC-Dropout cacheadas
3. Todas las 500 im√°genes deben calcular MC-Dropout desde cero (K=5 pases, muy costoso)
4. **HIP√ìTESIS**: El c√≥digo puede estar fallando silenciosamente y usando baseline en su lugar

## Verificaci√≥n

He agregado c√≥digo de diagn√≥stico al notebook que mostrar√°:
- Cu√°ntas im√°genes tienen overlap con el cache
- Cu√°ntas predicciones vienen de cach√© vs c√°lculo desde cero
- Comparaci√≥n de los CSVs generados (logits, scores, uncertainties)

## Soluciones Posibles

### Opci√≥n 1: Ejecutar Fase 3 Completa (RECOMENDADO)
Volver a ejecutar Fase 3 (MC-Dropout) en las **primeras 500 im√°genes de val_calib** para generar el cache correcto.

**Ventajas**:
- Tendr√°s predicciones MC-Dropout correctas con incertidumbre real
- Las temperaturas ser√°n diferentes para cada m√©todo
- Resultados m√°s precisos

**Desventajas**:
- Toma ~1.5 horas ejecutar MC-Dropout en 500 im√°genes (K=5 pases)

### Opci√≥n 2: Reducir Im√°genes Procesadas
Procesar solo las **100 im√°genes** que S√ç tienen MC-Dropout cacheado.

**C√≥mo**:
Cambiar en el notebook:
```python
# De:
for img_id in tqdm(img_ids_calib[:500]):

# A:
mc_cached_ids = set(mc_by_img.keys())
calib_subset = [img_id for img_id in img_ids_calib if img_id in mc_cached_ids][:100]
for img_id in tqdm(calib_subset):
```

**Ventajas**:
- R√°pido, usa solo cache
- Las temperaturas ser√°n diferentes

**Desventajas**:
- Solo 100 im√°genes para calibraci√≥n (menos robusto)

### Opci√≥n 3: Permitir C√°lculo desde Cero (ACTUAL)
El notebook ya est√° configurado para calcular MC-Dropout cuando no hay cache.

**Lo que deber√≠as verificar**:
1. Ejecutar el notebook con el nuevo c√≥digo de diagn√≥stico
2. Verificar que los contadores muestren:
   - `MC-Dropout: 0 cacheadas, 500 calculadas`
3. Verificar que los CSVs sean diferentes

**Si los CSVs siguen siendo id√©nticos**, significa que `inference_mc_dropout` no se est√° ejecutando correctamente y hay un bug en el c√≥digo.

## Pr√≥ximos Pasos

1. **Ejecuta el notebook** con el c√≥digo de diagn√≥stico actualizado
2. **Revisa los mensajes** en la secci√≥n 4 (val_calib):
   - ¬øCu√°ntas im√°genes de overlap?
   - ¬øCu√°ntas predicciones cacheadas vs calculadas?
   - ¬øLos CSVs son diferentes?

3. **Comparte los resultados** y decidimos:
   - Si los CSVs siguen id√©nticos ‚Üí hay un bug, necesito verlo
   - Si los CSVs son diferentes ‚Üí ¬°perfecto! Las temperaturas ser√°n diferentes

## Archivos de Diagn√≥stico Creados

- `diagnose_cache.py`: Verifica que los datos cacheados sean diferentes
- `check_overlap.py`: Verifica overlap entre cache y val_calib
- `count_images.py`: Cuenta im√°genes en val_calib

## Cambios Aplicados al Notebook

‚úÖ Agregado diagn√≥stico de overlap antes de procesar
‚úÖ Contadores de predicciones cacheadas vs calculadas  
‚úÖ Verificaci√≥n de diferencias en CSVs generados
‚úÖ Mensajes claros sobre qu√© est√° pasando

---

**Ejecuta el notebook y comparte la salida de la secci√≥n 4 para continuar.**
