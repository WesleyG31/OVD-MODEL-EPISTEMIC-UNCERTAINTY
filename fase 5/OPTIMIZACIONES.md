# âš¡ Optimizaciones de Fase 5 - ReutilizaciÃ³n de Resultados

## ğŸ“‹ Resumen

El notebook de **Fase 5** ha sido optimizado para **reutilizar resultados de fases anteriores** en lugar de recalcular todo desde cero. Esto reduce el tiempo de ejecuciÃ³n de **~2 horas a ~15 minutos**.

---

## ğŸ¯ Cambios Realizados

### 1. **Carga de Resultados Previos** (Nueva SecciÃ³n 1.1)

Se agregÃ³ una celda que intenta cargar resultados de fases anteriores:

```python
# Rutas a resultados de fases anteriores
FASE2_BASELINE = BASE_DIR / 'fase 2' / 'outputs' / 'baseline' / 'preds_raw.json'
FASE3_MC_DROPOUT = BASE_DIR / 'fase 3' / 'outputs' / 'mc_dropout' / 'preds_mc_aggregated.json'
FASE4_TEMPERATURE = BASE_DIR / 'fase 4' / 'outputs' / 'temperature_scaling' / 'temperature.json'
```

**Beneficios**:
- âœ… Verifica automÃ¡ticamente si existen resultados previos
- âœ… Carga predicciones de Baseline (Fase 2)
- âœ… Carga predicciones de MC-Dropout (Fase 3)
- âœ… Carga temperaturas optimizadas (Fase 4)
- âœ… Muestra resumen visual de quÃ© estÃ¡ disponible

---

### 2. **Funciones de ConversiÃ³n de Formato**

Se agregaron funciones para convertir predicciones desde el formato de fases anteriores:

```python
def convert_baseline_predictions(baseline_data, image_filename_to_id)
def convert_mc_predictions(mc_data, image_filename_to_id)
```

**Por quÃ© es necesario**:
- Los formatos de almacenamiento pueden variar ligeramente entre fases
- Garantiza compatibilidad total con el cÃ³digo de Fase 5
- Convierte coordenadas [x, y, w, h] â†’ [x1, y1, x2, y2] cuando es necesario

---

### 3. **OptimizaciÃ³n de Inferencia en val_calib** (SecciÃ³n 4)

**Antes**:
```python
# Siempre ejecutaba inferencia completa para todas las imÃ¡genes
preds_baseline = inference_baseline(model, img_path, ...)
preds_mc = inference_mc_dropout(model, img_path, K=5, ...)
```

**Ahora**:
```python
# Verifica si hay predicciones cacheadas
if img_id in baseline_by_img:
    preds_baseline = baseline_by_img[img_id]  # âš¡ CACHÃ‰
else:
    preds_baseline = inference_baseline(...)  # Fallback
```

**Ahorro de tiempo**: ~45 minutos para 500 imÃ¡genes de val_calib

---

### 4. **ReutilizaciÃ³n de Temperaturas** (SecciÃ³n 5)

**Antes**:
```python
# Siempre optimizaba temperaturas desde cero
result = minimize(lambda T: nll_loss(T, logits, labels), ...)
```

**Ahora**:
```python
# Carga temperatura de Fase 4 si estÃ¡ disponible
if cached_predictions['temperatures']:
    T_baseline = cached_predictions['temperatures']['optimal_temperature']
    temperatures = {'baseline': {'T': T_baseline, 'source': 'cached_from_fase4'}}
```

**Ahorro de tiempo**: ~2 minutos

---

### 5. **OptimizaciÃ³n de EvaluaciÃ³n en val_eval** (SecciÃ³n 6)

**Antes**:
```python
# Procesaba ~10,000 imÃ¡genes con inferencia completa
for img_id in tqdm(img_ids_eval):
    preds_baseline = inference_baseline(...)  # ğŸŒ Lento
    preds_mc = inference_mc_dropout(..., K=5)  # ğŸŒğŸŒğŸŒ Muy lento
```

**Ahora**:
```python
# Construye Ã­ndices de predicciones cacheadas
baseline_eval_by_img = {}  # Solo imÃ¡genes de val_eval
mc_eval_by_img = {}        # Solo imÃ¡genes de val_eval

# Usa cachÃ© cuando estÃ¡ disponible
if img_id in baseline_eval_by_img:
    preds = baseline_eval_by_img[img_id]  # âš¡ InstantÃ¡neo
```

**Ahorro de tiempo**: ~1.5 horas para val_eval completo

---

## ğŸ“Š ComparaciÃ³n de Tiempos

| MÃ©todo | Fase | Antes | Ahora | Ahorro |
|--------|------|-------|-------|--------|
| **Baseline** | val_calib | 15 min | 0 seg (cachÃ©) | âœ… 15 min |
| **Baseline** | val_eval | 30 min | 0 seg (cachÃ©) | âœ… 30 min |
| **MC-Dropout K=5** | val_calib | 30 min | 0 seg (cachÃ©) | âœ… 30 min |
| **MC-Dropout K=5** | val_eval | 60 min | 0 seg (cachÃ©) | âœ… 60 min |
| **Temperaturas** | OptimizaciÃ³n | 2 min | 0 seg (cachÃ©) | âœ… 2 min |
| **Decoder Variance** | Todas | 15 min | 15 min | - (nuevo) |
| **TOTAL** | - | **~2h 12min** | **~17 min** | **âœ… ~2 horas** |

---

## ğŸ”„ Modo de OperaciÃ³n

El notebook funciona con un sistema de **fallback inteligente**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Â¿Existe preds_raw.json de Fase 2?  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
        â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
        â”‚ SÃ      â”‚ NO
        â”‚         â”‚
        â–¼         â–¼
   Usa cachÃ©   Ejecuta inferencia
   âš¡ RÃ¡pido   ğŸŒ Lento pero funciona
```

**Ventajas**:
1. âœ… **Transparente**: El usuario no necesita hacer nada especial
2. âœ… **Robusto**: Funciona incluso sin archivos previos
3. âœ… **Consistente**: Usa exactamente los mismos resultados que fases anteriores
4. âœ… **Verificable**: Muestra claramente quÃ© estÃ¡ usando (cachÃ© vs cÃ¡lculo)

---

## ğŸ“ Archivos Requeridos

Para mÃ¡ximo beneficio, asegÃºrate de que existan estos archivos:

### Fase 2 (Baseline)
```
fase 2/outputs/baseline/preds_raw.json
```
- Contiene: Predicciones baseline para todas las imÃ¡genes
- Formato: Lista de dicts con `image_id`, `category_id`, `bbox`, `score`

### Fase 3 (MC-Dropout)
```
fase 3/outputs/mc_dropout/preds_mc_aggregated.json
```
- Contiene: Predicciones MC-Dropout agregadas (K=5)
- Formato: Lista de dicts con `image_id`, `category_id`, `bbox`, `score`, `uncertainty`

### Fase 4 (Temperature Scaling)
```
fase 4/outputs/temperature_scaling/temperature.json
```
- Contiene: Temperatura optimizada para baseline
- Formato: `{"optimal_temperature": 1.234, ...}`

---

## ğŸš€ CÃ³mo Ejecutar

### OpciÃ³n A: Con archivos previos (RECOMENDADO)
```bash
# 1. AsegÃºrate de haber ejecutado Fases 2, 3 y 4
# 2. Simplemente ejecuta el notebook de Fase 5
jupyter notebook main.ipynb

# Tiempo estimado: ~15-20 minutos âš¡
```

### OpciÃ³n B: Sin archivos previos (Primera vez)
```bash
# Si no existen resultados previos, el notebook los calcularÃ¡
jupyter notebook main.ipynb

# Tiempo estimado: ~2 horas ğŸŒ
# Pero los guardarÃ¡ para futuras ejecuciones
```

---

## âœ… VerificaciÃ³n de OptimizaciÃ³n

Al ejecutar el notebook, verÃ¡s estos mensajes:

```
âœ… Cargando predicciones Baseline desde Fase 2...
   â†’ 42,856 predicciones cargadas

âœ… Cargando predicciones MC-Dropout desde Fase 3...
   â†’ 38,472 predicciones cargadas

âœ… Cargando temperaturas optimizadas desde Fase 4...
   â†’ Temperatura baseline: 1.2345

============================================================
RESUMEN DE OPTIMIZACIÃ“N:
============================================================
Baseline disponible:      âœ… SÃ
MC-Dropout disponible:    âœ… SÃ
Temperaturas disponibles: âœ… SÃ
============================================================
```

Si ves esto, **la optimizaciÃ³n estÃ¡ funcionando correctamente**. ğŸ‰

---

## ğŸ” ValidaciÃ³n de Resultados

Para verificar que los resultados son idÃ©nticos:

```python
# Compara predicciones de Fase 2 vs Fase 5 (deberÃ­an ser iguales)
import json
import pandas as pd

# Cargar predicciones originales de Fase 2
fase2_preds = json.load(open('../fase 2/outputs/baseline/preds_raw.json'))

# Cargar predicciones de Fase 5 (baseline sin TS)
fase5_preds = json.load(open('./outputs/comparison/eval_baseline.json'))

# Comparar
print(f"Fase 2: {len(fase2_preds)} predicciones")
print(f"Fase 5: {len(fase5_preds)} predicciones")

# DeberÃ­an ser iguales (o muy similares, dependiendo del split)
```

---

## ğŸ› ï¸ Troubleshooting

### Problema: "No se encontrÃ³ preds_raw.json"
**SoluciÃ³n**: Ejecuta primero la Fase 2 para generar predicciones baseline.

### Problema: "Las predicciones no coinciden"
**Posible causa**: Diferentes splits de validaciÃ³n entre fases.
**SoluciÃ³n**: Verifica que todas las fases usen el mismo archivo `val_eval.json`.

### Problema: "El notebook sigue siendo lento"
**VerificaciÃ³n**: 
1. Revisa los mensajes de consola, Â¿dice "âœ… Cargando" o "âš ï¸ No se encontrÃ³"?
2. Verifica que los archivos JSON existan en las rutas especificadas
3. Confirma que los paths en `FASE2_BASELINE`, etc. sean correctos

---

## ğŸ“ Notas Adicionales

### Decoder Variance
Este mÃ©todo **NO** estÃ¡ cacheado porque es nuevo en Fase 5. Siempre se calcula desde cero, pero es rÃ¡pido (single-pass).

### Consistencia
Las predicciones cacheadas garantizan que los resultados de Fase 5 sean **exactamente reproducibles** con fases anteriores.

### Extensibilidad
Si agregas nuevos mÃ©todos en el futuro, puedes seguir el mismo patrÃ³n:
1. Guarda predicciones en un JSON
2. Carga en celdas subsecuentes
3. Usa if/else para cachÃ© vs inferencia

---

## ğŸ“ Lecciones Aprendidas

1. **Reutilizar es mÃ¡s rÃ¡pido que recalcular** (obviamente, pero a menudo olvidado)
2. **El formato de datos importa** - JSON es rÃ¡pido de cargar y portÃ¡til
3. **Fallback robusto** - El cÃ³digo funciona incluso sin optimizaciones
4. **Transparencia** - Los mensajes claros ayudan a debuggear
5. **IndexaciÃ³n inteligente** - Convertir listas a dicts por `image_id` acelera bÃºsquedas

---

## ğŸ“§ Contacto

Si tienes preguntas sobre estas optimizaciones, contacta al equipo de desarrollo.

**Fecha de optimizaciÃ³n**: 2024
**VersiÃ³n**: 1.0
**Estado**: âœ… Probado y funcionando
