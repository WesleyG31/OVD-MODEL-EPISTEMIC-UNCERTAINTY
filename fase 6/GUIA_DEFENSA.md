# üéì Gu√≠a para la Defensa - Demo Fase 6

## üìã Preparaci√≥n Pre-Defensa

### 1. Verificar Sistema (D√≠a antes)
```bash
cd "fase 6"
# Ejecutar todas las celdas del notebook main.ipynb
# Verificar que la celda 7 muestre ‚úÖ SISTEMA LISTO
```

### 2. Seleccionar Casos Clave (30 min antes)

**Caso 1: Escena F√°cil**
- Pocos objetos, buena visibilidad
- Objetivo: Mostrar que el sistema funciona bien en condiciones √≥ptimas
- Comparar: Baseline vs Baseline+TS (cambios sutiles en confianza)

**Caso 2: Escena Media**
- Tr√°fico normal, m√∫ltiples objetos
- Objetivo: Mostrar utilidad de la incertidumbre
- Comparar: Baseline+TS vs MC-Dropout+TS (detecciones con alta/baja incertidumbre)

**Caso 3: Escena Dif√≠cil**
- Muchos objetos, oclusi√≥n, condiciones adversas
- Objetivo: Demostrar cu√°ndo el sistema necesita ayuda
- Mostrar: Filtrado por umbral de incertidumbre

### 3. Tener Listo
- ‚úÖ Demo abierta y funcionando
- ‚úÖ 3 im√°genes cargadas (easy, medium, hard)
- ‚úÖ Capturas de pantalla en `outputs/screenshots/`
- ‚úÖ M√©tricas globales visibles en sidebar

---

## üéØ Narrativa para la Presentaci√≥n

### Introducci√≥n (1 min)
> "Voy a mostrar una demo interactiva que integra todo el trabajo:
> - Detecci√≥n Open-Vocabulary en escenas ADAS
> - Calibraci√≥n para probabilidades honestas
> - Incertidumbre epist√©mica para decisiones seguras"

### Demostraci√≥n 1: Calibraci√≥n (2-3 min)

**Mostrar**: Baseline vs Baseline + TS

**Script**:
1. "Aqu√≠ vemos la misma imagen procesada dos veces"
2. "A la izquierda: probabilidades originales"
3. "A la derecha: despu√©s de calibraci√≥n (Temperature Scaling)"
4. **Se√±alar detecci√≥n espec√≠fica**: "Este coche ten√≠a 0.92 de confianza, pero el modelo solo acierta ~75% a ese nivel. Con TS se corrige a 0.76, m√°s honesto"
5. **Mostrar m√©tricas**: "Globalmente, ECE baja de X a Y (mejor calibraci√≥n)"

**Mensaje clave**: *"La calibraci√≥n no mejora la detecci√≥n, pero hace que las probabilidades reflejen la realidad"*

### Demostraci√≥n 2: Incertidumbre (2-3 min)

**Mostrar**: Baseline + TS vs MC-Dropout + TS

**Script**:
1. "Ahora activamos MC-Dropout para estimar incertidumbre"
2. **Se√±alar etiquetas**: "Cada detecci√≥n tiene un nivel: LOW/MED/HIGH"
3. **Mostrar histograma**: "Vemos la distribuci√≥n de incertidumbre en esta escena"
4. **Ajustar umbral**: "Si filtramos solo las de baja incertidumbre..."
5. "Eliminamos X detecciones dudosas, nos quedamos con las confiables"

**Mensaje clave**: *"La incertidumbre nos dice cu√°ndo el modelo est√° inseguro, cr√≠tico para ADAS"*

### Demostraci√≥n 3: Caso Dif√≠cil (2 min)

**Mostrar**: Escena compleja con filtrado agresivo

**Script**:
1. "En esta escena dif√≠cil [noche/lluvia/ciudad], hay Y detecciones"
2. "Z tienen alta incertidumbre"
3. **Filtrar**: "Si el sistema ADAS solo toma decisiones con baja incertidumbre..."
4. "Se queda con N detecciones seguras, evita errores costosos"
5. **Mostrar m√©trica**: "Esto reduce FP en X%, manteniendo Y% de TP"

**Mensaje clave**: *"Trade-off expl√≠cito: cobertura vs riesgo, el sistema decide seg√∫n contexto"*

---

## üí° Respuestas a Preguntas Frecuentes

### "¬øCu√°nto cuesta computacionalmente?"
- Baseline: ~200ms/imagen
- MC-Dropout K=5: ~1s/imagen (5x m√°s lento)
- Varianza decoder: ~250ms (intermedio)
- **Respuesta**: "Para un veh√≠culo a 30 km/h procesando a 10 FPS, MC-Dropout es viable. Para 120 km/h, usar√≠amos varianza decoder (single-pass)"

### "¬øPor qu√© no usar simplemente un umbral de confianza?"
- Mostrar caso donde score alto pero alta incertidumbre
- "La confianza dice 'qu√© tan seguro estoy de esta clase', la incertidumbre dice 'qu√© tan inconsistente es el modelo internamente'. Son ortogonales"

### "¬øQu√© pasa si la incertidumbre est√° mal calibrada?"
- "La incertidumbre es relativa, no absoluta. Lo importante es el ranking: las detecciones de alta incertidumbre son estad√≠sticamente m√°s propensas a ser FP"
- Mostrar curvas risk-coverage de Fase 5

### "¬øC√≥mo se integrar√≠a en un sistema real?"
1. **Pipeline**: Detecci√≥n ‚Üí Calibraci√≥n ‚Üí C√°lculo de incertidumbre ‚Üí Decisi√≥n
2. **Modos**:
   - **Modo autopista**: Umbral bajo (solo muy confiables)
   - **Modo ciudad**: Umbral medio (balance)
   - **Modo asistido**: Todas las detecciones, UI resalta inciertas
3. **Fallback**: Si toda la escena tiene alta incertidumbre ‚Üí alerta al conductor

---

## üìä M√©tricas a Mencionar

**Sin entrar en detalles t√©cnicos excesivos**:
- "Reducimos ECE de X a Y (mejor calibraci√≥n)"
- "AUROC TP/FP de Z (incertidumbre discrimina errores)"
- "mAP se mantiene (no perdemos detecci√≥n)"

**√ânfasis**: "No sacrificamos rendimiento, agregamos confiabilidad"

---

## üö® Plan B (Si algo falla)

### Demo no carga
- Tener capturas de pantalla pre-generadas
- "Por tiempo, muestro capturas representativas"
- Explicar igual la narrativa

### Modelo es muy lento
- Usar im√°genes peque√±as pre-procesadas
- Reducir K de MC-Dropout a 3
- Usar varianza decoder en lugar de MC-Dropout

### Sin conexi√≥n a GPU
- Demo funciona en CPU (m√°s lento pero viable)
- Preparar ejemplos pre-calculados

---

## ‚úÖ Checklist Final (10 min antes)

- [ ] Demo corriendo en `localhost:8501`
- [ ] 3 casos cargados (easy/medium/hard)
- [ ] M√©tricas visibles en sidebar
- [ ] Capturas de respaldo en carpeta
- [ ] Saber responder 3 preguntas clave
- [ ] Tiempo cronometrado: 5-7 min total
- [ ] Mensaje final preparado

---

## üé¨ Cierre de la Demo

> "En resumen:
> 1. La calibraci√≥n hace que las probabilidades sean honestas
> 2. La incertidumbre identifica cu√°ndo el modelo necesita ayuda
> 3. Juntas, permiten decisiones m√°s seguras en sistemas cr√≠ticos como ADAS
> 
> Esta demo es una prueba de concepto, pero los principios aplican a cualquier modelo de detecci√≥n en aplicaciones de seguridad"

**Transici√≥n**: "Ahora paso a las conclusiones y trabajo futuro..."

---

## üéØ Tiempo Sugerido

| Secci√≥n | Tiempo |
|---------|--------|
| Introducci√≥n | 1 min |
| Demo 1: Calibraci√≥n | 2 min |
| Demo 2: Incertidumbre | 2 min |
| Demo 3: Caso dif√≠cil | 1 min |
| Preguntas/discusi√≥n | 2-3 min |
| **TOTAL** | **7-9 min** |

Reservar √∫ltimo 25% del tiempo para preguntas.
