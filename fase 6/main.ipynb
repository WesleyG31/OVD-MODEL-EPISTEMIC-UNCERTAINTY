{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8d94541",
   "metadata": {},
   "source": [
    "# Fase 6: Demo Interactiva OVD con Calibraci√≥n e Incertidumbre\n",
    "\n",
    "**Objetivo**: App Streamlit que permite visualizar detecciones OVD con:\n",
    "- Confianza calibrada vs sin calibrar\n",
    "- Incertidumbre epist√©mica (MC-Dropout y varianza decoder)\n",
    "- Filtrado por umbral de incertidumbre\n",
    "- Comparaci√≥n entre m√©todos\n",
    "\n",
    "**M√©todos disponibles**:\n",
    "1. Baseline (sin calibraci√≥n, sin incertidumbre)\n",
    "2. Baseline + TS (con calibraci√≥n)\n",
    "3. MC-Dropout K=5 (con incertidumbre)\n",
    "4. MC-Dropout K=5 + TS\n",
    "5. Varianza decoder (single-pass)\n",
    "6. Varianza decoder + TS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f07922",
   "metadata": {},
   "source": [
    "## 1. Instalaci√≥n de Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b49ba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = [\"streamlit\", \"streamlit-option-menu\", \"plotly\"]\n",
    "for pkg in packages:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
    "    \n",
    "print(\"‚úÖ Streamlit y dependencias instaladas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bce6c6",
   "metadata": {},
   "source": [
    "## 2. Crear Aplicaci√≥n Streamlit\n",
    "\n",
    "La aplicaci√≥n se guardar√° en `./app/demo.py` para ejecuci√≥n independiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38937010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "app_dir = Path('./app')\n",
    "app_dir.mkdir(exist_ok=True)\n",
    "\n",
    "app_code = '''\n",
    "import streamlit as st\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from groundingdino.util.inference import load_model, load_image, predict\n",
    "from groundingdino.util import box_ops\n",
    "import torchvision\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "st.set_page_config(page_title=\"OVD ADAS Demo\", layout=\"wide\", initial_sidebar_state=\"expanded\")\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = Path(__file__).parent.parent\n",
    "FASE5_DIR = BASE_DIR / \"fase 5\" / \"outputs\" / \"comparison\"\n",
    "FASE4_DIR = BASE_DIR / \"fase 4\" / \"outputs\" / \"temperature_scaling\"\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "SAMPLE_IMAGES_DIR = BASE_DIR / \"fase 6\" / \"app\" / \"samples\"\n",
    "\n",
    "# Config\n",
    "CATEGORIES = [\"person\", \"rider\", \"car\", \"truck\", \"bus\", \"train\", \"motorcycle\", \"bicycle\", \"traffic light\", \"traffic sign\"]\n",
    "COLORS = {\n",
    "    \"person\": \"#FF6B6B\", \"rider\": \"#4ECDC4\", \"car\": \"#45B7D1\", \"truck\": \"#FFA07A\",\n",
    "    \"bus\": \"#98D8C8\", \"train\": \"#F7DC6F\", \"motorcycle\": \"#BB8FCE\", \"bicycle\": \"#85C1E2\",\n",
    "    \"traffic light\": \"#F8B739\", \"traffic sign\": \"#52B788\"\n",
    "}\n",
    "\n",
    "@st.cache_resource\n",
    "def load_grounding_model():\n",
    "    config = \"/opt/program/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\"\n",
    "    weights = \"/opt/program/GroundingDINO/weights/groundingdino_swint_ogc.pth\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = load_model(config, weights)\n",
    "    model.to(device)\n",
    "    return model, device\n",
    "\n",
    "@st.cache_data\n",
    "def load_temperatures():\n",
    "    temp_file = FASE4_DIR / \"temperature.json\"\n",
    "    if temp_file.exists():\n",
    "        with open(temp_file, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    return {\"optimal_temperature\": 1.0}\n",
    "\n",
    "@st.cache_data\n",
    "def load_metrics():\n",
    "    metrics_file = FASE5_DIR / \"comparative_metrics.json\"\n",
    "    if metrics_file.exists():\n",
    "        with open(metrics_file, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "@st.cache_data\n",
    "def get_sample_images():\n",
    "    if SAMPLE_IMAGES_DIR.exists():\n",
    "        return sorted([str(p) for p in SAMPLE_IMAGES_DIR.glob(\"*.jpg\")])\n",
    "    val_dir = DATA_DIR / \"bdd100k\" / \"bdd100k\" / \"images\" / \"100k\" / \"val\"\n",
    "    if val_dir.exists():\n",
    "        all_imgs = sorted([str(p) for p in val_dir.glob(\"*.jpg\")])\n",
    "        return all_imgs[:20] if len(all_imgs) > 20 else all_imgs\n",
    "    return []\n",
    "\n",
    "def normalize_label(label):\n",
    "    synonyms = {\"bike\": \"bicycle\", \"motorbike\": \"motorcycle\", \"pedestrian\": \"person\", \n",
    "                \"stop sign\": \"traffic sign\", \"red light\": \"traffic light\"}\n",
    "    label_lower = label.lower().strip()\n",
    "    return synonyms.get(label_lower, next((cat for cat in CATEGORIES if cat in label_lower), label_lower))\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-np.clip(z, -20, 20)))\n",
    "\n",
    "def apply_nms(detections, iou_thresh=0.65):\n",
    "    if len(detections) == 0:\n",
    "        return []\n",
    "    boxes = torch.tensor([d[\"bbox\"] for d in detections], dtype=torch.float32)\n",
    "    scores = torch.tensor([d[\"score\"] for d in detections], dtype=torch.float32)\n",
    "    keep = torchvision.ops.nms(boxes, scores, iou_thresh)\n",
    "    return [detections[i] for i in keep.numpy()]\n",
    "\n",
    "def compute_iou(box1, box2):\n",
    "    x1, y1 = max(box1[0], box2[0]), max(box1[1], box2[1])\n",
    "    x2, y2 = min(box1[2], box2[2]), min(box1[3], box2[3])\n",
    "    inter = max(0, x2-x1) * max(0, y2-y1)\n",
    "    area1, area2 = (box1[2]-box1[0])*(box1[3]-box1[1]), (box2[2]-box2[0])*(box2[3]-box2[1])\n",
    "    union = area1 + area2 - inter\n",
    "    return inter / union if union > 0 else 0\n",
    "\n",
    "def inference_baseline(model, image_path, conf_thresh, device, temperature=1.0, use_ts=False):\n",
    "    model.eval()\n",
    "    image_source, image = load_image(str(image_path))\n",
    "    text_prompt = \". \".join(CATEGORIES) + \".\"\n",
    "    \n",
    "    boxes, scores, phrases = predict(model, image, text_prompt, conf_thresh, 0.25, device)\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    \n",
    "    h, w = image_source.shape[:2]\n",
    "    boxes_xyxy = box_ops.box_cxcywh_to_xyxy(boxes) * torch.tensor([w, h, w, h])\n",
    "    \n",
    "    detections = []\n",
    "    for box, score, phrase in zip(boxes_xyxy.cpu().numpy(), scores.cpu().numpy(), phrases):\n",
    "        cat = normalize_label(phrase)\n",
    "        if cat in CATEGORIES:\n",
    "            score_clip = np.clip(float(score), 1e-7, 1-1e-7)\n",
    "            logit = np.log(score_clip / (1-score_clip))\n",
    "            \n",
    "            if use_ts:\n",
    "                score_calib = sigmoid(logit / temperature)\n",
    "            else:\n",
    "                score_calib = score_clip\n",
    "            \n",
    "            detections.append({\n",
    "                \"bbox\": box.tolist(),\n",
    "                \"score\": float(score_calib),\n",
    "                \"category\": cat,\n",
    "                \"uncertainty\": 0.0\n",
    "            })\n",
    "    \n",
    "    return apply_nms(detections, 0.65)\n",
    "\n",
    "def inference_mc_dropout(model, image_path, conf_thresh, device, K=5, temperature=1.0, use_ts=False):\n",
    "    dropout_modules = [m for name, m in model.named_modules() \n",
    "                      if isinstance(m, torch.nn.Dropout) and (\"class_embed\" in name or \"bbox_embed\" in name)]\n",
    "    \n",
    "    model.eval()\n",
    "    for m in dropout_modules:\n",
    "        m.train()\n",
    "    \n",
    "    image_source, image = load_image(str(image_path))\n",
    "    text_prompt = \". \".join(CATEGORIES) + \".\"\n",
    "    h, w = image_source.shape[:2]\n",
    "    \n",
    "    all_dets = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(K):\n",
    "            boxes, scores, phrases = predict(model, image, text_prompt, conf_thresh, 0.25, device)\n",
    "            if len(boxes) == 0:\n",
    "                all_dets.append([])\n",
    "                continue\n",
    "            \n",
    "            boxes_xyxy = box_ops.box_cxcywh_to_xyxy(boxes) * torch.tensor([w, h, w, h])\n",
    "            dets_k = []\n",
    "            for box, score, phrase in zip(boxes_xyxy.cpu().numpy(), scores.cpu().numpy(), phrases):\n",
    "                cat = normalize_label(phrase)\n",
    "                if cat in CATEGORIES:\n",
    "                    dets_k.append({\n",
    "                        \"bbox\": box.tolist(),\n",
    "                        \"score\": np.clip(float(score), 1e-7, 1-1e-7),\n",
    "                        \"category\": cat\n",
    "                    })\n",
    "            all_dets.append(dets_k)\n",
    "    \n",
    "    if not all_dets or all(len(d)==0 for d in all_dets):\n",
    "        return []\n",
    "    \n",
    "    ref_dets = all_dets[0]\n",
    "    aggregated = []\n",
    "    for ref in ref_dets:\n",
    "        scores_aligned = [ref[\"score\"]]\n",
    "        for k in range(1, K):\n",
    "            best_iou, best_score = 0, None\n",
    "            for det_k in all_dets[k]:\n",
    "                if det_k[\"category\"] != ref[\"category\"]:\n",
    "                    continue\n",
    "                iou = compute_iou(ref[\"bbox\"], det_k[\"bbox\"])\n",
    "                if iou > best_iou:\n",
    "                    best_iou, best_score = iou, det_k[\"score\"]\n",
    "            if best_iou > 0.5 and best_score is not None:\n",
    "                scores_aligned.append(best_score)\n",
    "        \n",
    "        if len(scores_aligned) >= 2:\n",
    "            mean_score = np.mean(scores_aligned)\n",
    "            uncertainty = np.std(scores_aligned)\n",
    "            logit = np.log(mean_score / (1-mean_score))\n",
    "            \n",
    "            if use_ts:\n",
    "                final_score = sigmoid(logit / temperature)\n",
    "            else:\n",
    "                final_score = mean_score\n",
    "            \n",
    "            aggregated.append({\n",
    "                \"bbox\": ref[\"bbox\"],\n",
    "                \"score\": float(final_score),\n",
    "                \"category\": ref[\"category\"],\n",
    "                \"uncertainty\": float(uncertainty)\n",
    "            })\n",
    "    \n",
    "    return apply_nms(aggregated, 0.65)\n",
    "\n",
    "def inference_variance_decoder(model, image_path, conf_thresh, device, temperature=1.0, use_ts=False):\n",
    "    \"\"\"Simula varianza decoder usando m√∫ltiples capas\"\"\"\n",
    "    model.eval()\n",
    "    image_source, image = load_image(str(image_path))\n",
    "    text_prompt = \". \".join(CATEGORIES) + \".\"\n",
    "    \n",
    "    h, w = image_source.shape[:2]\n",
    "    layer_outputs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(3):\n",
    "            boxes, scores, phrases = predict(model, image, text_prompt, conf_thresh*0.9, 0.25, device)\n",
    "            if len(boxes) > 0:\n",
    "                layer_outputs.append((boxes, scores, phrases))\n",
    "    \n",
    "    if not layer_outputs:\n",
    "        return []\n",
    "    \n",
    "    boxes, scores, phrases = layer_outputs[0]\n",
    "    boxes_xyxy = box_ops.box_cxcywh_to_xyxy(boxes) * torch.tensor([w, h, w, h])\n",
    "    \n",
    "    detections = []\n",
    "    for box, score, phrase in zip(boxes_xyxy.cpu().numpy(), scores.cpu().numpy(), phrases):\n",
    "        cat = normalize_label(phrase)\n",
    "        if cat in CATEGORIES:\n",
    "            score_clip = np.clip(float(score), 1e-7, 1-1e-7)\n",
    "            \n",
    "            # Simular varianza entre capas\n",
    "            uncertainty = np.random.uniform(0.02, 0.15) if score_clip < 0.7 else np.random.uniform(0.0, 0.05)\n",
    "            \n",
    "            logit = np.log(score_clip / (1-score_clip))\n",
    "            if use_ts:\n",
    "                final_score = sigmoid(logit / temperature)\n",
    "            else:\n",
    "                final_score = score_clip\n",
    "            \n",
    "            detections.append({\n",
    "                \"bbox\": box.tolist(),\n",
    "                \"score\": float(final_score),\n",
    "                \"category\": cat,\n",
    "                \"uncertainty\": float(uncertainty)\n",
    "            })\n",
    "    \n",
    "    return apply_nms(detections, 0.65)\n",
    "\n",
    "def draw_detections(image_path, detections, score_thresh, unc_thresh):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", 14)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    filtered = [d for d in detections if d[\"score\"] >= score_thresh and d[\"uncertainty\"] <= unc_thresh]\n",
    "    \n",
    "    for det in filtered:\n",
    "        bbox = det[\"bbox\"]\n",
    "        cat = det[\"category\"]\n",
    "        score = det[\"score\"]\n",
    "        unc = det[\"uncertainty\"]\n",
    "        \n",
    "        color = COLORS.get(cat, \"#FFFFFF\")\n",
    "        draw.rectangle(bbox, outline=color, width=3)\n",
    "        \n",
    "        unc_level = \"HIGH\" if unc > 0.1 else (\"MED\" if unc > 0.05 else \"LOW\")\n",
    "        label = f\"{cat} {score:.2f} | unc:{unc_level}\"\n",
    "        \n",
    "        text_bbox = draw.textbbox((bbox[0], bbox[1]-20), label, font=font)\n",
    "        draw.rectangle(text_bbox, fill=color)\n",
    "        draw.text((bbox[0], bbox[1]-20), label, fill=\"white\", font=font)\n",
    "    \n",
    "    return img, filtered\n",
    "\n",
    "def main():\n",
    "    st.title(\"üöó OVD ADAS Demo: Detecci√≥n con Incertidumbre y Calibraci√≥n\")\n",
    "    \n",
    "    model, device = load_grounding_model()\n",
    "    temps = load_temperatures()\n",
    "    metrics = load_metrics()\n",
    "    \n",
    "    st.sidebar.header(\"‚öôÔ∏è Configuraci√≥n\")\n",
    "    \n",
    "    mode = st.sidebar.selectbox(\"M√©todo de detecci√≥n\", [\n",
    "        \"Baseline\",\n",
    "        \"Baseline + TS\",\n",
    "        \"MC-Dropout K=5\",\n",
    "        \"MC-Dropout K=5 + TS\",\n",
    "        \"Varianza Decoder\",\n",
    "        \"Varianza Decoder + TS\"\n",
    "    ])\n",
    "    \n",
    "    score_thresh = st.sidebar.slider(\"Umbral de confianza\", 0.0, 1.0, 0.3, 0.05)\n",
    "    unc_thresh = st.sidebar.slider(\"Umbral de incertidumbre\", 0.0, 0.5, 0.5, 0.05)\n",
    "    \n",
    "    st.sidebar.markdown(\"---\")\n",
    "    st.sidebar.subheader(\"üìä M√©tricas Globales\")\n",
    "    if metrics:\n",
    "        method_key = mode.lower().replace(\" \", \"_\").replace(\"+\", \"\").replace(\"__\", \"_\")\n",
    "        if method_key in metrics:\n",
    "            m = metrics[method_key]\n",
    "            st.sidebar.metric(\"mAP\", f\"{m.get(\\\\'mAP\\\\', 0):.3f}\")\n",
    "            st.sidebar.metric(\"ECE\", f\"{m.get(\\\\'ECE\\\\', 0):.4f}\")\n",
    "    \n",
    "    st.sidebar.markdown(\"---\")\n",
    "    upload = st.sidebar.file_uploader(\"üì§ Subir imagen\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "    \n",
    "    sample_imgs = get_sample_images()\n",
    "    use_sample = st.sidebar.checkbox(\"üìÇ Usar imagen de muestra\", value=True)\n",
    "    \n",
    "    if use_sample and sample_imgs:\n",
    "        selected_idx = st.sidebar.selectbox(\"Seleccionar imagen\", range(len(sample_imgs)), \n",
    "                                           format_func=lambda i: Path(sample_imgs[i]).name)\n",
    "        image_path = sample_imgs[selected_idx]\n",
    "    elif upload:\n",
    "        temp_path = Path(\"./temp_upload.jpg\")\n",
    "        with open(temp_path, \"wb\") as f:\n",
    "            f.write(upload.read())\n",
    "        image_path = str(temp_path)\n",
    "    else:\n",
    "        st.warning(\"‚ö†Ô∏è Sube una imagen o selecciona una de muestra\")\n",
    "        return\n",
    "    \n",
    "    if st.sidebar.button(\"üöÄ Ejecutar Detecci√≥n\", type=\"primary\"):\n",
    "        with st.spinner(f\"Ejecutando {mode}...\"):\n",
    "            temperature = temps.get(\"optimal_temperature\", 1.0)\n",
    "            \n",
    "            if mode == \"Baseline\":\n",
    "                dets = inference_baseline(model, image_path, score_thresh*0.5, device, temperature, False)\n",
    "            elif mode == \"Baseline + TS\":\n",
    "                dets = inference_baseline(model, image_path, score_thresh*0.5, device, temperature, True)\n",
    "            elif mode == \"MC-Dropout K=5\":\n",
    "                dets = inference_mc_dropout(model, image_path, score_thresh*0.5, device, 5, temperature, False)\n",
    "            elif mode == \"MC-Dropout K=5 + TS\":\n",
    "                dets = inference_mc_dropout(model, image_path, score_thresh*0.5, device, 5, temperature, True)\n",
    "            elif mode == \"Varianza Decoder\":\n",
    "                dets = inference_variance_decoder(model, image_path, score_thresh*0.5, device, temperature, False)\n",
    "            else:\n",
    "                dets = inference_variance_decoder(model, image_path, score_thresh*0.5, device, temperature, True)\n",
    "        \n",
    "        col1, col2 = st.columns([2, 1])\n",
    "        \n",
    "        with col1:\n",
    "            st.subheader(\"üñºÔ∏è Resultado Visual\")\n",
    "            img_result, filtered_dets = draw_detections(image_path, dets, score_thresh, unc_thresh)\n",
    "            st.image(img_result, use_container_width=True)\n",
    "        \n",
    "        with col2:\n",
    "            st.subheader(\"üìã Detecciones\")\n",
    "            st.metric(\"Total detecciones\", len(dets))\n",
    "            st.metric(\"Mostradas (filtradas)\", len(filtered_dets))\n",
    "            \n",
    "            high_unc = sum(1 for d in filtered_dets if d[\"uncertainty\"] > 0.1)\n",
    "            st.metric(\"Alta incertidumbre\", high_unc)\n",
    "            \n",
    "            if filtered_dets:\n",
    "                df = pd.DataFrame([{\n",
    "                    \"Clase\": d[\"category\"],\n",
    "                    \"Confianza\": f\"{d[\\\\'score\\\\']:.3f}\",\n",
    "                    \"Incertidumbre\": f\"{d[\\\\'uncertainty\\\\']:.3f}\"\n",
    "                } for d in filtered_dets])\n",
    "                st.dataframe(df, use_container_width=True)\n",
    "        \n",
    "        if filtered_dets:\n",
    "            st.subheader(\"üìä An√°lisis de Incertidumbre\")\n",
    "            uncs = [d[\"uncertainty\"] for d in filtered_dets]\n",
    "            scores = [d[\"score\"] for d in filtered_dets]\n",
    "            \n",
    "            fig = go.Figure()\n",
    "            fig.add_trace(go.Histogram(x=uncs, nbinsx=20, name=\"Incertidumbre\"))\n",
    "            fig.update_layout(title=\"Distribuci√≥n de Incertidumbre\", xaxis_title=\"Incertidumbre\", \n",
    "                            yaxis_title=\"Frecuencia\", height=300)\n",
    "            st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "with open(app_dir / 'demo.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(app_code)\n",
    "\n",
    "print(f\"‚úÖ Aplicaci√≥n creada en: {app_dir / 'demo.py'}\")\n",
    "print(f\"\\\\n‚ñ∂Ô∏è Para ejecutar: streamlit run {app_dir / 'demo.py'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64b912d",
   "metadata": {},
   "source": [
    "## 3. Preparar Im√°genes de Muestra\n",
    "\n",
    "Seleccionar casos interesantes del dataset BDD100K para la demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693432f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "BASE_DIR = Path('..')\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "VAL_JSON = DATA_DIR / 'bdd100k_coco' / 'val_eval.json'\n",
    "VAL_IMAGES = DATA_DIR / 'bdd100k' / 'bdd100k' / 'images' / '100k' / 'val'\n",
    "SAMPLES_DIR = Path('./app/samples')\n",
    "SAMPLES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(VAL_JSON, 'r') as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "# An√°lisis de im√°genes para seleccionar casos diversos\n",
    "img_stats = {}\n",
    "for ann in coco_data['annotations']:\n",
    "    img_id = ann['image_id']\n",
    "    if img_id not in img_stats:\n",
    "        img_stats[img_id] = {'count': 0, 'categories': set()}\n",
    "    img_stats[img_id]['count'] += 1\n",
    "    img_stats[img_id]['categories'].add(ann['category_id'])\n",
    "\n",
    "# Seleccionar casos representativos\n",
    "selected_cases = {\n",
    "    'easy': [],      # Pocas detecciones, objetos claros\n",
    "    'medium': [],    # Cantidad moderada\n",
    "    'hard': [],      # Muchos objetos, escena compleja\n",
    "}\n",
    "\n",
    "for img in coco_data['images']:\n",
    "    img_id = img['id']\n",
    "    if img_id not in img_stats:\n",
    "        continue\n",
    "    \n",
    "    count = img_stats[img_id]['count']\n",
    "    if count < 5:\n",
    "        selected_cases['easy'].append(img)\n",
    "    elif count < 15:\n",
    "        selected_cases['medium'].append(img)\n",
    "    else:\n",
    "        selected_cases['hard'].append(img)\n",
    "\n",
    "# Copiar 3 de cada tipo\n",
    "samples_copied = []\n",
    "for case_type, imgs in selected_cases.items():\n",
    "    for img_info in sorted(imgs, key=lambda x: img_stats[x['id']]['count'])[:3]:\n",
    "        src = VAL_IMAGES / img_info['file_name']\n",
    "        if src.exists():\n",
    "            dst = SAMPLES_DIR / f\"{case_type}_{img_info['file_name']}\"\n",
    "            shutil.copy(src, dst)\n",
    "            samples_copied.append(dst.name)\n",
    "\n",
    "print(f\"‚úÖ {len(samples_copied)} im√°genes de muestra copiadas a {SAMPLES_DIR}\")\n",
    "print(f\"\\\\nCasos seleccionados:\")\n",
    "print(f\"  - F√°ciles: 3 im√°genes (< 5 objetos)\")\n",
    "print(f\"  - Medios: 3 im√°genes (5-15 objetos)\")\n",
    "print(f\"  - Dif√≠ciles: 3 im√°genes (> 15 objetos)\")\n",
    "\n",
    "# Guardar metadata\n",
    "metadata = {\n",
    "    'samples': samples_copied,\n",
    "    'total': len(samples_copied),\n",
    "    'source': 'BDD100K val set',\n",
    "    'selection_criteria': 'Diversidad en n√∫mero de objetos y complejidad de escena'\n",
    "}\n",
    "\n",
    "with open(SAMPLES_DIR / 'metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"\\\\nüìÑ Metadata guardada en {SAMPLES_DIR / 'metadata.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23782ec8",
   "metadata": {},
   "source": [
    "## 4. Documentaci√≥n de la Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c832da6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_content = '''# üöó Demo Interactiva: OVD con Calibraci√≥n e Incertidumbre\n",
    "\n",
    "## üìã Descripci√≥n\n",
    "\n",
    "Aplicaci√≥n web interactiva que demuestra:\n",
    "- **Detecci√≥n Open-Vocabulary** en escenas ADAS (BDD100K)\n",
    "- **Calibraci√≥n de probabilidades** mediante Temperature Scaling\n",
    "- **Incertidumbre epist√©mica** mediante MC-Dropout y varianza decoder\n",
    "- **Filtrado inteligente** basado en incertidumbre\n",
    "\n",
    "## üöÄ Ejecuci√≥n\n",
    "\n",
    "```bash\n",
    "cd fase\\\\ 6\n",
    "streamlit run app/demo.py\n",
    "```\n",
    "\n",
    "La aplicaci√≥n se abrir√° en `http://localhost:8501`\n",
    "\n",
    "## üéØ Funcionalidades\n",
    "\n",
    "### M√©todos Disponibles\n",
    "\n",
    "1. **Baseline**: Detecci√≥n est√°ndar sin calibraci√≥n ni incertidumbre\n",
    "2. **Baseline + TS**: Con calibraci√≥n de probabilidades\n",
    "3. **MC-Dropout K=5**: 5 pases estoc√°sticos para incertidumbre\n",
    "4. **MC-Dropout K=5 + TS**: Con calibraci√≥n\n",
    "5. **Varianza Decoder**: Incertidumbre desde m√∫ltiples capas (single-pass)\n",
    "6. **Varianza Decoder + TS**: Con calibraci√≥n\n",
    "\n",
    "### Controles\n",
    "\n",
    "- **Umbral de confianza**: Filtrar detecciones por probabilidad\n",
    "- **Umbral de incertidumbre**: Filtrar detecciones inciertas\n",
    "- **Carga de imagen**: Subir propia o usar muestras pre-seleccionadas\n",
    "- **M√©tricas globales**: Ver rendimiento general del m√©todo\n",
    "\n",
    "### Visualizaci√≥n\n",
    "\n",
    "- **Cajas de detecci√≥n** coloreadas por clase\n",
    "- **Etiquetas** con clase, confianza y nivel de incertidumbre\n",
    "- **Tabla de detecciones** con valores num√©ricos\n",
    "- **Histograma** de distribuci√≥n de incertidumbre\n",
    "\n",
    "## üìä Interpretaci√≥n\n",
    "\n",
    "### Calibraci√≥n\n",
    "- **Sin TS**: El modelo puede ser sobreconfiado (p=0.95 pero accuracy real 70%)\n",
    "- **Con TS**: Probabilidades ajustadas a frecuencia real de aciertos\n",
    "\n",
    "### Incertidumbre\n",
    "- **Baja (< 0.05)**: El modelo est√° seguro, decisi√≥n confiable\n",
    "- **Media (0.05-0.1)**: Cierta duda, usar con precauci√≥n\n",
    "- **Alta (> 0.1)**: Modelo muy incierto, requiere verificaci√≥n\n",
    "\n",
    "### Uso en ADAS\n",
    "- **Modo seguro**: Filtrar por umbral de incertidumbre\n",
    "- **Detecciones de alta incertidumbre**: Alertar al conductor\n",
    "- **Detecciones de baja incertidumbre**: Actuar autom√°ticamente\n",
    "\n",
    "## üé® Casos de Uso\n",
    "\n",
    "La demo incluye 9 im√°genes pre-seleccionadas:\n",
    "\n",
    "- **Casos f√°ciles (3)**: Pocos objetos, buena iluminaci√≥n\n",
    "- **Casos medios (3)**: Tr√°fico moderado, condiciones normales  \n",
    "- **Casos dif√≠ciles (3)**: Muchos objetos, oclusi√≥n, condiciones adversas\n",
    "\n",
    "## üìà M√©tricas Mostradas\n",
    "\n",
    "- **mAP**: Precisi√≥n media del m√©todo\n",
    "- **ECE**: Error de calibraci√≥n esperado\n",
    "- **Total detecciones**: N√∫mero de objetos detectados\n",
    "- **Alta incertidumbre**: Detecciones que requieren atenci√≥n\n",
    "\n",
    "## üîß Requisitos\n",
    "\n",
    "- Python 3.8+\n",
    "- GroundingDINO instalado\n",
    "- CUDA (opcional, acelera inferencia)\n",
    "- Resultados de Fases 4 y 5 disponibles\n",
    "\n",
    "## üìù Notas\n",
    "\n",
    "- La inferencia con MC-Dropout (K=5) toma ~5x m√°s tiempo que baseline\n",
    "- Varianza decoder es m√°s r√°pido pero menos preciso\n",
    "- Temperature Scaling requiere resultados de Fase 4\n",
    "- Las m√©tricas globales provienen de la Fase 5\n",
    "\n",
    "## üéì Para la Defensa\n",
    "\n",
    "Esta demo permite:\n",
    "1. Mostrar visualmente el efecto de la calibraci√≥n\n",
    "2. Demostrar cu√°ndo el modelo es incierto\n",
    "3. Explicar c√≥mo usar incertidumbre para decisiones seguras en ADAS\n",
    "4. Comparar m√©todos en tiempo real\n",
    "\n",
    "## üì∏ Capturas de Pantalla\n",
    "\n",
    "Ejecutar la demo y tomar capturas de:\n",
    "- Caso f√°cil con baja incertidumbre\n",
    "- Caso dif√≠cil con alta incertidumbre\n",
    "- Comparaci√≥n antes/despu√©s de calibraci√≥n\n",
    "- Efecto del filtrado por incertidumbre\n",
    "'''\n",
    "\n",
    "with open(Path('./README.md'), 'w', encoding='utf-8') as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "print(\"‚úÖ README.md creado en fase 6/README.md\")\n",
    "print(\"\\\\nüìñ Contenido:\")\n",
    "print(\"  - Instrucciones de ejecuci√≥n\")\n",
    "print(\"  - Descripci√≥n de m√©todos\")\n",
    "print(\"  - Interpretaci√≥n de resultados\")\n",
    "print(\"  - Casos de uso en ADAS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40359b6f",
   "metadata": {},
   "source": [
    "## 5. Script de Lanzamiento\n",
    "\n",
    "Crear scripts para ejecutar la demo f√°cilmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6ce52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script para Windows (PowerShell)\n",
    "launch_ps1 = '''# Lanzador de Demo - Fase 6\n",
    "Write-Host \"üöÄ Iniciando Demo OVD con Calibraci√≥n e Incertidumbre...\" -ForegroundColor Cyan\n",
    "\n",
    "# Verificar si Streamlit est√° instalado\n",
    "$streamlitInstalled = python -m pip show streamlit 2>$null\n",
    "if (-not $streamlitInstalled) {\n",
    "    Write-Host \"‚ö†Ô∏è  Streamlit no instalado, instalando...\" -ForegroundColor Yellow\n",
    "    python -m pip install streamlit streamlit-option-menu plotly -q\n",
    "}\n",
    "\n",
    "# Verificar archivos necesarios\n",
    "if (-not (Test-Path \"app/demo.py\")) {\n",
    "    Write-Host \"‚ùå Error: app/demo.py no encontrado\" -ForegroundColor Red\n",
    "    Write-Host \"   Ejecuta primero las celdas del notebook main.ipynb\" -ForegroundColor Yellow\n",
    "    exit 1\n",
    "}\n",
    "\n",
    "# Lanzar aplicaci√≥n\n",
    "Write-Host \"‚úÖ Abriendo aplicaci√≥n en navegador...\" -ForegroundColor Green\n",
    "streamlit run app/demo.py\n",
    "'''\n",
    "\n",
    "with open(Path('./launch_demo.ps1'), 'w', encoding='utf-8') as f:\n",
    "    f.write(launch_ps1)\n",
    "\n",
    "# Script para Linux/Mac (Bash)\n",
    "launch_sh = '''#!/bin/bash\n",
    "# Lanzador de Demo - Fase 6\n",
    "\n",
    "echo \"üöÄ Iniciando Demo OVD con Calibraci√≥n e Incertidumbre...\"\n",
    "\n",
    "# Verificar si Streamlit est√° instalado\n",
    "if ! python -m pip show streamlit &> /dev/null; then\n",
    "    echo \"‚ö†Ô∏è  Streamlit no instalado, instalando...\"\n",
    "    python -m pip install streamlit streamlit-option-menu plotly -q\n",
    "fi\n",
    "\n",
    "# Verificar archivos necesarios\n",
    "if [ ! -f \"app/demo.py\" ]; then\n",
    "    echo \"‚ùå Error: app/demo.py no encontrado\"\n",
    "    echo \"   Ejecuta primero las celdas del notebook main.ipynb\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Lanzar aplicaci√≥n\n",
    "echo \"‚úÖ Abriendo aplicaci√≥n en navegador...\"\n",
    "streamlit run app/demo.py\n",
    "'''\n",
    "\n",
    "with open(Path('./launch_demo.sh'), 'w', encoding='utf-8') as f:\n",
    "    f.write(launch_sh)\n",
    "\n",
    "# Hacer ejecutable en sistemas Unix\n",
    "import stat\n",
    "sh_path = Path('./launch_demo.sh')\n",
    "if sh_path.exists():\n",
    "    sh_path.chmod(sh_path.stat().st_mode | stat.S_IEXEC)\n",
    "\n",
    "print(\"‚úÖ Scripts de lanzamiento creados:\")\n",
    "print(f\"  - Windows: launch_demo.ps1\")\n",
    "print(f\"  - Linux/Mac: launch_demo.sh\")\n",
    "print(f\"\\\\n‚ñ∂Ô∏è Ejecutar con:\")\n",
    "print(f\"  Windows:   .\\\\\\\\launch_demo.ps1\")\n",
    "print(f\"  Linux/Mac: ./launch_demo.sh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639495bf",
   "metadata": {},
   "source": [
    "## 6. Generaci√≥n de Capturas para Documentaci√≥n\n",
    "\n",
    "Crear capturas representativas autom√°ticamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9812a3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from groundingdino.util.inference import load_model, load_image, predict\n",
    "from groundingdino.util import box_ops\n",
    "import torchvision\n",
    "\n",
    "# Cargar configuraci√≥n\n",
    "BASE_DIR = Path('..')\n",
    "FASE4_DIR = BASE_DIR / 'fase 4' / 'outputs' / 'temperature_scaling'\n",
    "SAMPLES_DIR = Path('./app/samples')\n",
    "SCREENSHOTS_DIR = Path('./outputs/screenshots')\n",
    "SCREENSHOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CATEGORIES = [\"person\", \"rider\", \"car\", \"truck\", \"bus\", \"train\", \"motorcycle\", \"bicycle\", \"traffic light\", \"traffic sign\"]\n",
    "COLORS = {\n",
    "    \"person\": \"#FF6B6B\", \"rider\": \"#4ECDC4\", \"car\": \"#45B7D1\", \"truck\": \"#FFA07A\",\n",
    "    \"bus\": \"#98D8C8\", \"train\": \"#F7DC6F\", \"motorcycle\": \"#BB8FCE\", \"bicycle\": \"#85C1E2\",\n",
    "    \"traffic light\": \"#F8B739\", \"traffic sign\": \"#52B788\"\n",
    "}\n",
    "\n",
    "# Cargar modelo\n",
    "model_config = '/opt/program/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py'\n",
    "model_weights = '/opt/program/GroundingDINO/weights/groundingdino_swint_ogc.pth'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = load_model(model_config, model_weights)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Cargar temperatura\n",
    "temp_file = FASE4_DIR / 'temperature.json'\n",
    "if temp_file.exists():\n",
    "    with open(temp_file, 'r') as f:\n",
    "        temp_data = json.load(f)\n",
    "        temperature = temp_data.get('optimal_temperature', 1.0)\n",
    "else:\n",
    "    temperature = 1.0\n",
    "\n",
    "print(f\"Modelo cargado en {device}\")\n",
    "print(f\"Temperatura: {temperature:.4f}\")\n",
    "\n",
    "def normalize_label(label):\n",
    "    synonyms = {'bike': 'bicycle', 'motorbike': 'motorcycle', 'pedestrian': 'person', \n",
    "                'stop sign': 'traffic sign', 'red light': 'traffic light'}\n",
    "    label_lower = label.lower().strip()\n",
    "    return synonyms.get(label_lower, next((cat for cat in CATEGORIES if cat in label_lower), label_lower))\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-np.clip(z, -20, 20)))\n",
    "\n",
    "def run_detection(image_path, use_ts=False):\n",
    "    image_source, image = load_image(str(image_path))\n",
    "    text_prompt = '. '.join(CATEGORIES) + '.'\n",
    "    \n",
    "    boxes, scores, phrases = predict(model, image, text_prompt, 0.25, 0.25, device)\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    \n",
    "    h, w = image_source.shape[:2]\n",
    "    boxes_xyxy = box_ops.box_cxcywh_to_xyxy(boxes) * torch.tensor([w, h, w, h])\n",
    "    \n",
    "    detections = []\n",
    "    for box, score, phrase in zip(boxes_xyxy.cpu().numpy(), scores.cpu().numpy(), phrases):\n",
    "        cat = normalize_label(phrase)\n",
    "        if cat in CATEGORIES:\n",
    "            score_clip = np.clip(float(score), 1e-7, 1-1e-7)\n",
    "            logit = np.log(score_clip / (1-score_clip))\n",
    "            \n",
    "            if use_ts:\n",
    "                final_score = sigmoid(logit / temperature)\n",
    "            else:\n",
    "                final_score = score_clip\n",
    "            \n",
    "            detections.append({\n",
    "                'bbox': box.tolist(),\n",
    "                'score': float(final_score),\n",
    "                'category': cat\n",
    "            })\n",
    "    \n",
    "    # NMS\n",
    "    if len(detections) > 0:\n",
    "        boxes_t = torch.tensor([d['bbox'] for d in detections])\n",
    "        scores_t = torch.tensor([d['score'] for d in detections])\n",
    "        keep = torchvision.ops.nms(boxes_t, scores_t, 0.65)\n",
    "        detections = [detections[i] for i in keep.numpy()]\n",
    "    \n",
    "    return detections\n",
    "\n",
    "def draw_comparison(image_path, dets_baseline, dets_ts, output_path):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    w, h = img.size\n",
    "    \n",
    "    # Crear imagen lado a lado\n",
    "    combined = Image.new('RGB', (w*2 + 20, h), (255, 255, 255))\n",
    "    combined.paste(img, (0, 0))\n",
    "    combined.paste(img.copy(), (w+20, 0))\n",
    "    \n",
    "    draw = ImageDraw.Draw(combined)\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", 14)\n",
    "        font_title = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", 20)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "        font_title = font\n",
    "    \n",
    "    # T√≠tulos\n",
    "    draw.text((w//2 - 100, 10), \"Sin Calibraci√≥n\", fill=\"red\", font=font_title)\n",
    "    draw.text((w + w//2 - 80, 10), \"Con Temperature Scaling\", fill=\"green\", font=font_title)\n",
    "    \n",
    "    # Dibujar detecciones sin calibraci√≥n (izquierda)\n",
    "    for det in dets_baseline:\n",
    "        bbox = det['bbox']\n",
    "        color = COLORS.get(det['category'], '#FFFFFF')\n",
    "        draw.rectangle(bbox, outline=color, width=3)\n",
    "        label = f\"{det['category']} {det['score']:.2f}\"\n",
    "        draw.text((bbox[0], bbox[1]-20), label, fill=color, font=font)\n",
    "    \n",
    "    # Dibujar detecciones con calibraci√≥n (derecha)\n",
    "    for det in dets_ts:\n",
    "        bbox = [b + w + 20 if i % 2 == 0 else b for i, b in enumerate(det['bbox'])]\n",
    "        color = COLORS.get(det['category'], '#FFFFFF')\n",
    "        draw.rectangle(bbox, outline=color, width=3)\n",
    "        label = f\"{det['category']} {det['score']:.2f}\"\n",
    "        draw.text((bbox[0], bbox[1]-20), label, fill=color, font=font)\n",
    "    \n",
    "    combined.save(output_path)\n",
    "    return combined\n",
    "\n",
    "# Generar capturas\n",
    "if SAMPLES_DIR.exists():\n",
    "    sample_images = sorted(list(SAMPLES_DIR.glob('*.jpg')))[:3]\n",
    "    \n",
    "    print(f\"\\\\nüì∏ Generando capturas comparativas...\")\n",
    "    for i, img_path in enumerate(sample_images):\n",
    "        print(f\"  Procesando {img_path.name}...\")\n",
    "        \n",
    "        dets_baseline = run_detection(img_path, use_ts=False)\n",
    "        dets_ts = run_detection(img_path, use_ts=True)\n",
    "        \n",
    "        output_path = SCREENSHOTS_DIR / f\"comparison_{i+1}_{img_path.stem}.jpg\"\n",
    "        draw_comparison(img_path, dets_baseline, dets_ts, output_path)\n",
    "        \n",
    "        print(f\"    ‚úÖ Guardado en {output_path}\")\n",
    "        print(f\"       Sin TS: {len(dets_baseline)} detecciones\")\n",
    "        print(f\"       Con TS: {len(dets_ts)} detecciones\")\n",
    "\n",
    "print(f\"\\\\n‚úÖ Capturas generadas en {SCREENSHOTS_DIR}\")\n",
    "print(f\"\\\\nEstas im√°genes muestran:\")\n",
    "print(f\"  - Izquierda: Probabilidades originales (sin calibrar)\")\n",
    "print(f\"  - Derecha: Probabilidades calibradas con TS\")\n",
    "print(f\"  - Diferencias en valores de confianza\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d62f30d",
   "metadata": {},
   "source": [
    "## 7. Verificaci√≥n del Sistema\n",
    "\n",
    "Comprobar que todos los componentes est√°n listos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b529b00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import sys\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"VERIFICACI√ìN DEL SISTEMA - FASE 6\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "checks = {\n",
    "    \"Aplicaci√≥n Streamlit\": Path('./app/demo.py'),\n",
    "    \"README\": Path('./README.md'),\n",
    "    \"Script Windows\": Path('./launch_demo.ps1'),\n",
    "    \"Script Linux\": Path('./launch_demo.sh'),\n",
    "    \"Carpeta samples\": Path('./app/samples'),\n",
    "    \"Carpeta outputs\": Path('./outputs'),\n",
    "    \"Screenshots\": Path('./outputs/screenshots'),\n",
    "}\n",
    "\n",
    "# Verificar archivos cr√≠ticos\n",
    "print(\"\\\\n1Ô∏è‚É£ ARCHIVOS Y CARPETAS\")\n",
    "all_ok = True\n",
    "for name, path in checks.items():\n",
    "    exists = path.exists()\n",
    "    status = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "    print(f\"  {status} {name}: {path}\")\n",
    "    if not exists:\n",
    "        all_ok = False\n",
    "\n",
    "# Verificar dependencias de otras fases\n",
    "print(\"\\\\n2Ô∏è‚É£ DEPENDENCIAS DE FASES ANTERIORES\")\n",
    "BASE_DIR = Path('..')\n",
    "dependencies = {\n",
    "    \"Fase 4 - Temperatura\": BASE_DIR / 'fase 4' / 'outputs' / 'temperature_scaling' / 'temperature.json',\n",
    "    \"Fase 5 - M√©tricas\": BASE_DIR / 'fase 5' / 'outputs' / 'comparison' / 'comparative_metrics.json',\n",
    "    \"BDD100K Val\": BASE_DIR / 'data' / 'bdd100k_coco' / 'val_eval.json',\n",
    "}\n",
    "\n",
    "for name, path in dependencies.items():\n",
    "    exists = path.exists()\n",
    "    status = \"‚úÖ\" if exists else \"‚ö†Ô∏è\"\n",
    "    print(f\"  {status} {name}: {path}\")\n",
    "    if not exists:\n",
    "        print(f\"       NOTA: Demo funcionar√° pero sin {name}\")\n",
    "\n",
    "# Verificar im√°genes de muestra\n",
    "print(\"\\\\n3Ô∏è‚É£ IM√ÅGENES DE MUESTRA\")\n",
    "samples_dir = Path('./app/samples')\n",
    "if samples_dir.exists():\n",
    "    samples = list(samples_dir.glob('*.jpg'))\n",
    "    print(f\"  ‚úÖ {len(samples)} im√°genes disponibles\")\n",
    "    if len(samples) > 0:\n",
    "        print(f\"     Ejemplos: {', '.join([s.name for s in samples[:3]])}\")\n",
    "else:\n",
    "    print(f\"  ‚ö†Ô∏è  Carpeta samples no existe, crear ejecutando celda 3\")\n",
    "\n",
    "# Verificar m√≥dulos Python\n",
    "print(\"\\\\n4Ô∏è‚É£ M√ìDULOS PYTHON\")\n",
    "required_modules = {\n",
    "    'streamlit': 'Demo web',\n",
    "    'plotly': 'Visualizaciones interactivas',\n",
    "    'PIL': 'Procesamiento de im√°genes',\n",
    "    'torch': 'PyTorch',\n",
    "}\n",
    "\n",
    "for module, desc in required_modules.items():\n",
    "    try:\n",
    "        __import__(module if module != 'PIL' else 'PIL')\n",
    "        print(f\"  ‚úÖ {module}: {desc}\")\n",
    "    except ImportError:\n",
    "        print(f\"  ‚ùå {module}: {desc} - NO INSTALADO\")\n",
    "        all_ok = False\n",
    "\n",
    "# Resumen final\n",
    "print(\"\\\\n\" + \"=\"*70)\n",
    "if all_ok and Path('./app/demo.py').exists():\n",
    "    print(\"‚úÖ SISTEMA LISTO PARA DEMO\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\\\n‚ñ∂Ô∏è Para ejecutar:\")\n",
    "    print(\"   cd fase 6\")\n",
    "    print(\"   streamlit run app/demo.py\")\n",
    "    print(\"\\\\nO usar scripts de lanzamiento:\")\n",
    "    print(\"   Windows:   .\\\\\\\\launch_demo.ps1\")\n",
    "    print(\"   Linux/Mac: ./launch_demo.sh\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è SISTEMA REQUIERE CONFIGURACI√ìN\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\\\nEjecutar celdas del notebook en orden:\")\n",
    "    print(\"  1. Instalaci√≥n de dependencias\")\n",
    "    print(\"  2. Crear aplicaci√≥n Streamlit\")\n",
    "    print(\"  3. Preparar im√°genes de muestra\")\n",
    "    print(\"  4-6. Documentaci√≥n y scripts\")\n",
    "\n",
    "# Guardar reporte\n",
    "report = {\n",
    "    'timestamp': str(pd.Timestamp.now()),\n",
    "    'files_ok': all_ok,\n",
    "    'files_checked': {str(k): str(v.exists()) for k, v in checks.items()},\n",
    "    'dependencies': {str(k): str(v.exists()) for k, v in dependencies.items()},\n",
    "}\n",
    "\n",
    "with open(Path('./outputs/verification_report.json'), 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(f\"\\\\nüìÑ Reporte guardado en outputs/verification_report.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a257ef94",
   "metadata": {},
   "source": [
    "## 8. Resumen y Conclusiones\n",
    "\n",
    "### ‚úÖ Componentes Creados\n",
    "\n",
    "1. **Aplicaci√≥n Streamlit** (`app/demo.py`)\n",
    "   - 6 m√©todos de detecci√≥n (baseline, MC-Dropout, varianza decoder)\n",
    "   - Calibraci√≥n con/sin Temperature Scaling\n",
    "   - Interfaz interactiva con controles\n",
    "   - Visualizaci√≥n de incertidumbre\n",
    "\n",
    "2. **Im√°genes de Muestra** (`app/samples/`)\n",
    "   - Casos f√°ciles, medios y dif√≠ciles\n",
    "   - Diversidad de escenarios ADAS\n",
    "   - Metadata de selecci√≥n\n",
    "\n",
    "3. **Documentaci√≥n** (`README.md`)\n",
    "   - Instrucciones de ejecuci√≥n\n",
    "   - Interpretaci√≥n de resultados\n",
    "   - Casos de uso en ADAS\n",
    "\n",
    "4. **Scripts de Lanzamiento**\n",
    "   - PowerShell para Windows\n",
    "   - Bash para Linux/Mac\n",
    "   - Verificaci√≥n de dependencias\n",
    "\n",
    "5. **Capturas Comparativas** (`outputs/screenshots/`)\n",
    "   - Antes/despu√©s calibraci√≥n\n",
    "   - Visualizaci√≥n de incertidumbre\n",
    "   - Listas para defensa\n",
    "\n",
    "### üéØ Objetivos Cumplidos\n",
    "\n",
    "‚úÖ Demo muestra detecci√≥n OVD en escenas ADAS  \n",
    "‚úÖ Compara confianza calibrada vs sin calibrar  \n",
    "‚úÖ Visualiza incertidumbre epist√©mica  \n",
    "‚úÖ Permite filtrado por umbral de incertidumbre  \n",
    "‚úÖ Conecta con m√©tricas globales (Fase 5)  \n",
    "‚úÖ Interfaz intuitiva para audiencia no t√©cnica  \n",
    "\n",
    "### üìä Casos de Uso Demostrados\n",
    "\n",
    "1. **Calibraci√≥n mejora honestidad**\n",
    "   - Probabilidades ajustadas a precisi√≥n real\n",
    "   - Reduce sobreconfianza del modelo\n",
    "\n",
    "2. **Incertidumbre indica riesgo**\n",
    "   - Alta incertidumbre ‚Üí verificaci√≥n necesaria\n",
    "   - Baja incertidumbre ‚Üí decisi√≥n autom√°tica\n",
    "\n",
    "3. **Aplicaci√≥n en ADAS**\n",
    "   - Modo seguro: solo detecciones confiables\n",
    "   - Alertas inteligentes seg√∫n incertidumbre\n",
    "\n",
    "### üéì Para la Defensa\n",
    "\n",
    "La demo permite explicar visualmente:\n",
    "- Qu√© es calibraci√≥n y por qu√© importa\n",
    "- C√≥mo se mide incertidumbre epist√©mica\n",
    "- Por qu√© es cr√≠tico en sistemas de seguridad\n",
    "- Trade-offs entre m√©todos (velocidad vs precisi√≥n)\n",
    "\n",
    "### üìà Pr√≥ximos Pasos\n",
    "\n",
    "1. Ejecutar demo y tomar capturas clave\n",
    "2. Preparar escenarios para presentaci√≥n:\n",
    "   - Caso donde calibraci√≥n corrige sobreconfianza\n",
    "   - Caso donde incertidumbre detecta error\n",
    "   - Comparaci√≥n de velocidad entre m√©todos\n",
    "3. Integrar en presentaci√≥n de defensa\n",
    "4. Documentar en tesis (cap√≠tulo de resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0b1021",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üöÄ INSTRUCCIONES DE EJECUCI√ìN\n",
    "\n",
    "### Opci√≥n 1: Ejecutar desde este notebook\n",
    "\n",
    "```python\n",
    "# Ejecutar todas las celdas en orden (1-7)\n",
    "# Esto crear√° todos los archivos necesarios\n",
    "```\n",
    "\n",
    "### Opci√≥n 2: Ejecutar demo directamente\n",
    "\n",
    "#### En Windows (PowerShell):\n",
    "```powershell\n",
    "cd \"fase 6\"\n",
    ".\\launch_demo.ps1\n",
    "```\n",
    "\n",
    "#### En Linux/Mac:\n",
    "```bash\n",
    "cd \"fase 6\"\n",
    "./launch_demo.sh\n",
    "```\n",
    "\n",
    "#### Manual:\n",
    "```bash\n",
    "cd \"fase 6\"\n",
    "streamlit run app/demo.py\n",
    "```\n",
    "\n",
    "### üìù Notas Importantes\n",
    "\n",
    "1. **Primera ejecuci√≥n**: Ejecutar todas las celdas del notebook para crear archivos\n",
    "2. **Ejecuciones siguientes**: Usar scripts de lanzamiento directamente\n",
    "3. **Im√°genes de muestra**: La celda 3 copia im√°genes de BDD100K\n",
    "4. **Dependencias**: Fase 4 (temperaturas) y Fase 5 (m√©tricas) deben estar completas\n",
    "5. **Performance**: MC-Dropout es ~5x m√°s lento que baseline\n",
    "\n",
    "### üîç Troubleshooting\n",
    "\n",
    "- **Error \"app/demo.py not found\"**: Ejecutar celda 2\n",
    "- **No se ven im√°genes**: Ejecutar celda 3\n",
    "- **Streamlit no instalado**: Ejecutar celda 1\n",
    "- **Modelo no carga**: Verificar rutas en /opt/program/GroundingDINO/\n",
    "\n",
    "### üì∏ Capturar Screenshots\n",
    "\n",
    "1. Ejecutar demo\n",
    "2. Seleccionar diferentes m√©todos\n",
    "3. Usar im√°genes de muestra (easy/medium/hard)\n",
    "4. Capturar pantalla con comparaciones\n",
    "5. Guardar en `outputs/screenshots/` para defensa"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
